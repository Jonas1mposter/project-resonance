# Project Resonance — 测试数据标准规范 v1.0

**日期**：2026-02-24  
**适用范围**：构音障碍语音识别系统的数据采集、标注、验证与评测  
**数据库现状**：12 位说话人，4,944 条录音（未标注）

---

## 1. 术语定义

| 术语 | 定义 |
|------|------|
| **说话人 (Speaker)** | 一位独立的录音提供者，以 `DF`/`DM` + 编号标识（F=女性, M=男性） |
| **语料 (Utterance)** | 一条完整的录音样本，对应一个音频文件 |
| **标签 (Label)** | 语料对应的标准文本（即说话人"想要表达"的内容） |
| **严重度 (Severity)** | 构音障碍程度分级：轻度 / 中度 / 重度 / 极重度 |
| **训练集 (Train)** | 用于系统学习/建模的样本 |
| **测试集 (Test)** | 用于评测系统性能的样本，严禁用于训练 |
| **OOV (Out-of-Vocabulary)** | 不在词表内的语料，用于测试拒识能力 |

---

## 2. 数据采集标准

### 2.1 音频技术规格

| 参数 | 要求 | 说明 |
|------|------|------|
| 采样率 | **16,000 Hz** | 语音识别标准采样率 |
| 位深 | 16-bit PCM | 避免有损压缩 |
| 声道 | 单声道 (Mono) | 立体声需先混为单声道 |
| 格式 | WAV (首选) / WebM (浏览器录制原始格式) | 存储与传输分别使用 |
| 时长范围 | **0.5s ~ 10s** | <0.5s 判定无效；>10s 需人工检查是否含长静音 |
| 信噪比 (SNR) | ≥ 15 dB | 安静室内环境基本可达标 |

### 2.2 录音环境要求

| 条件 | 标准 | 验证方式 |
|------|------|----------|
| 环境噪声 | < 40 dB SPL | 录 3 秒静音段，计算 RMS |
| 距离 | 麦克风距口部 15~30 cm | 录音前口头确认 |
| 设备 | 手机自带麦克风 / USB 麦克 / 耳麦 | 记录设备型号至 metadata |
| 回声 | 无明显混响 | 主观判断 + 能量衰减检测 |

### 2.3 说话人信息采集

每位说话人须填写以下元数据（存入 `metadata` JSON 字段）：

```json
{
  "age": 35,
  "gender": "M",
  "severity": "moderate",
  "diagnosis": "脑瘫-痉挛型",
  "native_language": "普通话",
  "dialect": "四川方言",
  "device": "iPhone 15 内置麦克风",
  "environment": "家庭卧室",
  "notes": "佩戴矫形器，坐姿录音"
}
```

**severity 分级标准**（参照 Frenchay 构音障碍评估）：

| 等级 | 代码 | 描述 | 对普通人可懂度 |
|------|------|------|----------------|
| 轻度 | `mild` | 偶尔含糊，不影响交流 | > 80% |
| 中度 | `moderate` | 需集中注意力才能理解 | 50%~80% |
| 重度 | `severe` | 仅熟悉者能部分理解 | 20%~50% |
| 极重度 | `profound` | 几乎无法被理解 | < 20% |

---

## 3. 数据标注标准

### 3.1 必填字段

对数据库 `dysarthria_recordings` 表，以下字段**必须标注**方可进入有效数据集：

| 字段 | 要求 | 示例 |
|------|------|------|
| `speaker_id` | `DF`/`DM` + 4位编号 | `DM0008` |
| `label` | 说话人意图表达的标准文本（简体中文） | `我想喝水` |
| `category` | 所属分类（从 9 大类中选取） | `生理需求` |
| `duration_ms` | 有效语音时长（毫秒），不含首尾静音 | `2350` |
| `metadata` | JSON 对象，包含说话人信息 + 质量标记 | 见下方 |

### 3.2 标注分类体系

使用与应用词表一致的 9+1 分类：

| 编号 | 分类 | 目标条数/人 | 说明 |
|------|------|-------------|------|
| 1 | 生理需求 | 10~15 | 喝水、吃饭、上厕所等 |
| 2 | 照护协助 | 10~15 | 翻身、换尿布、量体温等 |
| 3 | 疼痛不适 | 8~12 | 头疼、肚子疼、不舒服等 |
| 4 | 社交寒暄 | 8~12 | 你好、谢谢、对不起等 |
| 5 | 家居日常 | 8~12 | 开灯、关门、开电视等 |
| 6 | 饮食相关 | 5~8 | 太烫、再来一碗、吃药等 |
| 7 | 出行交通 | 5~8 | 我要出去、打车、回家等 |
| 8 | 紧急求助 | 5~8 | 救命、帮帮我、打120等 |
| 9 | 情绪表达 | 5~8 | 开心、难过、害怕等 |
| 10 | OOV (词表外) | **15~20** | 不在词表中的语句，专用于拒识测试 |

### 3.3 标注质量标记

在 `metadata` 中增加 `quality` 字段：

```json
{
  "quality": {
    "snr_db": 22.5,
    "clipping": false,
    "too_quiet": false,
    "background_noise": "none",
    "intelligibility": 3,
    "annotator": "reviewer_01",
    "annotated_at": "2026-02-24T10:30:00Z",
    "verified": true
  }
}
```

**intelligibility 可懂度评分**（1~5 分制，由标注员主观评定）：

| 分数 | 含义 |
|------|------|
| 5 | 完全可以理解 |
| 4 | 基本可以理解，个别字含糊 |
| 3 | 需要参照文本才能对应上 |
| 2 | 即使参照文本也很难对应 |
| 1 | 完全无法识别语音内容 |

> **规则**：intelligibility ≤ 1 的样本标记为 `rejected`，不计入有效数据集。

---

## 4. 数据集划分标准

### 4.1 划分原则

| 原则 | 说明 |
|------|------|
| **说话人内划分** | 每位说话人的数据独立划分 Train/Test，不跨说话人混分 |
| **按短语分层** | 每条短语的多次录音按比例划分，保证 Test 集覆盖所有短语 |
| **OOV 仅入 Test** | 词表外语料 100% 进入 Test 集，用于拒识评估 |
| **时间顺序** | 优先将后录的样本分配到 Test（模拟真实使用顺序） |

### 4.2 划分比例

| 数据子集 | 比例 | 用途 | 最少样本数/短语 |
|----------|------|------|-----------------|
| Train | 70% | 模板建库 / 模型训练 | ≥ 2 条 |
| Dev (验证) | 10% | 调参（阈值、Top-K） | ≥ 1 条 |
| Test | 20% | 最终评测报告 | ≥ 1 条 |

**特殊情况**：当某短语仅有 2 条录音时，2 条均入 Train，该短语不参与 Test 评测（在报告中标注为"数据不足"）。

### 4.3 划分执行（SQL 参考）

```sql
-- 为每条录音生成 split 标记
-- 按 speaker_id + label 分组，组内按时间排序，后 20% 入 test，中间 10% 入 dev
UPDATE dysarthria_recordings r
SET metadata = jsonb_set(
  COALESCE(r.metadata::jsonb, '{}'::jsonb),
  '{split}',
  CASE
    WHEN row_pct > 0.8 THEN '"test"'
    WHEN row_pct > 0.7 THEN '"dev"'
    ELSE '"train"'
  END
)
FROM (
  SELECT id,
    percent_rank() OVER (
      PARTITION BY speaker_id, label
      ORDER BY created_at
    ) as row_pct
  FROM dysarthria_recordings
  WHERE speaker_id IS NOT NULL AND label IS NOT NULL
) sub
WHERE r.id = sub.id;
```

---

## 5. 质量验收标准

### 5.1 单条录音验收

一条录音通过验收需满足**全部**以下条件：

| # | 检查项 | 通过标准 | 检测方式 |
|---|--------|----------|----------|
| 1 | 时长 | 0.5s ≤ duration ≤ 10s | 自动 |
| 2 | 峰值电平 | -1 dBFS < peak < 0 dBFS（无爆音） | 自动：检测连续 ≥3 采样点达到满幅 |
| 3 | RMS 电平 | RMS > -40 dBFS（非静音） | 自动 |
| 4 | 有效语音占比 | VAD 检测语音段 ≥ 总时长 30% | 自动 |
| 5 | 标注完整 | speaker_id, label, category 均非空 | 自动 |
| 6 | 可懂度 | intelligibility ≥ 2 | 人工 |
| 7 | 标签正确 | 标注文本与说话人意图一致 | 人工（双人交叉验证） |

### 5.2 说话人级验收

| # | 检查项 | 通过标准 |
|---|--------|----------|
| 1 | 有效录音总数 | ≥ 80 条（不含 OOV） |
| 2 | 词表覆盖率 | ≥ 80% 的目标短语有 ≥ 2 条有效录音 |
| 3 | OOV 样本数 | ≥ 15 条 |
| 4 | 元数据完整 | severity, age, gender 均已填写 |
| 5 | 设备一致性 | 同一说话人使用同一设备完成 ≥ 90% 录音 |

### 5.3 整体数据集验收

| # | 检查项 | 通过标准 |
|---|--------|----------|
| 1 | 说话人数量 | ≥ 5 位（含 ≥ 2 位重度/极重度） |
| 2 | 严重度覆盖 | 至少覆盖 3 个严重度等级 |
| 3 | 性别平衡 | 男女比例在 3:7 ~ 7:3 之间 |
| 4 | Test 集规模 | 每位说话人 ≥ 20 条 Test 样本 |
| 5 | 标注一致性 | 双人标注一致率 (Cohen's κ) ≥ 0.85 |

---

## 6. 评测指标体系

### 6.1 识别性能指标

| 指标 | 定义 | 目标值 (MVP) |
|------|------|-------------|
| **Top-1 Accuracy** | 排名第一的候选命中正确短语的比例 | ≥ 50% |
| **Top-3 Accuracy** | 正确短语出现在前 3 候选中的比例 | ≥ 75% |
| **Top-3 Recall@轻度** | 轻度患者的 Top-3 命中率 | ≥ 85% |
| **Top-3 Recall@重度** | 重度患者的 Top-3 命中率 | ≥ 60% |

### 6.2 拒识性能指标

| 指标 | 定义 | 目标值 (MVP) |
|------|------|-------------|
| **OOV Rejection Rate** | OOV 语料被正确判为 unknown 的比例 | ≥ 80% |
| **False Rejection Rate** | 词表内语料被错误判为 unknown 的比例 | ≤ 15% |
| **False Acceptance Rate** | OOV 语料被错误识别为某条词表短语的比例 | ≤ 20% |

### 6.3 增量学习指标

| 指标 | 定义 | 目标值 |
|------|------|--------|
| **纠错提升率** | 纠错回灌后，同一短语下次识别的 Top-1 命中提升 | ≥ +10pp |
| **无退化** | 纠错后其他短语的 Top-3 Accuracy 不下降 | Δ ≤ -2pp |

### 6.4 可用性曲线（PRD §5.8）

以每条短语的训练样本数为 X 轴，对应性能为 Y 轴，绘制可用性曲线：

| 样本数/短语 | 预期 Top-1 | 预期 Top-3 | 说明 |
|------------|-----------|-----------|------|
| 2 | ≥ 35% | ≥ 55% | PRD 最低要求 |
| 5 | ≥ 50% | ≥ 75% | 推荐训练量 |
| 10 | ≥ 60% | ≥ 85% | 充分训练 |

### 6.5 延迟指标

| 指标 | 定义 | 目标值 |
|------|------|--------|
| **端到端延迟** | 录音结束 → Top-3 结果展示 | ≤ 3 秒（普通笔记本） |
| **TTS 延迟** | 点击复述 → 开始播放 | ≤ 1 秒 |

---

## 7. 现有数据清洗计划

### 7.1 现状分析

当前数据库中 4,944 条录音的状态：

| 说话人 | 录音数 | 性别 | 标注状态 |
|--------|--------|------|----------|
| DF0001 | 405 | F | ❌ 未标注 |
| DF0006 | 404 | F | ❌ 未标注 |
| DF0007 | 405 | F | ❌ 未标注 |
| DF0009 | 404 | F | ❌ 未标注 |
| DF0013 | 405 | F | ❌ 未标注 |
| DF0014 | 405 | F | ❌ 未标注 |
| DM0002 | 405 | M | ❌ 未标注 |
| DM0003 | 781 | M | ❌ 未标注 |
| DM0008 | 115 | M | ❌ 未标注 |
| DM0010 | 405 | M | ❌ 未标注 |
| DM0017 | 405 | M | ❌ 未标注 |
| DM0020 | 405 | M | ❌ 未标注 |

### 7.2 清洗步骤（可执行）

**Step 1：提取 speaker_id**（自动，从文件名解析）
```sql
UPDATE dysarthria_recordings
SET speaker_id = SUBSTRING(file_name FROM '^[A-Z]+[0-9]+')
WHERE speaker_id IS NULL;
```

**Step 2：音频质量自动检测**（Edge Function 批处理）
- 从存储桶下载音频 → 计算 duration、RMS、peak、SNR → 写回 `duration_ms` 和 `metadata.quality`
- 标记 `rejected` 的样本

**Step 3：文本标注**（人工）
- 导出 CSV（speaker_id, file_name, storage_path）
- 标注员逐条听音频，填写 `label` 和 `intelligibility`
- 采用双人交叉验证：两位标注员独立标注，不一致的由第三人仲裁

**Step 4：分类标注**（半自动）
- 根据 label 文本与默认词表做精确匹配 / 模糊匹配
- 匹配成功的自动填充 category
- 未匹配的人工分配至 10 个分类之一

**Step 5：数据集划分**
- 按 §4.3 的 SQL 执行 Train/Dev/Test 划分
- 生成划分报告，验证每个分区的覆盖率

**Step 6：验收检查**
- 运行 §5 验收标准的自动检查脚本
- 输出验收报告，标记未通过项

---

## 8. 新数据采集 SOP

### 8.1 采集前准备

1. 确认说话人知情同意（隐私协议签署）
2. 检查录音设备与环境是否达标（§2.2）
3. 准备录音词表（从应用导出 JSON）
4. 为说话人分配 ID（`DF`/`DM` + 4 位编号，递增）
5. 填写说话人元数据表（§2.3）

### 8.2 录音流程

```
1. 打开应用 → 训练页
2. 选择第一条短语
3. 协助者朗读短语（或展示文字）→ 说话人尝试表达
4. 点击录音 → 说话人说话 → 点击停止
5. 检查：时长 ≥ 0.5s？音量正常？→ 否则重录
6. 每条短语录 5 遍（建议值），最少 2 遍
7. 每 20 分钟休息 5 分钟（避免疲劳影响语音质量）
8. 在同一 session 内录 15~20 条 OOV 语料（随意说非词表内容）
```

### 8.3 采集后处理

1. 上传音频至存储桶（应用自动完成或批量上传脚本）
2. 在数据库中自动创建记录（file_name, storage_path, speaker_id）
3. 48 小时内完成人工标注（§3）
4. 标注完成后执行质量验收（§5.1）
5. 通过验收的样本进入正式数据集

---

## 9. 版本管理

| 版本 | 日期 | 变更 |
|------|------|------|
| v1.0 | 2026-02-24 | 初版，建立完整数据标准 |

---

## 附录 A：数据库字段完整定义

```sql
-- dysarthria_recordings 表字段说明
id              UUID        -- 主键，自动生成
file_name       TEXT        -- 音频文件名，格式：{speaker_id}_{seq}.wav
storage_path    TEXT        -- 存储桶内路径
speaker_id      TEXT        -- 说话人ID，如 DM0008
label           TEXT        -- 标注文本（说话人意图表达的内容）
category        TEXT        -- 分类：9 大类 + OOV
duration_ms     INTEGER     -- 有效语音时长（毫秒）
metadata        JSONB       -- 扩展元数据，包含：
                            --   severity: 严重度等级
                            --   quality: 质量标记（snr, clipping, intelligibility等）
                            --   split: 数据集划分（train/dev/test）
                            --   device: 录音设备
                            --   environment: 录音环境
                            --   annotator: 标注员ID
                            --   verified: 是否通过双人验证
created_at      TIMESTAMPTZ -- 录音时间
```

## 附录 B：快速验收 Checklist

```
□ speaker_id 已从 file_name 自动提取
□ 所有录音 duration_ms 已计算
□ label 标注完成率 ≥ 95%
□ category 标注完成率 ≥ 95%  
□ metadata.quality.intelligibility 标注完成
□ intelligibility ≤ 1 的样本已标记 rejected
□ 双人标注一致率 κ ≥ 0.85
□ Train/Dev/Test 划分已执行
□ 每位说话人 Test 集 ≥ 20 条
□ OOV 样本 ≥ 15 条/人
□ 验收报告已生成并存档
```
