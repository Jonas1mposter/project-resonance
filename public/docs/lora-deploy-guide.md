# ðŸŽ™ï¸ Whisper + LoRA å¾®è°ƒéƒ¨ç½²æŒ‡å—ï¼ˆå°ç™½ç‰ˆï¼‰

> æœ¬æŒ‡å—é€‚åˆæ²¡æœ‰ AI è®­ç»ƒç»éªŒçš„å¼€å‘è€…ï¼Œä¸€æ­¥æ­¥æ•™ä½ ä»Žé›¶å¼€å§‹ï¼Œä¸ºè„‘ç˜«æ‚£è€…å®šåˆ¶ä¸“å±žè¯­éŸ³è¯†åˆ«æ¨¡åž‹ã€‚
> é¢„è®¡æ€»è€—æ—¶ï¼š**1-2 å‘¨**ï¼ˆå«æ•°æ®é‡‡é›†ï¼‰

---

## ðŸ“‹ ä½ éœ€è¦å‡†å¤‡ä»€ä¹ˆï¼Ÿ

| ç‰©å“ | è¯´æ˜Ž | è´¹ç”¨ |
|------|------|------|
| äº‘ GPU æœåŠ¡å™¨ | ç”¨æ¥è®­ç»ƒæ¨¡åž‹ï¼ˆç§Ÿç”¨å³å¯ï¼Œä¸éœ€è¦ä¹°ï¼‰ | ~Â¥15-30/æ¬¡è®­ç»ƒ |
| æ‚£è€…å½•éŸ³ | 50-100 æ¡çŸ­è¯­çš„è¯­éŸ³å½•éŸ³ | å…è´¹ |
| ä¸€å°ç”µè„‘ | ä»»ä½•ç³»ç»Ÿéƒ½è¡Œï¼Œç”¨äºŽä¸Šä¼ æ–‡ä»¶å’Œæ“ä½œ | å·²æœ‰ |

---

## ç¬¬ä¸€æ­¥ï¼šç§Ÿä¸€å° GPU æœåŠ¡å™¨ ðŸ–¥ï¸

> ðŸ’¡ ç±»æ¯”ï¼šå°±åƒç§Ÿä¸€å°è¶…çº§ç”µè„‘ï¼Œç”¨å®Œå°±è¿˜ï¼ŒæŒ‰å°æ—¶è®¡è´¹ã€‚

### æŽ¨èå¹³å°ï¼ˆå›½å†…ï¼‰ï¼šAutoDL

1. æ‰“å¼€ [AutoDL å®˜ç½‘](https://www.autodl.com)ï¼Œæ³¨å†Œè´¦å·
2. ç‚¹å‡»ã€Œç§Ÿç”¨å®žä¾‹ã€â†’ é€‰æ‹© **RTX 3090**ï¼ˆå¤Ÿç”¨ä¸”ä¾¿å®œï¼‰
3. é•œåƒé€‰æ‹©ï¼šæœç´¢ `PyTorch 2.1`ï¼Œé€‰æ‹©å¸¦ **CUDA 12.1** çš„ç‰ˆæœ¬
4. å­˜å‚¨é€‰æ‹©ï¼š**æ•°æ®ç›˜ 20GB** å³å¯
5. ç‚¹å‡»ã€Œç«‹å³ç§Ÿç”¨ã€ï¼Œç­‰å¾…æœºå™¨å¯åŠ¨ï¼ˆçº¦ 1-2 åˆ†é’Ÿï¼‰

> âœ… æˆåŠŸæ ‡å¿—ï¼šçœ‹åˆ°æœºå™¨çŠ¶æ€å˜ä¸ºã€Œè¿è¡Œä¸­ã€ï¼Œæœ‰ä¸€ä¸ª SSH è¿žæŽ¥åœ°å€

---

## ç¬¬äºŒæ­¥ï¼šè¿žæŽ¥åˆ°æœåŠ¡å™¨ ðŸ’»

æœåŠ¡å™¨å¯åŠ¨åŽï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„ä¿¡æ¯ï¼š
```
SSH è¿žæŽ¥ï¼šssh -p 12345 root@123.456.789.0
å¯†ç ï¼šautodl
```

### Windows ç”¨æˆ·
1. ä¸‹è½½å¹¶å®‰è£… [MobaXterm](https://mobaxterm.mobatek.net/)ï¼ˆå…è´¹ç‰ˆå°±è¡Œï¼‰
2. ç‚¹å‡» Session â†’ SSHï¼Œå¡«å…¥ä¸Šé¢çš„åœ°å€å’Œç«¯å£
3. è¾“å…¥å¯†ç ï¼Œè¿›å…¥å‘½ä»¤è¡Œ

### Mac / Linux ç”¨æˆ·
ç›´æŽ¥æ‰“å¼€ã€Œç»ˆç«¯ã€ï¼Œç²˜è´´ SSH å‘½ä»¤ï¼Œè¾“å…¥å¯†ç 

> âœ… æˆåŠŸæ ‡å¿—ï¼šçœ‹åˆ°å‘½ä»¤è¡Œæç¤ºç¬¦ï¼Œç±»ä¼¼ `root@GPUæœåŠ¡å™¨:~#`

---

## ç¬¬ä¸‰æ­¥ï¼šå®‰è£…æ‰€éœ€å·¥å…· ðŸ”§

åœ¨æœåŠ¡å™¨å‘½ä»¤è¡Œé‡Œï¼Œ**ä¸€è¡Œä¸€è¡Œ**å¤åˆ¶ç²˜è´´ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# 1. æ›´æ–°ç³»ç»Ÿï¼ˆç­‰å¾… 1-2 åˆ†é’Ÿï¼‰
apt-get update -y

# 2. å®‰è£… Python ä¾èµ–
pip install transformers peft datasets soundfile librosa evaluate jiwer -q

# 3. éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸ
python -c "import transformers, peft; print('âœ… å®‰è£…æˆåŠŸï¼')"
```

> âœ… æˆåŠŸæ ‡å¿—ï¼šçœ‹åˆ° `âœ… å®‰è£…æˆåŠŸï¼`

---

## ç¬¬å››æ­¥ï¼šä¸Šä¼ ä½ çš„å½•éŸ³æ•°æ® ðŸ“

### æ•°æ®æ ¼å¼è¦æ±‚
- æ–‡ä»¶æ ¼å¼ï¼š**WAV**ï¼ˆä¸æ˜¯ MP3ï¼ï¼‰
- é‡‡æ ·çŽ‡ï¼š**16000 Hz**ï¼ˆ16kHzï¼‰
- å£°é“ï¼š**å•å£°é“**

### å‡†å¤‡æ•°æ®æ–‡ä»¶å¤¹ç»“æž„
åœ¨ä½ çš„ç”µè„‘ä¸Šåˆ›å»ºè¿™æ ·çš„æ–‡ä»¶å¤¹ï¼š
```
æˆ‘çš„è®­ç»ƒæ•°æ®/
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ 001_æˆ‘æƒ³å–æ°´.wav
â”‚   â”œâ”€â”€ 002_æˆ‘æƒ³åƒé¥­.wav
â”‚   â””â”€â”€ ... ï¼ˆ50-100 ä¸ªæ–‡ä»¶ï¼‰
â””â”€â”€ labels.json
```

### labels.json çš„æ ¼å¼ï¼ˆç”¨è®°äº‹æœ¬ç¼–è¾‘ï¼‰
```json
[
  {"audio": "audio/001_æˆ‘æƒ³å–æ°´.wav", "text": "æˆ‘æƒ³å–æ°´"},
  {"audio": "audio/002_æˆ‘æƒ³åƒé¥­.wav", "text": "æˆ‘æƒ³åƒé¥­"},
  {"audio": "audio/003_å¸®æˆ‘å¼€ç¯.wav",  "text": "å¸®æˆ‘å¼€ç¯"}
]
```

> ðŸ’¡ æç¤ºï¼šæ–‡ä»¶åé‡Œå¯ä»¥å¸¦ä¸­æ–‡ï¼Œä½†ä¸è¦æœ‰ç©ºæ ¼

### ä¸Šä¼ åˆ°æœåŠ¡å™¨
ä½¿ç”¨ MobaXterm çš„æ–‡ä»¶ç®¡ç†å™¨ï¼ˆå·¦ä¾§é¢æ¿ï¼‰ï¼ŒæŠŠæ•´ä¸ªæ–‡ä»¶å¤¹æ‹–è¿›åŽ»ï¼Œä¸Šä¼ åˆ° `/root/data/` ç›®å½•

---

## ç¬¬äº”æ­¥ï¼šéŸ³é¢‘æ ¼å¼è½¬æ¢ï¼ˆå¦‚æžœéœ€è¦ï¼‰ðŸ”„

å¦‚æžœä½ çš„å½•éŸ³æ˜¯ MP3 æˆ–å…¶ä»–æ ¼å¼ï¼Œè¿è¡Œè¿™ä¸ªè„šæœ¬è½¬æ¢ï¼š

```bash
# åˆ›å»ºè½¬æ¢è„šæœ¬
cat > /root/convert_audio.py << 'EOF'
import librosa
import soundfile as sf
import os

input_dir = "/root/data/audio_raw"   # åŽŸå§‹éŸ³é¢‘ç›®å½•
output_dir = "/root/data/audio"      # è¾“å‡ºç›®å½•

os.makedirs(output_dir, exist_ok=True)

for fname in os.listdir(input_dir):
    if fname.endswith(('.mp3', '.m4a', '.wav', '.ogg')):
        path = os.path.join(input_dir, fname)
        audio, _ = librosa.load(path, sr=16000, mono=True)
        out_name = os.path.splitext(fname)[0] + '.wav'
        sf.write(os.path.join(output_dir, out_name), audio, 16000)
        print(f"âœ… è½¬æ¢: {fname}")

print("å…¨éƒ¨è½¬æ¢å®Œæˆï¼")
EOF

python /root/convert_audio.py
```

---

## ç¬¬å…­æ­¥ï¼šè®­ç»ƒæ¨¡åž‹ ðŸš€

åˆ›å»ºè®­ç»ƒè„šæœ¬ï¼š

```bash
cat > /root/train.py << 'EOF'
import json, os, torch
from datasets import Dataset, Audio
from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer
from peft import LoraConfig, get_peft_model
import evaluate

# â”€â”€ é…ç½®åŒºï¼ˆåªéœ€ä¿®æ”¹è¿™é‡Œï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR   = "/root/data"          # æ•°æ®ç›®å½•
OUTPUT_DIR = "/root/lora_output"   # è¾“å‡ºç›®å½•
LANGUAGE   = "zh"                  # è¯­è¨€ï¼šä¸­æ–‡
STEPS      = 500                   # è®­ç»ƒæ­¥æ•°ï¼ˆæ•°æ®å°‘å¯æ”¹ä¸º 300ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

print("ðŸ“¦ åŠ è½½æ¨¡åž‹å’Œå¤„ç†å™¨...")
processor = WhisperProcessor.from_pretrained("openai/whisper-small", language=LANGUAGE, task="transcribe")
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")

# é…ç½® LoRA
lora_config = LoraConfig(
    r=16, lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05, bias="none"
)
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()  # ä¼šæ˜¾ç¤ºåªè®­ç»ƒäº† <1% å‚æ•°

# åŠ è½½æ•°æ®
print("ðŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")
with open(f"{DATA_DIR}/labels.json") as f:
    records = json.load(f)

for r in records:
    r["audio"] = os.path.join(DATA_DIR, r["audio"])

dataset = Dataset.from_list(records).cast_column("audio", Audio(sampling_rate=16000))

def preprocess(batch):
    audio = batch["audio"]["array"]
    inputs = processor(audio, sampling_rate=16000, return_tensors="pt")
    batch["input_features"] = inputs.input_features[0]
    batch["labels"] = processor.tokenizer(batch["text"]).input_ids
    return batch

print("âš™ï¸  é¢„å¤„ç†æ•°æ®...")
dataset = dataset.map(preprocess, remove_columns=["audio", "text"])
split = dataset.train_test_split(test_size=0.1)

# è®­ç»ƒå‚æ•°
args = Seq2SeqTrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=8,
    gradient_accumulation_steps=1,
    max_steps=STEPS,
    learning_rate=1e-3,
    warmup_steps=50,
    evaluation_strategy="steps",
    eval_steps=100,
    save_steps=100,
    logging_steps=25,
    predict_with_generate=True,
    fp16=torch.cuda.is_available(),
    report_to="none",
)

trainer = Seq2SeqTrainer(
    model=model,
    args=args,
    train_dataset=split["train"],
    eval_dataset=split["test"],
    tokenizer=processor.feature_extractor,
)

print("ðŸš€ å¼€å§‹è®­ç»ƒï¼ï¼ˆçº¦ 30 åˆ†é’Ÿï¼‰")
trainer.train()

print("ðŸ’¾ ä¿å­˜ LoRA æƒé‡...")
model.save_pretrained(OUTPUT_DIR)
processor.save_pretrained(OUTPUT_DIR)
print(f"âœ… è®­ç»ƒå®Œæˆï¼æƒé‡ä¿å­˜åœ¨ {OUTPUT_DIR}")
EOF

python /root/train.py
```

> â±ï¸ ç­‰å¾…çº¦ 30 åˆ†é’Ÿï¼Œä½ ä¼šçœ‹åˆ°è®­ç»ƒè¿›åº¦å’Œ loss ä¸æ–­ä¸‹é™

---

## ç¬¬ä¸ƒæ­¥ï¼šæµ‹è¯•æ¨¡åž‹æ•ˆæžœ âœ…

```bash
cat > /root/test.py << 'EOF'
import torch, soundfile as sf
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from peft import PeftModel

MODEL_DIR = "/root/lora_output"
TEST_AUDIO = "/root/data/audio/001_æˆ‘æƒ³å–æ°´.wav"  # æ¢æˆä½ çš„æµ‹è¯•æ–‡ä»¶

processor = WhisperProcessor.from_pretrained(MODEL_DIR)
base_model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
model = PeftModel.from_pretrained(base_model, MODEL_DIR)
model.eval()

audio, sr = sf.read(TEST_AUDIO)
inputs = processor(audio, sampling_rate=16000, return_tensors="pt")
with torch.no_grad():
    ids = model.generate(**inputs)
result = processor.batch_decode(ids, skip_special_tokens=True)[0]
print(f"è¯†åˆ«ç»“æžœï¼š{result}")
EOF

python /root/test.py
```

---

## ç¬¬å…«æ­¥ï¼šä¸‹è½½ LoRA æƒé‡æ–‡ä»¶ ðŸ“¥

è®­ç»ƒå®ŒæˆåŽï¼ŒæŠŠæƒé‡æ–‡ä»¶ä¸‹è½½åˆ°ä½ çš„ç”µè„‘ï¼š

ç”¨ MobaXterm æ–‡ä»¶ç®¡ç†å™¨ï¼Œæ‰¾åˆ° `/root/lora_output/` æ–‡ä»¶å¤¹ï¼Œä¸‹è½½è¿™äº›æ–‡ä»¶ï¼š
- `adapter_model.safetensors`ï¼ˆ~8MBï¼Œæœ€é‡è¦ï¼ï¼‰
- `adapter_config.json`
- `vocab.json`ã€`tokenizer.json` ç­‰

---

## ç¬¬ä¹æ­¥ï¼šéƒ¨ç½²æŽ¨ç†æœåŠ¡ ðŸŒ

### æ–¹æ¡ˆ Aï¼šç»§ç»­ç”¨ AutoDLï¼ˆæœ€ç®€å•ï¼‰

åœ¨åŒä¸€å°æœåŠ¡å™¨ä¸Šè¿è¡Œ FastAPIï¼š

```bash
pip install fastapi uvicorn python-multipart -q

cat > /root/server.py << 'EOF'
import torch, io, soundfile as sf
from fastapi import FastAPI, UploadFile
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from peft import PeftModel

app = FastAPI()

print("æ­£åœ¨åŠ è½½æ¨¡åž‹...")
processor = WhisperProcessor.from_pretrained("/root/lora_output")
base = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
model = PeftModel.from_pretrained(base, "/root/lora_output")
model.eval()
print("æ¨¡åž‹åŠ è½½å®Œæˆï¼")

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/transcribe")
async def transcribe(file: UploadFile):
    data = await file.read()
    audio, _ = sf.read(io.BytesIO(data))
    inputs = processor(audio, sampling_rate=16000, return_tensors="pt")
    with torch.no_grad():
        ids = model.generate(**inputs)
    text = processor.batch_decode(ids, skip_special_tokens=True)[0]
    return {"text": text}
EOF

# å¯åŠ¨æœåŠ¡ï¼ˆä¿æŒè¿è¡Œï¼Œç”¨ Ctrl+C åœæ­¢ï¼‰
uvicorn server:app --host 0.0.0.0 --port 8000
```

### èŽ·å–ä½ çš„æœåŠ¡åœ°å€

åœ¨ AutoDL æŽ§åˆ¶å°ï¼Œç‚¹å‡»ã€Œè‡ªå®šä¹‰æœåŠ¡ã€â†’ å¼€æ”¾ 8000 ç«¯å£ï¼Œä¼šå¾—åˆ°ä¸€ä¸ªå…¬ç½‘åœ°å€ï¼š
```
https://u12345-8000.proxy.xxxxxxx.com
```

---

## ç¬¬åæ­¥ï¼šè¿žæŽ¥åˆ° App ðŸ”—

å°†ä¸Šé¢çš„æœåŠ¡åœ°å€å¡«å…¥ App è®¾ç½®é¡µé¢çš„ã€Œè‡ªå®šä¹‰ ASR åœ°å€ã€ï¼š
```
https://u12345-8000.proxy.xxxxxxx.com/transcribe
```

---

## â“ å¸¸è§é—®é¢˜

**Qï¼šè®­ç»ƒæ—¶æç¤º CUDA out of memoryï¼Ÿ**
Aï¼šæŠŠ `per_device_train_batch_size` ä»Ž 8 æ”¹æˆ 4ï¼Œé‡æ–°è¿è¡Œ

**Qï¼šè®­ç»ƒå®Œè¯†åˆ«æ•ˆæžœè¿˜æ˜¯ä¸å¥½ï¼Ÿ**
Aï¼šæ£€æŸ¥å½•éŸ³è´¨é‡ï¼ˆæ˜¯å¦æœ‰å™ªéŸ³ï¼‰ï¼›å°è¯•å¢žåŠ å½•éŸ³æ•°é‡åˆ° 100 æ¡ä»¥ä¸Šï¼›æŠŠ `STEPS` å¢žåŠ åˆ° 800

**Qï¼šæœåŠ¡å™¨è´¹ç”¨æ€Žä¹ˆæŽ§åˆ¶ï¼Ÿ**
Aï¼šè®­ç»ƒå®ŒåŽç«‹å³ã€Œå…³æœºã€ï¼ˆä¸æ˜¯é‡Šæ”¾ï¼‰ï¼Œå…³æœºçŠ¶æ€åªæ”¶å­˜å‚¨è´¹ï¼ˆçº¦ Â¥0.1/å°æ—¶ï¼‰

**Qï¼šå¯ä»¥ç»™å¤šä¸ªæ‚£è€…ç”¨å—ï¼Ÿ**
Aï¼šå¯ä»¥ï¼æ¯ä¸ªæ‚£è€…åˆ†åˆ«è®­ç»ƒï¼Œä¿å­˜ä¸åŒçš„æƒé‡æ–‡ä»¶å¤¹ï¼ŒæŽ¨ç†æ—¶æŒ‰æ‚£è€… ID åŠ è½½å¯¹åº”æƒé‡

---

## ðŸ“Š é¢„æœŸæ•ˆæžœ

| æ•°æ®é‡ | é¢„æœŸè¯†åˆ«å‡†ç¡®çŽ‡ | ç›¸æ¯”é€šç”¨ ASR æå‡ |
|--------|--------------|-----------------|
| 30 æ¡  | ~55%         | +15%            |
| 50 æ¡  | ~70%         | +30%            |
| 100 æ¡ | ~80%         | +40%            |

---

## ðŸ’° è´¹ç”¨ä¼°ç®—

| é¡¹ç›® | è´¹ç”¨ |
|------|------|
| è®­ç»ƒä¸€æ¬¡ï¼ˆ3090ï¼Œçº¦ 1 å°æ—¶ï¼‰ | ~Â¥8 |
| æŽ¨ç†æœåŠ¡ï¼ˆ3090ï¼ŒæŒ‰æœˆï¼‰ | ~Â¥300-500 |
| æŽ¨ç†æœåŠ¡ï¼ˆæŒ‰éœ€å¯åŠ¨ï¼Œéž 7Ã—24ï¼‰ | ~Â¥50-100/æœˆ |

---

*Project Resonance â€” å…±é¸£é¡¹ç›® | è®©æ¯ä¸€ä¸ªå£°éŸ³éƒ½è¢«å¬è§*
