# MDSC 论文技术路径与关键参数详解

**论文**：Enhancing Voice Wake-Up for Dysarthria: MDSC Release and Customized System Design  
**聚焦**：技术架构、模型参数、训练配置，以及如何迁移到其他实验

---

## 1. 整体技术路径

```
输入音频 (16kHz, 单声道)
    ↓
全局 CMVN 归一化层 (Cepstral Mean & Variance Normalization)
    ↓
预处理模块 (维度映射 → 目标维度)
    ↓
骨干网络: DS-TCN (Depthwise Separable Temporal Convolutional Network)
    ↓
多关键词二分类器 (每个唤醒词一个独立的二分类头)
    ↓
输出: 每个唤醒词的 正/负 判定
```

### 1.1 为什么选择 DS-TCN？

| 特性 | 说明 |
|------|------|
| **轻量化** | 深度可分离卷积大幅减少参数量，适合端侧部署 |
| **时序建模** | TCN 擅长捕捉语音中的时序依赖关系 |
| **并行训练** | 相比 RNN/LSTM，TCN 可完全并行化训练 |
| **因果卷积** | 支持流式推理，适用于实时唤醒场景 |

---

## 2. 三阶段渐进式训练（核心方法论）

### 阶段 1: SIC（Speaker-Independent Control）

| 参数 | 值 |
|------|-----|
| 训练数据 | C-train（健康对照组训练集），6.4 小时 |
| 说话人数 | 21 人（健康） |
| 数据增强 | ✅ 频谱掩蔽 + 速度扰动 + 白噪声 |
| 输出 | 通用基线唤醒词检测模型 |
| 在 C-test 上的 Score | **0.0148**（FAR=0.0148, FRR=0.0000） |
| 在 D-test 上的 Score | **0.5339**（FAR=0.1630, FRR=0.3708） |

### 阶段 2: SID（Speaker-Independent Dysarthria）

| 参数 | 值 |
|------|-----|
| 初始化权重 | SIC 模型 |
| 训练数据 | D-train（构音障碍训练集），6.1 小时 |
| 说话人数 | 13 人（构音障碍） |
| 数据增强 | ✅ 同上三种增强 |
| 训练方式 | 基于 SIC 权重做 **fine-tuning** |
| 在 D-test 上的 Score | **0.3413**（FAR=0.1538, FRR=0.1875） |
| 相对 SIC 提升 | **36%** |

### 阶段 3: SDD（Speaker-Dependent Dysarthria）

| 参数 | 值 |
|------|-----|
| 初始化权重 | SID 模型 |
| 训练数据 | 个人注册语料（D1-enroll ~ D6-enroll） |
| 数据量 | **每人仅 3 分钟** |
| 正负样本比 | **1:5**（唤醒词 : 非唤醒词） |
| 数据增强 | ✅ 同上三种增强 |
| 训练方式 | 基于 SID 权重做 **fine-tuning** |
| 在 D-test 上的 Score | **0.1388**（FAR=0.0555, FRR=0.0833） |
| 相对 SIC 提升 | **74%** |

---

## 3. 关键超参数汇总

### 3.1 音频输入参数

| 参数 | 值 | 备注 |
|------|-----|------|
| 采样率 | **16,000 Hz** | 语音识别标准采样率 |
| 声道 | **单声道 (Mono)** | — |
| 录音距离 | **~20 cm** | 麦克风到嘴的距离 |
| 录音环境 | 安静室内 | — |

### 3.2 数据增强参数

| 增强策略 | 具体参数 | 作用 |
|----------|---------|------|
| **频谱掩蔽** | 频率轴 + 时间轴随机遮盖 | 增强对频谱缺失的鲁棒性 |
| **速度扰动** | 速度比率 ∈ **[0.9, 1.1]** | 模拟构音障碍患者语速不稳定 |
| **白噪声注入** | SNR ∈ **[-15, 15] dB** | 模拟真实环境噪声干扰 |

### 3.3 注册语料参数（通过消融实验确定）

| 参数 | 最佳值 | 实验范围 | 说明 |
|------|--------|---------|------|
| **总时长** | **3 分钟** | 1 min → 3 min | 1min 时 Score≈0.39，3min 时 Score≈0.14 |
| **正负样本比** | **1:5** | 1:0 → 1:8 | 纯正样本(1:0)效果最差；1:5 后趋于平缓 |

### 3.4 模型架构参数

| 组件 | 技术 | 说明 |
|------|------|------|
| 特征归一化 | **CMVN** (Global Cepstral Mean & Variance Normalization) | 将声学特征归一化为高斯分布 |
| 预处理 | 线性映射层 | 输入特征维度 → 模型目标维度 |
| 骨干网络 | **DS-TCN** (Depthwise Separable Temporal Convolutional Network) | 轻量级时序卷积网络 |
| 分类头 | **10 个独立二分类器** | 每个唤醒词一个，支持多关键词场景 |
| 工具包 | **WeKWS** (WeNet Keyword Spotting Toolkit) | 开源框架 |

### 3.5 评估指标

| 指标 | 公式 | 说明 |
|------|------|------|
| **FAR** (False Alarm Rate) | N_FA / N_non-wake | 非唤醒词被误识别为唤醒词的比率 |
| **FRR** (False Reject Rate) | N_FR / N_wake | 唤醒词未被识别的比率 |
| **Score** | FAR + FRR | 综合评分，越低越好 |

---

## 4. 数据集 MDSC 参数

| 参数 | 值 |
|------|-----|
| 总录音数 | **18,630 条** |
| 总时长 | **17 小时** |
| 健康对照 (Control) | 10,125 条，7.6 小时，25 人（13女12男） |
| 构音障碍 (Dysarthria) | 8,505 条，9.4 小时，21 人（12女9男） |
| 唤醒词数量 | **10 个**，每词重复 **5 遍**（不同语速） |
| 非唤醒词 | **355 条**（固定指令 + 自由指令 + 家居指令） |
| 单人文本列表 | **295 条不重复语句** |
| 注册语料 | 每人 **3 分钟**（不入任何训练/测试子集） |

### 数据划分

| 子集 | Control ||| Dysarthria |||
|------|---------|-----|------|------------|-----|------|
| | Train | Dev | Test | Train | Dev | Test |
| 时长 (h) | 6.4 | 0.6 | 0.6 | 6.1 | 0.9 | 2.4 |
| 说话人 | 21 | 2 | 2 | 13 | 2 | 6 |

**关键规则**：各子集间**说话人无重叠**。

---

## 5. 个体级实验结果

| 个体 | 可懂度排名 | SIC Score | SID Score | SDD Score | SID 提升 | SDD 提升 |
|------|-----------|-----------|-----------|-----------|---------|---------|
| D1 | 最高 | 低 | ⚠️ 退化 | 显著改善 | 负面 | 正面 |
| D2 | 高 | — | 改善 | 显著改善 | — | — |
| D3 | 中 | — | **51%↑** | 显著改善 | 最大获益 | — |
| D4 | 中 | — | **67%↑** | 显著改善 | 最大获益 | — |
| D5 | 低 | — | 改善 | 改善 | — | — |
| D6 | 最低 | 高 | 有限改善 | 有限改善 | — | 仍然困难 |

### 关键发现

1. **D1 在 SID 阶段退化** — 高可懂度患者的发音特征与其他患者差异大，群体微调反而有害
2. **D3/D4 获益最大** — 中度患者最能代表群体平均特征
3. **D6 始终困难** — 极重度患者即使个人定制仍效果有限
4. **SDD 对可懂度不敏感** — 个人定制模型的性能不受可懂度等级显著影响

---

## 6. 迁移到其他实验的操作指南

### 6.1 如果你的任务是唤醒词/关键词检测

```
直接复用路径：
1. 安装 WeKWS 工具包
2. 准备数据：健康语音(C) + 目标群体语音(D) + 个人注册语料(enroll)
3. 三阶段训练：C-train → D-train → enroll fine-tune
4. 数据增强：频谱掩蔽 + 速度扰动[0.9,1.1] + 白噪声[-15,15]dB
5. 注册语料：3分钟，正负比 1:5
6. 评估：FAR + FRR = Score
```

### 6.2 如果你的任务是 ASR（语音识别）

| 论文方法 | 迁移方式 |
|----------|---------|
| 三阶段渐进训练 | 替换为：通用 ASR 预训练 → 病理语音微调 → 个人 LoRA 适配 |
| DS-TCN 骨干 | 替换为：Whisper / Paraformer 等 ASR 模型 |
| 二分类头 | 替换为：序列到序列解码器 |
| CMVN 归一化 | ✅ 直接复用 |
| 数据增强三件套 | ✅ 直接复用（参数相同） |
| 注册语料 3min + 1:5 | ✅ 直接复用（个人适配数据量参考） |

### 6.3 如果你的数据量不同

| 你的数据量 | 建议调整 |
|-----------|---------|
| < 3 小时（整体） | 加大数据增强力度，速度扰动扩到 [0.8, 1.2] |
| 3-10 小时 | 与论文规模接近，直接复用参数 |
| > 10 小时 | 可适当减少增强幅度，尝试更大模型 |
| 个人注册 < 1 min | 效果会大幅下降（Score≈0.39 vs 0.14） |
| 个人注册 1-3 min | 线性提升区间，尽量收集到 3 min |
| 个人注册 > 3 min | 收益递减，不必过多 |

### 6.4 可懂度评估框架复用

```
步骤 1: 主观可懂度
  5 位标注员 → 各自转录 → 与标准文本对比 → 取平均准确率

步骤 2: 客观可懂度
  开源 ASR (Paraformer/WeNet) → 转录 → 计算 WER/CER

步骤 3: 交叉验证
  主观 vs 客观 → 验证一致性 → 按可懂度分组报告性能
```

---

## 7. 论文使用的工具与依赖

| 工具 | 用途 | 链接/备注 |
|------|------|----------|
| **WeKWS** | 唤醒词检测工具包（基于 WeNet） | 开源，含 DS-TCN 实现 |
| **Paraformer** | 客观可懂度评估用 ASR | 阿里达摩院开源 |
| **WeNet** | 客观可懂度评估用 ASR | 出门问问开源 |
| **MDSC 数据集** | 训练与评估 | https://www.aishelltech.com/AISHELL_6B |

---

*Project Resonance — 共鸣项目*
