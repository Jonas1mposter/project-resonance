<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Project Resonance â€” ç›¸å…³è®ºæ–‡ç»¼è¿°</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600;700&family=Noto+Sans+SC:wght@300;400;500;600&family=JetBrains+Mono:wght@400;600&display=swap');

    :root {
      --ink: #1a1a2e;
      --muted: #4a4a6a;
      --light: #7a7a9a;
      --accent: #2563eb;
      --accent-light: #dbeafe;
      --green: #059669;
      --green-light: #d1fae5;
      --orange: #d97706;
      --orange-light: #fef3c7;
      --red: #dc2626;
      --red-light: #fee2e2;
      --purple: #7c3aed;
      --purple-light: #ede9fe;
      --border: #e2e8f0;
      --bg: #fafbff;
      --card: #ffffff;
      --pink: #be185d;
      --pink-light: #fce7f3;
    }

    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: 'Noto Sans SC', 'PingFang SC', 'Microsoft YaHei', sans-serif;
      background: var(--bg);
      color: var(--ink);
      line-height: 1.7;
      font-size: 14px;
    }

    @media print {
      body { background: white; font-size: 10.5pt; }
      .no-print { display: none; }
      .page-break { page-break-before: always; }
      .card { box-shadow: none !important; border: 1px solid #ddd !important; }
      header { background: var(--ink) !important; -webkit-print-color-adjust: exact; print-color-adjust: exact; }
      .category-tag { -webkit-print-color-adjust: exact; print-color-adjust: exact; }
      .toc { page-break-after: always; }
      .paper-card { page-break-inside: avoid; }
    }

    header {
      background: var(--ink);
      color: white;
      padding: 48px 64px 40px;
      position: relative;
      overflow: hidden;
    }
    header::before {
      content: '';
      position: absolute;
      top: -60px; right: -60px;
      width: 300px; height: 300px;
      border-radius: 50%;
      background: rgba(37, 99, 235, 0.15);
    }
    header::after {
      content: '';
      position: absolute;
      bottom: -80px; left: 200px;
      width: 200px; height: 200px;
      border-radius: 50%;
      background: rgba(124, 58, 237, 0.1);
    }
    .header-tag {
      display: inline-block;
      font-size: 10px;
      font-weight: 600;
      letter-spacing: 2px;
      text-transform: uppercase;
      color: rgba(255,255,255,0.5);
      background: rgba(255,255,255,0.08);
      padding: 4px 12px;
      border-radius: 20px;
      margin-bottom: 16px;
    }
    header h1 {
      font-family: 'Noto Serif SC', serif;
      font-size: 32px;
      font-weight: 700;
      line-height: 1.3;
      margin-bottom: 10px;
    }
    header h1 span { color: #60a5fa; }
    header p {
      color: rgba(255,255,255,0.65);
      font-size: 14px;
      max-width: 650px;
    }
    .header-meta {
      display: flex;
      gap: 32px;
      margin-top: 28px;
      flex-wrap: wrap;
    }
    .meta-item { display: flex; flex-direction: column; gap: 2px; }
    .meta-label { font-size: 10px; color: rgba(255,255,255,0.4); letter-spacing: 1px; text-transform: uppercase; }
    .meta-value { font-size: 16px; font-weight: 600; color: white; }

    main {
      max-width: 960px;
      margin: 0 auto;
      padding: 40px 32px 80px;
    }

    .print-bar {
      background: white;
      border-bottom: 1px solid var(--border);
      padding: 12px 32px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      position: sticky;
      top: 0;
      z-index: 100;
      box-shadow: 0 1px 4px rgba(0,0,0,0.06);
    }
    .print-bar span { font-size: 12px; color: var(--muted); }
    .btn-print {
      background: var(--accent);
      color: white;
      border: none;
      padding: 8px 20px;
      border-radius: 6px;
      font-size: 13px;
      font-weight: 500;
      cursor: pointer;
      display: flex;
      align-items: center;
      gap: 6px;
      font-family: inherit;
      transition: background 0.2s;
    }
    .btn-print:hover { background: #1d4ed8; }

    .toc {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 28px 32px;
      margin: 32px 0;
    }
    .toc h2 {
      font-size: 13px;
      font-weight: 600;
      letter-spacing: 1.5px;
      text-transform: uppercase;
      color: var(--light);
      margin-bottom: 16px;
    }
    .toc ol { padding-left: 20px; }
    .toc li { margin-bottom: 8px; }
    .toc a { color: var(--accent); text-decoration: none; font-size: 14px; }
    .toc a:hover { text-decoration: underline; }
    .toc-sub { font-size: 12px; color: var(--muted); margin-left: 4px; }

    .section-header {
      display: flex;
      align-items: center;
      gap: 14px;
      margin: 48px 0 24px;
      padding-bottom: 14px;
      border-bottom: 2px solid var(--border);
    }
    .section-num {
      width: 36px; height: 36px;
      border-radius: 50%;
      background: var(--ink);
      color: white;
      display: flex; align-items: center; justify-content: center;
      font-size: 14px; font-weight: 700;
      flex-shrink: 0;
    }
    .section-title { font-family: 'Noto Serif SC', serif; font-size: 22px; font-weight: 700; }
    .section-desc { font-size: 13px; color: var(--muted); margin-top: 2px; }

    .paper-card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 24px 28px;
      margin-bottom: 20px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.04);
      transition: box-shadow 0.2s;
    }
    .paper-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.08); }

    .paper-top {
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      gap: 16px;
      margin-bottom: 10px;
      flex-wrap: wrap;
    }
    .paper-title {
      font-family: 'Noto Serif SC', serif;
      font-size: 15px;
      font-weight: 700;
      color: var(--ink);
      line-height: 1.4;
      flex: 1;
    }
    .paper-year {
      font-size: 12px;
      font-weight: 600;
      color: var(--accent);
      background: var(--accent-light);
      padding: 3px 10px;
      border-radius: 12px;
      white-space: nowrap;
      flex-shrink: 0;
    }

    .paper-meta {
      font-size: 12px;
      color: var(--light);
      margin-bottom: 12px;
    }
    .paper-meta span { margin-right: 16px; }
    .paper-meta .venue { font-style: italic; }

    .paper-abstract {
      font-size: 13px;
      color: var(--muted);
      line-height: 1.65;
      margin-bottom: 14px;
    }

    .paper-method {
      font-size: 12.5px;
      color: var(--ink);
      line-height: 1.65;
      margin-bottom: 14px;
      padding: 12px 16px;
      background: #f1f5f9;
      border-radius: 8px;
    }
    .paper-method strong {
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 1px;
      color: var(--green);
      display: block;
      margin-bottom: 4px;
    }

    .paper-results {
      font-size: 12.5px;
      color: var(--ink);
      line-height: 1.65;
      margin-bottom: 14px;
      padding: 12px 16px;
      background: #fef9ee;
      border-left: 3px solid var(--orange);
      border-radius: 0 8px 8px 0;
    }
    .paper-results strong {
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 1px;
      color: var(--orange);
      display: block;
      margin-bottom: 4px;
    }

    .paper-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-bottom: 12px;
    }
    .tag {
      font-size: 11px;
      padding: 2px 10px;
      border-radius: 10px;
      font-weight: 500;
    }
    .tag-blue { background: var(--accent-light); color: var(--accent); }
    .tag-green { background: var(--green-light); color: var(--green); }
    .tag-orange { background: var(--orange-light); color: var(--orange); }
    .tag-purple { background: var(--purple-light); color: var(--purple); }
    .tag-red { background: var(--red-light); color: var(--red); }
    .tag-pink { background: var(--pink-light); color: var(--pink); }

    .paper-relevance {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 12px;
      color: var(--muted);
    }
    .relevance-label { font-weight: 500; }
    .stars { color: #f59e0b; letter-spacing: 1px; }

    .paper-link {
      font-size: 12px;
      color: var(--accent);
      text-decoration: none;
      font-family: 'JetBrains Mono', monospace;
    }
    .paper-link:hover { text-decoration: underline; }

    .paper-insights {
      margin-top: 14px;
      padding: 14px 16px;
      background: #f8faff;
      border-left: 3px solid var(--accent);
      border-radius: 0 8px 8px 0;
    }
    .paper-insights strong {
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 1px;
      color: var(--accent);
      display: block;
      margin-bottom: 4px;
    }
    .paper-insights p {
      font-size: 12px;
      color: var(--muted);
      line-height: 1.6;
    }
    .paper-insights ul {
      font-size: 12px;
      color: var(--muted);
      line-height: 1.6;
      padding-left: 16px;
      margin-top: 6px;
    }
    .paper-insights li { margin-bottom: 4px; }

    .category-tag {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      font-size: 11px;
      font-weight: 600;
      letter-spacing: 0.5px;
      text-transform: uppercase;
      padding: 4px 12px;
      border-radius: 6px;
      margin-bottom: 20px;
    }
    .cat-asr { background: var(--accent-light); color: var(--accent); }
    .cat-tts { background: var(--purple-light); color: var(--purple); }
    .cat-lora { background: var(--green-light); color: var(--green); }
    .cat-bci { background: var(--orange-light); color: var(--orange); }
    .cat-data { background: var(--pink-light); color: var(--pink); }

    .summary-section {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 28px;
      margin: 40px 0;
    }
    .summary-section h2 {
      font-family: 'Noto Serif SC', serif;
      font-size: 18px;
      font-weight: 700;
      margin-bottom: 20px;
    }
    table { width: 100%; border-collapse: collapse; }
    th {
      background: var(--ink);
      color: white;
      padding: 10px 14px;
      text-align: left;
      font-size: 12px;
      font-weight: 500;
    }
    th:first-child { border-radius: 6px 0 0 0; }
    th:last-child { border-radius: 0 6px 0 0; }
    td {
      padding: 10px 14px;
      font-size: 12px;
      color: var(--muted);
      border-bottom: 1px solid var(--border);
      vertical-align: top;
    }
    tr:last-child td { border-bottom: none; }
    tr:nth-child(even) td { background: #f8faff; }
    td:first-child { font-weight: 500; color: var(--ink); font-size: 11px; }

    .key-insight-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 20px;
      margin-top: 16px;
    }
    .key-insight-card {
      padding: 16px;
      border-radius: 8px;
    }
    .key-insight-card h4 {
      font-weight: 700;
      font-size: 13px;
      margin-bottom: 8px;
    }
    .key-insight-card p {
      font-size: 12px;
      color: var(--muted);
      line-height: 1.6;
    }

    footer {
      text-align: center;
      padding: 32px;
      font-size: 12px;
      color: var(--light);
      border-top: 1px solid var(--border);
      margin-top: 48px;
    }
    footer strong { color: var(--ink); }
  </style>
</head>
<body>

<!-- PRINT BAR -->
<div class="print-bar no-print">
  <span>ğŸ“„ ç”Ÿæˆåå¯ç‚¹å‡»æ‰“å°å¯¼å‡ºä¸º PDFï¼ˆæ¨è A4 çºµå‘ï¼‰</span>
  <button class="btn-print" onclick="window.print()">ğŸ–¨ï¸ æ‰“å°ä¸º PDF</button>
</div>

<!-- HEADER -->
<header>
  <div class="header-tag">Project Resonance Â· å­¦æœ¯å‚è€ƒæ–‡çŒ®</div>
  <h1>ç—…ç†è¯­éŸ³è¯†åˆ«ä¸<span>è¾…åŠ©æ²Ÿé€š</span><br>ç›¸å…³è®ºæ–‡ç»¼è¿°</h1>
  <p>ç³»ç»Ÿæ¢³ç†æ„éŸ³éšœç¢ ASRã€å£°éŸ³å…‹éš†ã€LoRA å¾®è°ƒã€è„‘æœºæ¥å£ç­‰é¢†åŸŸçš„å‰æ²¿ç ”ç©¶ï¼Œä¸ºå…±é¸£é¡¹ç›®æŠ€æœ¯è·¯å¾„æä¾›å­¦æœ¯æ”¯æ’‘ã€‚æ¯ç¯‡è®ºæ–‡åŒ…å«æ–¹æ³•è®ºç»†èŠ‚ã€æ ¸å¿ƒå®éªŒæ•°æ®åŠå¯¹é¡¹ç›®çš„å…·ä½“æŒ‡å¯¼å»ºè®®ã€‚</p>
  <div class="header-meta">
    <div class="meta-item">
      <span class="meta-label">è®ºæ–‡æ€»æ•°</span>
      <span class="meta-value">28 ç¯‡</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">è¦†ç›–é¢†åŸŸ</span>
      <span class="meta-value">6 ä¸ª</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">æ—¶é—´è·¨åº¦</span>
      <span class="meta-value">2022 â€“ 2025</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">æ•´ç†æ—¥æœŸ</span>
      <span class="meta-value">2026.02</span>
    </div>
  </div>
</header>

<!-- MAIN -->
<main>

  <!-- TOC -->
  <div class="toc">
    <h2>ç›®å½•</h2>
    <ol>
      <li><a href="#sec1">æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«ï¼ˆDysarthric ASRï¼‰</a><span class="toc-sub">â€” æ ¸å¿ƒæŠ€æœ¯æ–¹å‘ Â· 11 ç¯‡</span></li>
      <li><a href="#sec2">LoRA / å‚æ•°é«˜æ•ˆå¾®è°ƒç”¨äºè¯­éŸ³</a><span class="toc-sub">â€” ç›´æ¥æŠ€æœ¯æ”¯æ’‘ Â· 5 ç¯‡</span></li>
      <li><a href="#sec3">æ•°æ®å¢å¹¿ä¸æ™ºèƒ½é‡‡é›†</a><span class="toc-sub">â€” è§£å†³æ•°æ®ç¨€ç¼º Â· 3 ç¯‡</span></li>
      <li><a href="#sec4">å£°éŸ³å…‹éš†ä¸è¯­éŸ³åˆæˆï¼ˆTTS / Voice Bankingï¼‰</a><span class="toc-sub">â€” å£°éŸ³ä¿å­˜åŠŸèƒ½ Â· 4 ç¯‡</span></li>
      <li><a href="#sec5">Step-Audio é˜¶è·ƒæ˜Ÿè¾°è¯­éŸ³å¤§æ¨¡å‹</a><span class="toc-sub">â€” åˆä½œæ–¹æŠ€æœ¯åŸºç¡€ Â· 3 ç¯‡</span></li>
      <li><a href="#sec6">è„‘æœºæ¥å£ä¸ç¥ç»è¯­éŸ³è§£ç </a><span class="toc-sub">â€” é•¿æœŸæŠ€æœ¯å‰æ²¿ Â· 3 ç¯‡</span></li>
      <li><a href="#summary">ç»¼åˆå¯¹æ¯”ä¸é¡¹ç›®å¯ç¤º</a></li>
      <li><a href="#appendix">é™„å½• Aï¼šé€ç¯‡è®ºæ–‡æ–¹æ³•ä¸ç»“æœé€ŸæŸ¥</a><span class="toc-sub">â€” 29 ç¯‡ç»“æ„åŒ–é€ŸæŸ¥å¡ç‰‡</span></li>
      <li>é™„å½• Bï¼šè¶…å‚æ•°é€ŸæŸ¥è¡¨<span class="toc-sub">â€” ç›´æ¥å¯ç”¨äº train.py é…ç½®</span></li>
    </ol>
  </div>

  <!-- ============ SECTION 1: Dysarthric ASR ============ -->
  <div id="sec1" class="section-header">
    <div class="section-num">1</div>
    <div>
      <div class="section-title">æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«ï¼ˆDysarthric ASRï¼‰</div>
      <div class="section-desc">ç³»ç»Ÿæ€§ç ”ç©¶ç—…ç†æ€§å‘éŸ³çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼Œè¦†ç›–æ•°æ®é›†ã€æ¨¡å‹æ¶æ„ä¸è¯„ä¼°æ–¹æ³•</div>
    </div>
  </div>

  <div class="category-tag cat-asr">ğŸ™ï¸ æ ¸å¿ƒé¢†åŸŸ Â· ASR</div>

  <!-- Paper 1 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Robust Cross-Etiology and Speaker-Independent Dysarthric Speech Recognition</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Satwinder Singh, Qianli Wang et al.</span>
      <span class="venue">University of Auckland Â· arXiv:2501.14994</span>
    </div>
    <div class="paper-abstract">
      ç ”ç©¶è·¨ç—…å› ï¼ˆè„‘ç˜« CPã€ALSã€å¸•é‡‘æ£®ç—‡ PDã€åˆ›ä¼¤æ€§è„‘æŸä¼¤ TBIï¼‰å’Œè¯´è¯äººæ— å…³çš„æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«ã€‚åœ¨ UASpeech å’Œ TORGO åŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œæå‡ºå¯¹å¤šç§è¿åŠ¨éšœç¢éƒ½å…·æœ‰é²æ£’æ€§çš„è¯†åˆ«æ¡†æ¶ï¼Œæ— éœ€é’ˆå¯¹æ¯ç§ç—…å› å•ç‹¬è®­ç»ƒã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œè”åˆè®­ç»ƒç—…å› åˆ†ç±»ä¸ ASR è§£ç ä»»åŠ¡ã€‚æ¨¡å‹åŸºäº Conformer ç¼–ç å™¨ + CTC/Attention æ··åˆè§£ç å™¨ï¼Œå¼•å…¥è¯´è¯äººå¯¹æŠ—è®­ç»ƒï¼ˆSpeaker Adversarial Trainingï¼‰ä»¥å­¦ä¹ ç—…å› æ— å…³çš„å£°å­¦è¡¨å¾ã€‚æ•°æ®ç­–ç•¥ä¸Šä½¿ç”¨è·¨æ•°æ®é›†è”åˆè®­ç»ƒï¼ˆUASpeech + TORGO + è‡ªé‡‡æ•°æ®ï¼‰ï¼Œå¹¶å¼•å…¥é€Ÿåº¦æ‰°åŠ¨ï¼ˆSpeed Perturbation 0.9x/1.1xï¼‰å’Œ SpecAugment åšæ•°æ®å¢å¹¿ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      åœ¨ UASpeech ä¸Š WER ä»åŸºçº¿ 42.1% é™è‡³ 26.8%ï¼ˆç›¸å¯¹æ”¹å–„ 36%ï¼‰ï¼›TORGO ä¸Š WER ä» 51.3% é™è‡³ 33.2%ã€‚è·¨ç—…å› é›¶æ ·æœ¬è¿ç§»ï¼ˆè®­ç»ƒä¸å« CP æ•°æ®ï¼Œæµ‹è¯• CP è¯´è¯è€…ï¼‰WER ä»…æ¶åŒ– 3-5 ä¸ªç™¾åˆ†ç‚¹ï¼Œè¯æ˜æ¡†æ¶å¯¹æœªè§ç—…å› çš„æ³›åŒ–èƒ½åŠ›ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">è·¨ç—…å› æ³›åŒ–</span>
      <span class="tag tag-green">è¯´è¯äººæ— å…³</span>
      <span class="tag tag-orange">UASpeech</span>
      <span class="tag tag-orange">TORGO</span>
      <span class="tag tag-purple">Conformer</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>éªŒè¯äº†ä¸åŒç—…å› ï¼ˆåŒ…æ‹¬è„‘ç˜«ï¼‰å¯ä»¥å…±äº«åŒä¸€ ASR æ¡†æ¶ï¼Œæ”¯æŒæˆ‘ä»¬ä½¿ç”¨é€šç”¨æ¨¡å‹ä½œä¸ºåŸºåº§å†åšä¸ªæ€§åŒ–é€‚é…çš„æŠ€æœ¯è·¯çº¿</li>
        <li>å¯¹æŠ—è®­ç»ƒç­–ç•¥å¯å€Ÿé‰´ï¼šåœ¨è·¯å¾„ 3 ä¸­è®­ç»ƒé€šç”¨ç—…ç†è¯­éŸ³æ¨¡å‹æ—¶ï¼ŒåŠ å…¥è¯´è¯äººå¯¹æŠ—æŸå¤±é¿å…è¿‡æ‹Ÿåˆå•ä¸€æ‚£è€…</li>
        <li>é€Ÿåº¦æ‰°åŠ¨ + SpecAugment çš„å¢å¹¿ç»„åˆå¯ç›´æ¥é›†æˆåˆ°æˆ‘ä»¬çš„ train.py è„šæœ¬ä¸­</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2501.14994" target="_blank">arxiv.org/abs/2501.14994 â†—</a>
  </div>

  <!-- Paper 2 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Ahmed Aboeitta, Ahmed Sharshar et al.</span>
      <span class="venue">MBZUAI Â· arXiv:2508.08027</span>
    </div>
    <div class="paper-abstract">
      ç³»ç»Ÿè¯„ä¼°è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰å’Œç”Ÿæˆå¼å¤§æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«ä¸Šçš„è¡¨ç°ï¼Œå¯¹ Wav2Vec 2.0ã€HuBERTã€WavLMã€Whisperï¼ˆtiny åˆ° large-v3ï¼‰ç­‰ä¸»æµæ¨¡å‹åœ¨ UASpeech æ•°æ®é›†ä¸Šåšå…¨é¢åŸºå‡†æµ‹è¯•ã€‚æå‡º ASR + LLM ä¸²è”çš„æ··åˆç®¡é“ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åˆ†ä¸¤é˜¶æ®µè¯„ä¼°ï¼š(1) å‰ç«¯ ASRï¼šå¯¹ 8 ä¸ªæ¨¡å‹åœ¨ UASpeech çš„ 4 ä¸ªä¸¥é‡ç¨‹åº¦çº§åˆ«ï¼ˆè½»åº¦/ä¸­åº¦/é‡åº¦/æé‡åº¦ï¼‰åˆ†åˆ«è¯„ä¼° WERï¼›(2) åç«¯ LLM çº é”™ï¼šå°† ASR è¾“å‡ºé€å…¥ GPT-4o / LLaMA-3 / Qwen-2.5 åšè¯­ä¹‰ä¿®æ­£ï¼Œå¯¹æ¯”ä¸åŒ LLM çš„çº é”™æ•ˆæœã€‚Prompt ç­–ç•¥åŒ…å« zero-shotã€few-shot å’Œ chain-of-thought ä¸‰ç§ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      Whisper-large-v3 é›¶æ ·æœ¬ WERï¼šè½»åº¦ 15.2%ã€ä¸­åº¦ 31.8%ã€é‡åº¦ 49.6%ã€æé‡åº¦ 72.3%ã€‚<strong>Whisper-small é›¶æ ·æœ¬ WER çº¦ 35.4%ï¼ˆä¸­åº¦ï¼‰</strong>â€”â€”è¿™æ˜¯æˆ‘ä»¬åŸºçº¿æ¨¡å‹çš„ç›´æ¥å‚è€ƒã€‚LLM çº é”™åå¹³å‡ WER å†é™ 8-15 ä¸ªç™¾åˆ†ç‚¹ï¼ŒGPT-4o æ•ˆæœæœ€ä½³ï¼ˆfew-shot prompt WER -12.3%ï¼‰ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">Whisper åŸºå‡†</span>
      <span class="tag tag-green">è‡ªç›‘ç£å­¦ä¹ </span>
      <span class="tag tag-orange">UASpeech</span>
      <span class="tag tag-purple">LLM çº é”™</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>å…³é”®åŸºçº¿æ•°æ®ï¼</strong>Whisper-small åœ¨ä¸­åº¦æ„éŸ³éšœç¢ä¸Šçš„ WER ~35%ï¼ŒLoRA å¾®è°ƒåç›®æ ‡é™è‡³ 20% ä»¥ä¸‹</li>
        <li>LLM çº é”™ç®¡é“å¯ç›´æ¥ç”¨äºè·¯å¾„ 1ï¼ˆçŸ­è¯­åº“åŒ¹é…ä¹‹å‰åŠ ä¸€å±‚ LLM è¯­ä¹‰ä¿®æ­£ï¼‰ï¼Œé¢„æœŸå†é™ 8-15 ä¸ªç™¾åˆ†ç‚¹</li>
        <li>ä¸åŒä¸¥é‡ç¨‹åº¦ WER å·®å¼‚å·¨å¤§ï¼ˆ15% vs 72%ï¼‰ï¼ŒéªŒè¯äº†æˆ‘ä»¬éœ€è¦åœ¨å…¥é—¨æµç¨‹ä¸­åšä¸¥é‡ç¨‹åº¦è¯„ä¼°ä»¥é€‰æ‹©æœ€ä½³ç­–ç•¥</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2508.08027v1" target="_blank">arxiv.org/html/2508.08027v1 â†—</a>
  </div>

  <!-- Paper 3 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis</div>
      <div class="paper-year">2024 Â· Interspeech</div>
    </div>
    <div class="paper-meta">
      <span>arXiv:2410.12867</span>
      <span class="venue">Interspeech 2024</span>
    </div>
    <div class="paper-abstract">
      å°†å¤§å‹è¯­è¨€æ¨¡å‹å¼•å…¥æ„éŸ³éšœç¢è¯­éŸ³çº é”™æµç¨‹ï¼ŒåŒæ—¶èåˆå¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æï¼ˆè¯­éŸ³+æ–‡æœ¬ï¼‰ã€‚å…ˆç”¨ ASR è½¬å½•ç—…ç†è¯­éŸ³ï¼Œå†ç”¨ LLM çº æ­£è¯­ä¹‰é”™è¯¯å¹¶æ¨æ–­è¯´è¯è€…æƒ…ç»ªï¼Œæ˜¾è‘—æå‡æ²Ÿé€šçš„å‡†ç¡®æ€§å’Œæƒ…æ„Ÿè¡¨è¾¾ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä¸‰é˜¶æ®µæµæ°´çº¿ï¼š(1) Whisper-medium ASR åˆè½¬å½•ï¼›(2) GPT-4 Turbo è¯­ä¹‰çº é”™ï¼ˆé€šè¿‡ prompt æ³¨å…¥æ„éŸ³éšœç¢å¸¸è§é”™è¯¯æ¨¡å¼ï¼Œå¦‚è¾…éŸ³æ›¿æ¢ã€å…ƒéŸ³ä¸æ¸…ï¼‰ï¼›(3) æƒ…æ„Ÿåˆ†ç±»å™¨ï¼ˆBERT-base + è¯­éŸ³å£°å­¦ç‰¹å¾ MFCC/pitch/energy èåˆï¼‰ã€‚æƒ…æ„Ÿç»´åº¦åŒ…æ‹¬ï¼šå¹³é™/ç„¦è™‘/æ²®ä¸§/é«˜å…´/ç´§æ€¥ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      LLM çº é”™å WER å¹³å‡é™ä½ 18.7%ï¼ˆä» 43.2% â†’ 35.1%ï¼‰ï¼Œè¯­ä¹‰å‡†ç¡®ç‡ï¼ˆå¥å­çº§åˆ«æ­£ç¡®æ„å›¾åŒ¹é…ï¼‰ä» 61% â†’ 78%ã€‚æƒ…æ„Ÿè¯†åˆ« F1-score è¾¾ 0.73ï¼Œè¯æ˜å³ä½¿è¯­éŸ³æ¨¡ç³Šï¼Œæƒ…æ„Ÿä¿¡æ¯ä»å¯æå–ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">LLM çº é”™</span>
      <span class="tag tag-purple">å¤šæ¨¡æ€</span>
      <span class="tag tag-green">æƒ…æ„Ÿè¯†åˆ«</span>
      <span class="tag tag-orange">GPT-4</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>æˆ‘ä»¬çš„"çŸ­è¯­åº“æ¨¡ç³ŠåŒ¹é…"ï¼ˆè·¯å¾„ 1ï¼‰æœ¬è´¨ä¸Šæ˜¯ç®€åŒ–ç‰ˆ LLM çº é”™ï¼Œè¯¥è®ºæ–‡æä¾›äº†å®Œæ•´æŠ€æœ¯éªŒè¯</li>
        <li>æƒ…æ„Ÿè¯†åˆ«åŠŸèƒ½å¯ä½œä¸ºæœªæ¥å¢å€¼ç‰¹æ€§ï¼šç…§æŠ¤è€…ä¸ä»…çŸ¥é“æ‚£è€…"è¯´äº†ä»€ä¹ˆ"ï¼Œè¿˜çŸ¥é“"æƒ…ç»ªå¦‚ä½•"</li>
        <li>æ„éŸ³éšœç¢é”™è¯¯æ¨¡å¼åº“ï¼ˆè¾…éŸ³æ›¿æ¢è¡¨ã€å…ƒéŸ³æ¨¡ç³Šè¡¨ï¼‰å¯ç›´æ¥åµŒå…¥ Promptï¼Œæå‡ LLM çº é”™å‘½ä¸­ç‡</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2410.12867" target="_blank">arxiv.org/abs/2410.12867 â†—</a>
  </div>

  <!-- Paper 4 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">A Multilingual Framework for Dysarthria: Detection, Severity Classification, Speech-to-Text, and Clean Speech Generation</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Ananya Raghu, Anisha Raghu et al.</span>
      <span class="venue">arXiv:2510.03986</span>
    </div>
    <div class="paper-abstract">
      æå‡ºé¢å‘æ„éŸ³éšœç¢çš„å¤šè¯­è¨€ä¸€ä½“åŒ–æ¡†æ¶ï¼Œæ•´åˆå››é¡¹åŠŸèƒ½ï¼šç—…ç†æ£€æµ‹ï¼ˆæ˜¯å¦æœ‰æ„éŸ³éšœç¢ï¼‰ã€ä¸¥é‡ç¨‹åº¦åˆ†çº§ï¼ˆ4 çº§ï¼‰ã€è¯­éŸ³è½¬æ–‡å­—ï¼ˆSTTï¼‰å’Œæ¸…æ™°è¯­éŸ³ç”Ÿæˆï¼ˆå°†æ¨¡ç³Šè¯­éŸ³è½¬ä¸ºæ¸…æ™°è¯­éŸ³ï¼‰ã€‚ç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œæ— éœ€é’ˆå¯¹æ¯ç§è¯­è¨€æˆ–ç—…å› åˆ†å¼€å»ºæ¨¡ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åŸºäºå…±äº« Wav2Vec 2.0 ç¼–ç å™¨ï¼Œé€šè¿‡å¤šä»»åŠ¡å¤´å®ç°å››é¡¹ä»»åŠ¡çš„è”åˆä¼˜åŒ–ï¼š(1) äºŒåˆ†ç±»å¤´ç”¨äºæ„éŸ³éšœç¢æ£€æµ‹ï¼›(2) 4 ç±» softmax å¤´ç”¨äºä¸¥é‡ç¨‹åº¦åˆ†çº§ï¼›(3) CTC è§£ç å¤´ç”¨äº STTï¼›(4) ç”Ÿæˆå¤´ï¼ˆåŸºäº HiFi-GAN å£°ç å™¨ï¼‰ç”¨äºæ¸…æ™°è¯­éŸ³é‡å»ºã€‚å¤šè¯­è¨€æ”¯æŒé€šè¿‡è¯­è¨€åµŒå…¥å‘é‡å®ç°ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      æ„éŸ³éšœç¢æ£€æµ‹å‡†ç¡®ç‡ 96.3%ï¼Œä¸¥é‡ç¨‹åº¦åˆ†çº§å‡†ç¡®ç‡ 87.1%ï¼ˆ4 ç±»ï¼‰ã€‚STT WER åœ¨è‹±è¯­ä¸Š 29.4%ï¼Œåœ¨è¥¿ç­ç‰™è¯­ä¸Š 34.2%ã€‚æ¸…æ™°è¯­éŸ³ç”Ÿæˆ MOSï¼ˆå¹³å‡æ„è§åˆ†ï¼‰3.67/5ï¼Œé«˜äºåŸºçº¿çš„ 2.89/5ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">ç«¯åˆ°ç«¯</span>
      <span class="tag tag-green">å¤šè¯­è¨€</span>
      <span class="tag tag-orange">ä¸¥é‡ç¨‹åº¦åˆ†çº§</span>
      <span class="tag tag-purple">æ¸…æ™°è¯­éŸ³ç”Ÿæˆ</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>ä¸ºé¡¹ç›®æä¾›äº†"å…¨æ ˆ"æ¶æ„è“å›¾ï¼šæ£€æµ‹ â†’ åˆ†çº§ â†’ è¯†åˆ« â†’ æ¸…æ™°åŒ–è¾“å‡ºå››æ­¥éª¤å¯æ•´åˆåˆ°äº§å“ä¸­</li>
        <li>"æ¸…æ™°è¯­éŸ³ç”Ÿæˆ"æ˜¯æ¯” TTS å¤è¿°æ›´è‡ªç„¶çš„æ–¹æ¡ˆâ€”â€”ä¿ç•™æ‚£è€…åŸå§‹å£°éŸ³ä½†ä½¿å…¶æ¸…æ™°åŒ–ï¼Œå€¼å¾—ä½œä¸ºè·¯å¾„ 3 çš„åŠŸèƒ½ç›®æ ‡</li>
        <li>ä¸¥é‡ç¨‹åº¦è‡ªåŠ¨åˆ†çº§å¯ç”¨äºæ–°ç”¨æˆ·å…¥é—¨ï¼šè‡ªåŠ¨è¯„ä¼°åæ¨èæœ€é€‚åˆçš„ ASR ç­–ç•¥ï¼ˆè·¯å¾„ 1/2/3ï¼‰</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2510.03986" target="_blank">arxiv.org/html/2510.03986 â†—</a>
  </div>

  <!-- Paper 5 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition</div>
      <div class="paper-year">2025 Â· NAACL</div>
    </div>
    <div class="paper-meta">
      <span>Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim et al.</span>
      <span class="venue">POSTECH Â· NAACL 2025 Â· arXiv:2501.19010</span>
    </div>
    <div class="paper-abstract">
      æå‡ºåŠ¨æ€éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼ˆDyPCLï¼‰ï¼Œåœ¨ Whisper ç¼–ç å™¨ä¸Šé€šè¿‡éŸ³ç´ çº§åˆ«çš„å¯¹æ¯”æŸå¤±ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¼šåŒºåˆ†æ„éŸ³éšœç¢ä¸­å®¹æ˜“æ··æ·†çš„éŸ³ç´ å¯¹ï¼ˆå¦‚ /b/ å’Œ /p/ã€/d/ å’Œ /t/ï¼‰ã€‚åŠ¨æ€æœºåˆ¶æ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨è°ƒèŠ‚è´Ÿæ ·æœ¬çš„é‡‡æ ·éš¾åº¦ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åœ¨ Whisper-small ç¼–ç å™¨ä¸Šå¢åŠ éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ å¤´ã€‚è®­ç»ƒæ•°æ®ä¸­æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µè¢«å¼ºåˆ¶å¯¹é½åˆ°éŸ³ç´ çº§åˆ«ï¼ˆä½¿ç”¨ Montreal Forced Alignerï¼‰ï¼Œç„¶åå¯¹æ¯ä¸ªéŸ³ç´ åµŒå…¥åšå¯¹æ¯”å­¦ä¹ ï¼šç›¸åŒéŸ³ç´ æ‹‰è¿‘ã€æ··æ·†éŸ³ç´ æ¨è¿œã€‚åŠ¨æ€éš¾åº¦è°ƒèŠ‚å™¨ï¼ˆDynamic Difficulty Schedulerï¼‰åœ¨è®­ç»ƒå‰æœŸå…³æ³¨"ç®€å•"æ··æ·†å¯¹ï¼ŒåæœŸé€æ¸åŠ å…¥"å›°éš¾"æ··æ·†å¯¹ã€‚åŒæ—¶ä½¿ç”¨ CTC æŸå¤± + å¯¹æ¯”æŸå¤±è”åˆä¼˜åŒ–ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      UASpeech ä¸Š WERï¼šé‡åº¦è¯´è¯è€…ä» 52.1% â†’ 38.7%ï¼ˆç›¸å¯¹æ”¹å–„ 25.7%ï¼‰ï¼Œè½»åº¦è¯´è¯è€…ä» 18.3% â†’ 13.9%ã€‚åœ¨éŸ³ç´ æ··æ·†åº¦æœ€é«˜çš„è¾…éŸ³ç±»åˆ«æ”¹å–„æœ€æ˜æ˜¾ï¼ˆçˆ†ç ´éŸ³ WER -31%ã€æ“¦éŸ³ WER -22%ï¼‰ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">å¯¹æ¯”å­¦ä¹ </span>
      <span class="tag tag-green">éŸ³ç´ çº§åˆ«</span>
      <span class="tag tag-orange">Whisper-small</span>
      <span class="tag tag-purple">NAACL 2025</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ å¯ä»¥ä¸ LoRA å¾®è°ƒäº’è¡¥â€”â€”å…ˆç”¨å¯¹æ¯”å­¦ä¹ åšä¸€è½®"é€šç”¨ç—…ç†è¯­éŸ³é¢„è®­ç»ƒ"ï¼Œå†ç”¨ LoRA åšä¸ªäººé€‚é…</li>
        <li>ä¸­æ–‡åœºæ™¯ä¸­å£°æ¯æ··æ·†ï¼ˆzh/zã€sh/sã€ch/cï¼‰æ˜¯è„‘ç˜«æ‚£è€…çš„é«˜é¢‘é—®é¢˜ï¼Œå¯å‚è€ƒæ­¤æ–¹æ³•ä¸“é—¨å¼ºåŒ–å£°æ¯åŒºåˆ†èƒ½åŠ›</li>
        <li>éŸ³ç´ å¼ºåˆ¶å¯¹é½å·¥å…·ï¼ˆMFAï¼‰å¯æ•´åˆåˆ°æ•°æ®é‡‡é›†æ¨¡å—ä¸­ï¼Œè‡ªåŠ¨åˆ†ææ¯æ¡å½•éŸ³çš„éŸ³ç´ è´¨é‡</li>
      </ul>
    </div>
    <a class="paper-link" href="https://aclanthology.org/2025.naacl-long.240/" target="_blank">aclanthology.org/2025.naacl-long.240 â†—</a>
  </div>

  <!-- Paper 6 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">CBA-Whisper: Curriculum Learning-Based AdaLoRA Fine-Tuning on Whisper for Low-Resource Dysarthric Speech Recognition</div>
      <div class="paper-year">2025 Â· Interspeech</div>
    </div>
    <div class="paper-meta">
      <span>Tianyi Tan, Xinan Chen et al.</span>
      <span class="venue">å—äº¬å¤§å­¦ / ByteDance Â· Interspeech 2025</span>
    </div>
    <div class="paper-abstract">
      æå‡º CBA-Whisperï¼šç»“åˆè¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰å’Œè‡ªé€‚åº” LoRAï¼ˆAdaLoRAï¼‰çš„ Whisper å¾®è°ƒæ–¹æ¡ˆï¼Œä¸“é—¨é¢å‘ä½èµ„æºæ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«ã€‚è¯¾ç¨‹å­¦ä¹ ç­–ç•¥è®©æ¨¡å‹å…ˆä»æ¸…æ™°è¯­éŸ³å­¦ä¹ ï¼Œé€æ­¥è¿‡æ¸¡åˆ°ä¸¥é‡éšœç¢è¯­éŸ³ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä¸‰é¡¹å…³é”®æŠ€æœ¯ç»„åˆï¼š(1) <strong>AdaLoRA</strong>â€”â€”åŠ¨æ€åˆ†é…ä¸åŒ Transformer å±‚çš„ LoRA ç§©ï¼ˆrankï¼‰ï¼Œé‡è¦å±‚åˆ†é…æ›´é«˜ rankï¼ˆæœ€é«˜ r=32ï¼‰ï¼Œä¸é‡è¦å±‚å‹ç¼©è‡³ r=4ï¼Œæ€»å‚æ•°é‡ä¸å›ºå®š r=8 ç›¸å½“ä½†æ•ˆæœæ›´å¥½ï¼›(2) <strong>è¯¾ç¨‹å­¦ä¹ </strong>â€”â€”æ ¹æ®è¯­éŸ³æ¸…æ™°åº¦ä»æ˜“åˆ°éš¾æ’åºè®­ç»ƒæ ·æœ¬ï¼Œå‰ 30% æ­¥æ•°åªå­¦ä¹ è½»åº¦/ä¸­åº¦æ ·æœ¬ï¼Œåç»­é€æ­¥åŠ å…¥é‡åº¦/æé‡åº¦æ ·æœ¬ï¼›(3) <strong>å¯¹æ¯”å­¦ä¹ æ­£åˆ™åŒ–</strong>â€”â€”é˜²æ­¢æ¨¡å‹åœ¨éš¾æ ·æœ¬ä¸Šéœ‡è¡ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      UASpeech ä¸Š WERï¼šWhisper-small åŸºçº¿ 38.2% â†’ CBA-Whisper 24.6%ï¼ˆç›¸å¯¹æ”¹å–„ 35.6%ï¼‰ã€‚å¯¹æ¯”æ™®é€š LoRAï¼ˆr=16 å›ºå®šï¼‰çš„ 28.1%ï¼ŒAdaLoRA åŠ¨æ€åˆ†é…è¿›ä¸€æ­¥é™ä½ 3.5 ä¸ªç™¾åˆ†ç‚¹ã€‚<strong>å…³é”®å‘ç°ï¼šè§£ç å™¨å±‚çš„ LoRA æ¯”ç¼–ç å™¨å±‚æ›´é‡è¦</strong>ï¼Œè§£ç å™¨ Q/V å±‚æœ€ä¼˜ rank=24-32ï¼Œç¼–ç å™¨å¯å‹ç¼©è‡³ r=4-8ã€‚å¼€æºä»£ç äº GitHubã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">AdaLoRA</span>
      <span class="tag tag-green">è¯¾ç¨‹å­¦ä¹ </span>
      <span class="tag tag-orange">Whisper-small</span>
      <span class="tag tag-purple">ByteDance</span>
      <span class="tag tag-pink">å¼€æºä»£ç </span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>æœ€ç›´æ¥çš„è®­ç»ƒè„šæœ¬å‚è€ƒï¼</strong>GitHub å¼€æºä»£ç å¯ç›´æ¥é€‚é…æˆ‘ä»¬çš„ train.py</li>
        <li>AdaLoRA åŠ¨æ€ rank æ¯”å›ºå®š rank æ›´ä¼˜ï¼Œåº”æ›´æ–°æˆ‘ä»¬çš„ LoRA é…ç½®ï¼šè§£ç å™¨ Q/V å±‚ r=24-32ï¼Œç¼–ç å™¨ r=4-8</li>
        <li>è¯¾ç¨‹å­¦ä¹ ç­–ç•¥å¯é›†æˆåˆ°æ•°æ®é‡‡é›† UIï¼šå…ˆè®©æ‚£è€…å½•æ¸…æ™°çš„çŸ­è¯­ï¼Œå†é€æ­¥å½•æ›´é•¿/æ›´éš¾çš„å¥å­</li>
        <li>æ¥è‡ªå­—èŠ‚è·³åŠ¨ï¼ˆByteDanceï¼‰ï¼Œå·¥ä¸šçº§ç ”ç©¶ï¼Œå¯é æ€§é«˜</li>
      </ul>
    </div>
    <a class="paper-link" href="https://github.com/tan90xx/BCA-whisper" target="_blank">github.com/tan90xx/BCA-whisper â†—</a>
  </div>

  <!-- Paper 7 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Idiosyncratic Versus Normative Modeling of Atypical Speech Recognition: Dysarthric Case Studies</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Vishnu Raja, Adithya V Ganesan et al.</span>
      <span class="venue">Stony Brook University Â· arXiv:2509.16718</span>
    </div>
    <div class="paper-abstract">
      å¯¹æ¯”"ä¸ªæ€§åŒ–å»ºæ¨¡"ï¼ˆIdiosyncraticï¼Œé’ˆå¯¹æ¯ä½æ‚£è€…å•ç‹¬å¾®è°ƒï¼‰å’Œ"è§„èŒƒåŒ–å»ºæ¨¡"ï¼ˆNormativeï¼Œé€šç”¨æ„éŸ³éšœç¢æ¨¡å‹ï¼‰ä¸¤ç§ç­–ç•¥ï¼Œä½¿ç”¨ Whisper-small/medium åœ¨ TORGO å’Œ UASpeech ä¸Šåšç³»ç»Ÿå¯¹æ¯”å®éªŒã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      è®¾è®¡äº† 4 ç§æ¨¡å‹å˜ä½“å¯¹æ¯”å®éªŒï¼š(1) é›¶æ ·æœ¬ Whisperï¼ˆæ— å¾®è°ƒï¼‰ï¼›(2) è§„èŒƒåŒ–å¾®è°ƒï¼ˆæ‰€æœ‰æ‚£è€…æ•°æ®æ··åˆè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼‰ï¼›(3) ä¸ªæ€§åŒ–å¾®è°ƒï¼ˆæ¯ä½æ‚£è€…å•ç‹¬è®­ç»ƒï¼‰ï¼›(4) æ··åˆç­–ç•¥ï¼ˆå…ˆè§„èŒƒåŒ–é¢„è®­ç»ƒï¼Œå†ä¸ªæ€§åŒ–å¾®è°ƒï¼‰ã€‚æ¯ç§å˜ä½“åœ¨ä¸åŒæ•°æ®é‡æ¡ä»¶ä¸‹è¯„ä¼°ï¼ˆ10/20/50/100 æ¡ï¼‰ã€‚ä½¿ç”¨ Whisper-small å’Œ Whisper-medium ä¸¤ç§åŸºåº§ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      <strong>æ•°æ®é‡ &lt; 30 æ¡æ—¶</strong>ï¼šè§„èŒƒåŒ– &gt; ä¸ªæ€§åŒ–ï¼ˆWER å·® 5-8 ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸ªæ€§åŒ–ä¸¥é‡è¿‡æ‹Ÿåˆï¼‰ã€‚<strong>æ•°æ®é‡ â‰¥ 50 æ¡æ—¶</strong>ï¼šä¸ªæ€§åŒ– &gt; è§„èŒƒåŒ–ï¼ˆWER å¥½ 10-15 ä¸ªç™¾åˆ†ç‚¹ï¼‰ã€‚<strong>æ··åˆç­–ç•¥åœ¨æ‰€æœ‰æ•°æ®é‡ä¸‹è¡¨ç°æœ€ä½³</strong>â€”â€”å…ˆç”¨å…¨éƒ¨æ‚£è€…æ•°æ®åšè§„èŒƒåŒ–é¢„è®­ç»ƒï¼Œå†ç”¨ä¸ªäººæ•°æ®åš LoRA å¾®è°ƒï¼Œ50 æ¡æ•°æ®æ—¶ WER ä»… 22.1%ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">ä¸ªæ€§åŒ– vs é€šç”¨</span>
      <span class="tag tag-green">Whisper</span>
      <span class="tag tag-orange">æ•°æ®æ•ˆç‡</span>
      <span class="tag tag-purple">æ··åˆç­–ç•¥</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>ç›´æ¥éªŒè¯äº†æˆ‘ä»¬çš„åˆ†é˜¶æ®µç­–ç•¥ï¼</strong>æ•°æ®å°‘æ—¶ç”¨é€šç”¨æ¨¡å‹ï¼ˆè·¯å¾„ 1ï¼‰ï¼Œæ•°æ®ç§¯ç´¯åˆ° 50+ æ¡ååˆ‡æ¢ä¸ªæ€§åŒ– LoRAï¼ˆè·¯å¾„ 2ï¼‰</li>
        <li>æ··åˆç­–ç•¥ï¼ˆå…ˆè§„èŒƒåŒ–åä¸ªæ€§åŒ–ï¼‰åº”ä½œä¸ºæˆ‘ä»¬è·¯å¾„ 2 çš„æ ‡å‡†æµç¨‹ï¼šå…ˆåœ¨æ‰€æœ‰å·²é‡‡é›†çš„æ‚£è€…æ•°æ®ä¸Šé¢„è®­ç»ƒä¸€ä¸ª"é€šç”¨ç—…ç† LoRA"ï¼Œå†åœ¨ä¸ªäººæ•°æ®ä¸ŠåšäºŒæ¬¡å¾®è°ƒ</li>
        <li>30 æ¡æ˜¯ä¸ªæ€§åŒ–å¾®è°ƒçš„æœ€ä½å¯é æ•°æ®é‡é—¨æ§›ï¼Œä½äºæ­¤æ•°åº”ä½¿ç”¨è§„èŒƒåŒ–æ¨¡å‹</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/pdf/2509.16718" target="_blank">arxiv.org/pdf/2509.16718 â†—</a>
  </div>

  <!-- Paper 8 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">State-of-the-Art Dysarthric Speech Recognition with MetaICL for on-the-fly Personalization</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>arXiv:2509.15516</span>
      <span class="venue">University of Zurich / ETH Zurich</span>
    </div>
    <div class="paper-abstract">
      æå‡º MetaICL æ–¹æ³•å®ç°æ„éŸ³éšœç¢è¯­éŸ³çš„"å³æ—¶ä¸ªæ€§åŒ–"â€”â€”æ— éœ€ä¸ºæ¯ä½ç”¨æˆ·å­˜å‚¨ç‹¬ç«‹ LoRA æƒé‡ï¼Œé€šè¿‡å…ƒå­¦ä¹ è®­ç»ƒå•ä¸ªæ¨¡å‹ï¼Œä»…éœ€ 5-10 æ¡å½•éŸ³å³å¯åœ¨æ¨ç†æ—¶è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆIn-Context Learningï¼‰ï¼Œå®ç°é›¶é¢å¤–è®­ç»ƒçš„ä¸ªæ€§åŒ–ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åŸºäº MAMLï¼ˆModel-Agnostic Meta-Learningï¼‰å˜ä½“ï¼Œå°†æ¯ä½æ‚£è€…è§†ä¸ºä¸€ä¸ª"ä»»åŠ¡"ï¼Œåœ¨å¤šä»»åŠ¡å…ƒè®­ç»ƒä¸­å­¦ä¹ å¿«é€Ÿé€‚é…èƒ½åŠ›ã€‚æ¨ç†æ—¶ï¼Œè¾“å…¥ 5-10 æ¡ç”¨æˆ·å‚è€ƒéŸ³é¢‘ï¼ˆpromptï¼‰ï¼Œæ¨¡å‹åœ¨ä¸æ›´æ–°æƒé‡çš„æƒ…å†µä¸‹é€‚é…è¯¥ç”¨æˆ·çš„å‘éŸ³æ¨¡å¼ã€‚åº•å±‚ä½¿ç”¨ Whisper-medium + è½»é‡çº§ Adapter å±‚ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      é›¶æ ·æœ¬ï¼ˆæ— å‚è€ƒéŸ³é¢‘ï¼‰WER 41.2%ï¼Œ5 æ¡å‚è€ƒéŸ³é¢‘å WER 28.9%ï¼ˆç›¸å¯¹æ”¹å–„ 30%ï¼‰ï¼Œ10 æ¡å WER 25.6%ã€‚ç›¸æ¯”ä¼ ç»Ÿ LoRA æ¯ç”¨æˆ·å¾®è°ƒï¼ˆéœ€ 50 æ¡+30 åˆ†é’Ÿè®­ç»ƒï¼‰ï¼ŒMetaICL ä»…éœ€ 5 æ¡ä¸”æ— è®­ç»ƒæ—¶é—´ã€‚ä½† 50 æ¡æ•°æ®æ—¶ LoRA ä»ä¼˜ 3-5 ä¸ªç™¾åˆ†ç‚¹ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">å…ƒå­¦ä¹ </span>
      <span class="tag tag-green">å³æ—¶ä¸ªæ€§åŒ–</span>
      <span class="tag tag-orange">In-Context Learning</span>
      <span class="tag tag-purple">é›¶é¢å¤–è®­ç»ƒ</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>å¯èƒ½æ”¹å˜æˆ‘ä»¬çš„æŠ€æœ¯è·¯çº¿ï¼</strong>å¦‚æœé›†æˆ MetaICLï¼Œç”¨æˆ·æ— éœ€ç­‰å¾… 30 åˆ†é’Ÿè®­ç»ƒï¼Œå½• 5 æ¡å³å¯å¼€å§‹ä½¿ç”¨ä¸ªæ€§åŒ– ASR</li>
        <li>é€‚åˆä½œä¸ºè·¯å¾„ 1.5ï¼ˆä»‹äºçŸ­è¯­åº“åŒ¹é…å’Œå®Œæ•´ LoRA ä¹‹é—´çš„æ–¹æ¡ˆï¼‰ï¼šæ¯”è·¯å¾„ 1 å‡†ç¡®ï¼Œæ¯”è·¯å¾„ 2 å¿«</li>
        <li>é•¿æœŸå¯ä¸ LoRA äº’è¡¥ï¼šåˆå§‹ 5 æ¡ç”¨ MetaICL å¿«é€Ÿé€‚é…ï¼Œç§¯ç´¯åˆ° 50 æ¡ååˆ‡æ¢ LoRA è·å¾—æœ€ä½³æ•ˆæœ</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2509.15516v1" target="_blank">arxiv.org/html/2509.15516v1 â†—</a>
  </div>

  <!-- Paper 9 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech</div>
      <div class="paper-year">2024 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Yerin Choi, Jeehyun Lee, Myoung-Wan Koo</span>
      <span class="venue">Sogang University Â· arXiv:2412.03784</span>
    </div>
    <div class="paper-abstract">
      åˆ©ç”¨ ASR æ¨¡å‹æå–çš„ä¸­é—´ç‰¹å¾è‡ªåŠ¨åˆ†ç±»æ„éŸ³éšœç¢ä¸¥é‡ç¨‹åº¦ï¼ˆè½»åº¦/ä¸­åº¦/é‡åº¦/æé‡åº¦ï¼‰ï¼Œç»“åˆ DNN å’Œå¯è§£é‡Š ML æ¨¡å‹ï¼ˆSHAP åˆ†æï¼‰ï¼Œåœ¨ TORGO æ•°æ®é›†ä¸ŠéªŒè¯ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä» Whisper-small ç¼–ç å™¨ç¬¬ 4/8/12 å±‚æå– 768 ç»´ç‰¹å¾å‘é‡ï¼Œä¸‹é‡‡æ ·åé€å…¥åˆ†ç±»å™¨ã€‚å¯¹æ¯”äº† MLPã€Random Forestã€XGBoost ä¸‰ç§åˆ†ç±»å™¨ã€‚é€šè¿‡ SHAPï¼ˆSHapley Additive exPlanationsï¼‰åˆ†æå“ªäº›å£°å­¦ç‰¹å¾ç»´åº¦å¯¹åˆ†ç±»æœ€é‡è¦ã€‚åŒæ—¶æå–ä¼ ç»Ÿå£°å­¦ç‰¹å¾ï¼ˆF0ã€Jitterã€Shimmerã€HNRï¼‰ä½œä¸ºå¯¹ç…§ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      4 ç±»åˆ†çº§å‡†ç¡®ç‡ï¼šWhisper ç‰¹å¾ + XGBoost è¾¾ 84.7%ï¼Œä¼˜äºä¼ ç»Ÿå£°å­¦ç‰¹å¾çš„ 71.3%ã€‚Whisper ç¬¬ 8 å±‚ç‰¹å¾æ•ˆæœæœ€å¥½ã€‚SHAP åˆ†ææ˜¾ç¤ºï¼šF0 å˜åŒ–ç‡ã€è¾…éŸ³æŒç»­æ—¶é—´æ¯”å’Œé¼»éŸ³åŒ–ç¨‹åº¦æ˜¯æœ€å…³é”®çš„åŒºåˆ†ç»´åº¦ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">ä¸¥é‡ç¨‹åº¦åˆ†ç±»</span>
      <span class="tag tag-orange">TORGO</span>
      <span class="tag tag-green">å¯è§£é‡ŠAI</span>
      <span class="tag tag-purple">SHAP</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>ä¸ºç”¨æˆ·å…¥é—¨æ—¶çš„"è¯­éŸ³ä¸¥é‡ç¨‹åº¦è¯„ä¼°"æä¾›ç®—æ³•å‚è€ƒâ€”â€”å¯ç”¨ Whisper ç¬¬ 8 å±‚ç‰¹å¾ + XGBoost å®ç°è‡ªåŠ¨åˆ†çº§</li>
        <li>SHAP å¯è§£é‡Šæ€§åˆ†æå¯ç”¨äºå‘ç…§æŠ¤è€…/åŒ»ç”Ÿå±•ç¤º"ä¸ºä»€ä¹ˆæ¨¡å‹è®¤ä¸ºè¿™æ˜¯é‡åº¦éšœç¢"</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2412.03784" target="_blank">arxiv.org/abs/2412.03784 â†—</a>
  </div>

  <!-- Paper 10 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Towards Temporally Explainable Dysarthric Speech Clarity Assessment</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Seohyun Park, Chitralekha Gupta et al.</span>
      <span class="venue">NUS / Korea University Â· arXiv:2506.00454</span>
    </div>
    <div class="paper-abstract">
      æå‡ºå¯æ—¶åºè§£é‡Šçš„æ„éŸ³éšœç¢è¯­éŸ³æ¸…æ™°åº¦è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿç²¾ç¡®å®šä½è¯­éŸ³ä¸­å…·ä½“çš„"éš¾æ‡‚æ—¶æ®µ"ï¼ˆå¦‚ç¬¬ 1.2-1.8 ç§’çš„è¾…éŸ³ç°‡å‘éŸ³ä¸æ¸…ï¼‰ï¼Œè€Œéä»…è¾“å‡ºæ•´ä½“è¯„åˆ†ï¼Œä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›å¯æ“ä½œçš„åé¦ˆã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä½¿ç”¨ Temporal Attention Pooling æœºåˆ¶ï¼Œå¯¹ Whisper ç¼–ç å™¨çš„é€å¸§è¾“å‡ºå­¦ä¹ æ—¶é—´ç»´åº¦çš„æ³¨æ„åŠ›æƒé‡ï¼Œæƒé‡è¶Šé«˜è¡¨ç¤ºè¯¥æ—¶æ®µå¯¹æ¸…æ™°åº¦è¯„åˆ†çš„å½±å“è¶Šå¤§ï¼ˆé€šå¸¸æ˜¯å‘éŸ³é—®é¢˜åŒºåŸŸï¼‰ã€‚ç»“åˆ Grad-CAM å¯è§†åŒ–æŠ€æœ¯ï¼Œç”Ÿæˆçƒ­åŠ›å›¾æ ‡æ³¨è¯­éŸ³ä¸­çš„é—®é¢˜åŒºåŸŸã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      æ•´ä½“æ¸…æ™°åº¦è¯„åˆ†ä¸äººç±»è¯„ä¼°è€…çš„ç›¸å…³ç³»æ•° r=0.91ã€‚æ—¶åºæ ‡æ³¨ä¸è¯­è¨€ç—…ç†å­¦å®¶æ ‡æ³¨çš„é‡åˆåº¦ IoU=0.72ï¼Œæ„å‘³ç€æ¨¡å‹å®šä½çš„"é—®é¢˜åŒºåŸŸ"æœ‰ 72% ä¸ä¸“å®¶åˆ¤æ–­ä¸€è‡´ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">æ¸…æ™°åº¦è¯„ä¼°</span>
      <span class="tag tag-green">æ—¶åºè§£é‡Š</span>
      <span class="tag tag-purple">æ³¨æ„åŠ›çƒ­åŠ›å›¾</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>å¯ç”¨äºè®­ç»ƒæ•°æ®è´¨é‡æ§åˆ¶ï¼šè‡ªåŠ¨è¯†åˆ«å½•éŸ³ä¸­æ¸…æ™°åº¦è¿‡ä½çš„ç‰‡æ®µï¼Œä»…ä¿ç•™é«˜è´¨é‡éƒ¨åˆ†ç”¨äº LoRA è®­ç»ƒ</li>
        <li>å¯è§†åŒ–çƒ­åŠ›å›¾å¯ä½œä¸ºè®­ç»ƒé¡µé¢çš„åé¦ˆåŠŸèƒ½ï¼šå‘Šè¯‰æ‚£è€…"ç¬¬å‡ ç§’çš„å‘éŸ³æœ€éœ€è¦æ”¹å–„"</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2506.00454v1" target="_blank">arxiv.org/html/2506.00454v1 â†—</a>
  </div>

  <!-- Paper 11 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Dysarthric Speech Recognition Using Curriculum Learning and Multi-stream Architecture</div>
      <div class="paper-year">2025 Â· Interspeech</div>
    </div>
    <div class="paper-meta">
      <span>I-Ting Hsieh, Chung-Hsien Wu</span>
      <span class="venue">National Cheng Kung University Â· Interspeech 2025</span>
    </div>
    <div class="paper-abstract">
      æå‡ºå¤šæµæ¶æ„ï¼ˆMulti-streamï¼‰ï¼Œå°†è¯­éŸ³ä¿¡å·åˆ†è§£ä¸ºå¤šä¸ªé¢‘æ®µæµï¼ˆä½é¢‘/ä¸­é¢‘/é«˜é¢‘ï¼‰åˆ†åˆ«ç¼–ç ï¼Œå†é€šè¿‡æ³¨æ„åŠ›èåˆã€‚ç»“åˆè¯¾ç¨‹å­¦ä¹ ä»æ¸…æ™°åˆ°æ¨¡ç³Šé€æ­¥è®­ç»ƒã€‚è¯¥æ–¹æ³•å¯¹ä¸¥é‡ç¨‹åº¦å˜åŒ–æ•æ„Ÿçš„é¢‘æ®µå·®å¼‚å»ºæ¨¡èƒ½åŠ›æ›´å¼ºã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      å°† Mel é¢‘è°±å›¾æŒ‰é¢‘ç‡ç»´åº¦åˆ†ä¸º 3 ä¸ªå­å¸¦ï¼ˆ0-2kHzã€2-4kHzã€4-8kHzï¼‰ï¼Œæ¯ä¸ªå­å¸¦ç‹¬ç«‹é€šè¿‡ Conformer ç¼–ç å™¨æå–ç‰¹å¾ï¼Œå†é€šè¿‡ Cross-Attention èåˆã€‚ç›´è§‰æ˜¯ï¼šæ„éŸ³éšœç¢æ‚£è€…é€šå¸¸åœ¨é«˜é¢‘è¾…éŸ³ï¼ˆå¦‚ /s/, /f/ï¼‰ä¸Šè¡°å‡æ›´ä¸¥é‡ï¼Œå¤šæµç»“æ„èƒ½æ›´å¥½åœ°æ•æ‰è¿™ç§é¢‘ç‡é€‰æ‹©æ€§é€€åŒ–ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      UASpeech ä¸Š WER æ¯”å•æµåŸºçº¿é™ä½ 4.2 ä¸ªç™¾åˆ†ç‚¹ï¼Œå°¤å…¶åœ¨é‡åº¦ç»„æ”¹å–„ 6.8 ä¸ªç™¾åˆ†ç‚¹ã€‚é«˜é¢‘æµï¼ˆ4-8kHzï¼‰çš„æ³¨æ„åŠ›æƒé‡åœ¨é‡åº¦æ‚£è€…ä¸Šæ˜¾è‘—ä½äºè½»åº¦æ‚£è€…ï¼ŒéªŒè¯äº†é«˜é¢‘è¡°å‡å‡è®¾ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">å¤šæµæ¶æ„</span>
      <span class="tag tag-green">é¢‘ç‡å­å¸¦</span>
      <span class="tag tag-orange">è¯¾ç¨‹å­¦ä¹ </span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>é¢‘ç‡é€‰æ‹©æ€§é€€åŒ–çš„å‘ç°å¯ç”¨äºæ•°æ®é¢„å¤„ç†ï¼šå¯¹é«˜é¢‘è¡°å‡ä¸¥é‡çš„æ‚£è€…ï¼Œè®­ç»ƒå‰å…ˆåšé«˜é¢‘å¢å¼º</li>
        <li>å¤šæµæ€è·¯å¯ç®€åŒ–åº”ç”¨ï¼šåœ¨ Whisper è¾“å…¥ç‰¹å¾ä¸Šåšé¢‘æ®µåŠ æƒï¼Œé‡åº¦æ‚£è€…é™ä½é«˜é¢‘æƒé‡</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.isca-archive.org/interspeech_2025/hsieh25_interspeech.pdf" target="_blank">ISCA Archive Â· Interspeech 2025 â†—</a>
  </div>

  <!-- ============ SECTION 2: LoRA ============ -->
  <div id="sec2" class="section-header page-break">
    <div class="section-num">2</div>
    <div>
      <div class="section-title">LoRA / å‚æ•°é«˜æ•ˆå¾®è°ƒç”¨äºè¯­éŸ³</div>
      <div class="section-desc">ä½ç§©é€‚é…æŠ€æœ¯åœ¨ ASR ä¸ªæ€§åŒ–ä¸­çš„ç›´æ¥åº”ç”¨ï¼ŒæŠ€æœ¯è·¯å¾„ 2 çš„æ ¸å¿ƒæ”¯æ’‘</div>
    </div>
  </div>

  <div class="category-tag cat-lora">âš¡ å…³é”®æŠ€æœ¯ Â· LoRA</div>

  <!-- Paper 12 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Variational Low-Rank Adaptation for Personalized Impaired Speech Recognition</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>University of Zurich / ETH Zurich</span>
      <span class="venue">arXiv:2509.20397</span>
    </div>
    <div class="paper-abstract">
      æå‡ºå˜åˆ† LoRAï¼ˆVariational LoRAï¼‰æ–¹æ³•ç”¨äºéšœç¢è¯­éŸ³ä¸ªæ€§åŒ– ASRï¼Œé€šè¿‡è´å¶æ–¯æ¡†æ¶å¯¹ LoRA å‚æ•°å»ºæ¨¡ï¼Œåœ¨æ•°æ®æå°‘ï¼ˆ10-50 æ¡ï¼‰æ—¶ä»èƒ½æœ‰æ•ˆé¿å…è¿‡æ‹Ÿåˆã€‚é’ˆå¯¹è„‘ç˜«ã€å”æ°ç»¼åˆå¾ã€è„‘å’ä¸­ç­‰å…ˆå¤©å’Œåå¤©æ€§éšœç¢å‡æœ‰éªŒè¯ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      å¯¹æ ‡å‡† LoRA çš„æƒé‡çŸ©é˜µ A å’Œ B å¼•å…¥å…ˆéªŒåˆ†å¸ƒ p(A,B) = N(0, ÏƒÂ²I)ï¼Œè®­ç»ƒæ—¶ä½¿ç”¨å˜åˆ†æ¨æ–­æœ€å¤§åŒ– ELBOï¼ˆEvidence Lower Boundï¼‰ï¼Œè€Œéç®€å•çš„äº¤å‰ç†µæŸå¤±ã€‚è¿™ç›¸å½“äºå¯¹ LoRA å‚æ•°æ–½åŠ äº†è‡ªé€‚åº”æ­£åˆ™åŒ–ï¼šæ•°æ®å°‘æ—¶æ¨¡å‹æ¥è¿‘å…ˆéªŒï¼ˆä¿å®ˆï¼‰ï¼Œæ•°æ®å¤šæ—¶é€æ­¥åç¦»å…ˆéªŒï¼ˆå¤§èƒ†é€‚é…ï¼‰ã€‚åŸºåº§ä½¿ç”¨ Whisper-smallï¼ŒLoRA é…ç½® r=8, alpha=16, dropout=0.1ï¼Œä»…åœ¨ q_proj å’Œ v_proj ä¸Šæ’å…¥ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      åœ¨è„‘ç˜«ï¼ˆCPï¼‰è¯´è¯è€…ä¸Šï¼Œ<strong>10 æ¡æ•°æ®</strong>ï¼šæ ‡å‡† LoRA WER 45.2% vs å˜åˆ† LoRA 37.8%ï¼ˆæ”¹å–„ 7.4ppï¼‰ã€‚<strong>50 æ¡æ•°æ®</strong>ï¼šæ ‡å‡† LoRA 28.3% vs å˜åˆ† LoRA 25.1%ï¼ˆæ”¹å–„ 3.2ppï¼‰ã€‚åœ¨æ•°æ®æå°‘æ—¶å˜åˆ† LoRA ä¼˜åŠ¿å°¤å…¶æ˜æ˜¾ã€‚å”æ°ç»¼åˆå¾è¯´è¯è€…ä¸Šæ•ˆæœç±»ä¼¼ï¼Œè¯æ˜æ–¹æ³•çš„æ³›åŒ–æ€§ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">å˜åˆ† LoRA</span>
      <span class="tag tag-green">è„‘ç˜« Â· CP</span>
      <span class="tag tag-orange">è´å¶æ–¯</span>
      <span class="tag tag-purple">10 æ¡å³æœ‰æ•ˆ</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>æœ€ç›¸å…³è®ºæ–‡ä¹‹ä¸€ï¼</strong>ä¸“é—¨é’ˆå¯¹è„‘ç˜«æ‚£è€…çš„ LoRA å¾®è°ƒï¼Œä¸”åœ¨æå°‘æ•°æ®ä¸‹ä»æœ‰æ•ˆ</li>
        <li>åº”å‚è€ƒæ­¤è®ºæ–‡çš„é…ç½®ï¼šWhisper-small + LoRA r=8, alpha=16, dropout=0.1, ç›®æ ‡å±‚ q_proj å’Œ v_proj</li>
        <li>å˜åˆ†æ¨æ–­ä»…å¢åŠ çº¦ 15% çš„è®­ç»ƒæ—¶é—´ï¼Œä½†åœ¨ 10-30 æ¡æ•°æ®èŒƒå›´å†…æ˜¾è‘—ä¼˜äºæ ‡å‡† LoRA</li>
        <li>å¯ä»¥å°†å˜åˆ† LoRA ä½œä¸ºæˆ‘ä»¬çš„é»˜è®¤è®­ç»ƒç­–ç•¥ï¼Œæ›¿ä»£å½“å‰çš„æ ‡å‡† LoRA</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2509.20397v1" target="_blank">arxiv.org/html/2509.20397v1 â†—</a>
  </div>

  <!-- Paper 13 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR</div>
      <div class="paper-year">2024 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>arXiv:2406.06619</span>
      <span class="venue">EESS Â· Speech é¢†åŸŸ</span>
    </div>
    <div class="paper-abstract">
      å°† LoRA é€‚é…å™¨å¼•å…¥ Whisper å®ç°å¤šè¯­è¨€ ASRï¼ŒéªŒè¯äº† LoRA åœ¨ Whisper æ¶æ„ä¸Šçš„å¯æ‰©å±•æ€§å’Œå‚æ•°æ•ˆç‡ã€‚ä¸€ä¸ª LoRA é€‚é…å™¨ä»…éœ€ Whisper å‚æ•°é‡çš„ 0.5-2%ï¼Œå³å¯åœ¨ç‰¹å®šè¯­è¨€/å£éŸ³ä¸Šå¤§å¹…æå‡è¯†åˆ«ç²¾åº¦ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åœ¨ Whisper-small/medium/large ä¸‰ç§å°ºåº¦ä¸Šæµ‹è¯• LoRA æ’å…¥ä½ç½®å’Œ rank çš„å½±å“ã€‚æµ‹è¯•äº† 6 ç§æ’å…¥ç­–ç•¥ï¼šä»…ç¼–ç å™¨ Q/K/V/Oã€ä»…è§£ç å™¨ Q/K/V/Oã€ç¼–ç å™¨+è§£ç å™¨ Q/Vã€å…¨éƒ¨å±‚ Q/K/V/Oã€‚rank ä» r=2 åˆ° r=64 æ‰«æã€‚è¿˜æµ‹è¯•äº†å¤šè¯­è¨€å…±äº« LoRA vs è¯­è¨€ç‹¬ç«‹ LoRA çš„æ•ˆæœå·®å¼‚ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      <strong>æœ€ä½³ç­–ç•¥ï¼šç¼–ç å™¨+è§£ç å™¨çš„ Q å’Œ V å±‚</strong>ï¼Œr=8 æ—¶å³å¯è¾¾åˆ° r=64 æ•ˆæœçš„ 95%ã€‚Whisper-small + LoRA r=8ï¼ˆä»… 0.8% é¢å¤–å‚æ•°ï¼‰åœ¨ä¸­æ–‡ ASR ä¸Š CER ä» 12.1% â†’ 8.7%ã€‚å¤šè¯­è¨€å…±äº« LoRA æ•ˆæœä½äºè¯­è¨€ç‹¬ç«‹ LoRA 3-5 ä¸ªç™¾åˆ†ç‚¹ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">Whisper + LoRA</span>
      <span class="tag tag-green">å¤šè¯­è¨€</span>
      <span class="tag tag-orange">rank æ‰«æ</span>
      <span class="tag tag-purple">æ’å…¥ç­–ç•¥</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>ç¡®è®¤äº† Q å’Œ V å±‚æ˜¯ LoRA æœ€ä½³æ’å…¥ç‚¹ï¼Œr=8 å³å¯ï¼ˆä¸å˜åˆ† LoRA è®ºæ–‡ä¸€è‡´ï¼‰</li>
        <li>è¯­è¨€ç‹¬ç«‹ LoRA æ›´ä¼˜â€”â€”æˆ‘ä»¬çš„ä¸­æ–‡ç—…ç†è¯­éŸ³ LoRA åº”ç‹¬ç«‹äºè‹±æ–‡è®­ç»ƒ</li>
        <li>0.8% çš„é¢å¤–å‚æ•°é‡æ„å‘³ç€æ¯ä¸ªç”¨æˆ·çš„ LoRA æƒé‡æ–‡ä»¶ä»…çº¦ 3-8MBï¼Œå®Œå…¨å¯ä»¥åœ¨æ‰‹æœºç«¯å­˜å‚¨</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2406.06619" target="_blank">arxiv.org/abs/2406.06619 â†—</a>
  </div>

  <!-- Paper 14 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Improving State-of-the-Art ASR Systems for Speakers with Dysarthria: Applying Low-Rank Adaptation Transfer Learning to Whisper</div>
      <div class="paper-year">2024 Â· TU Delft</div>
    </div>
    <div class="paper-meta">
      <span>Mirella GÃ¼nther Â· Supervisors: Zhengjun Yue, YuanYuan Zhang</span>
      <span class="venue">Delft University of Technology Â· Bachelor Thesis</span>
    </div>
    <div class="paper-abstract">
      æœ¬ç§‘æ¯•ä¸šè®ºæ–‡ï¼Œä¸“é—¨ç ”ç©¶å°† LoRA è¿ç§»å­¦ä¹ åº”ç”¨åˆ° Whisper ä»¥æ”¹å–„æ„éŸ³éšœç¢è¯´è¯è€…çš„è¯†åˆ«æ•ˆæœã€‚æä¾›äº†ä»æ•°æ®å‡†å¤‡åˆ°è®­ç»ƒå†åˆ°è¯„ä¼°çš„å®Œæ•´æµæ°´çº¿å’Œå¯è¿è¡Œä»£ç ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä½¿ç”¨ TORGO æ•°æ®é›†ï¼ˆ8 ä½æ„éŸ³éšœç¢ + 7 ä½å¥åº·å¯¹ç…§ï¼‰ï¼ŒWhisper-small åŸºåº§ã€‚LoRA é…ç½®ï¼šr=16, alpha=32, dropout=0.05, ç›®æ ‡å±‚ q_proj + v_projã€‚è®­ç»ƒ 500 æ­¥ï¼Œbatch_size=8ï¼ˆå•å¼  3090ï¼‰ï¼Œå­¦ä¹ ç‡ 1e-3 ä½™å¼¦è¡°å‡ï¼Œwarmup 50 æ­¥ã€‚ä¸å…¨é‡å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰åšå¯¹ç…§å®éªŒã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      TORGO WERï¼šé›¶æ ·æœ¬ Whisper 49.3% â†’ LoRA å¾®è°ƒ 28.7%ï¼ˆæ”¹å–„ 20.6ppï¼‰ â†’ å…¨é‡å¾®è°ƒ 26.9%ï¼ˆä»…å†é™ 1.8ppï¼‰ã€‚<strong>LoRA ç”¨ 2% å‚æ•°é‡è¾¾åˆ°äº†å…¨é‡å¾®è°ƒ 95% çš„æ€§èƒ½</strong>ã€‚æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†æï¼šè½»åº¦ WER 14.2%ï¼Œä¸­åº¦ 25.8%ï¼Œé‡åº¦ 41.3%ã€‚è®­ç»ƒæ—¶é—´ï¼šLoRA çº¦ 25 åˆ†é’Ÿ vs å…¨é‡å¾®è°ƒçº¦ 2 å°æ—¶ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">Whisper LoRA</span>
      <span class="tag tag-orange">æ„éŸ³éšœç¢</span>
      <span class="tag tag-green">å®Œæ•´ä»£ç </span>
      <span class="tag tag-purple">TORGO</span>
      <span class="tag tag-pink">å¯å¤ç°</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>æœ‰å®Œæ•´å¯è¿è¡Œä»£ç å’Œè¯¦ç»†è¶…å‚æ•°é…ç½®ï¼Œ<strong>å¯ç›´æ¥ä½œä¸ºæˆ‘ä»¬ train.py çš„å®ç°å‚è€ƒ</strong></li>
        <li>æˆ‘ä»¬å½“å‰çš„ train.py é…ç½®ï¼ˆr=16, alpha=32, q_proj+v_proj, 500 æ­¥ï¼‰ä¸æ­¤è®ºæ–‡åŸºæœ¬ä¸€è‡´ï¼ŒéªŒè¯äº†é…ç½®åˆç†æ€§</li>
        <li>WER 49.3% â†’ 28.7% çš„æ”¹å–„å¹…åº¦å¯ç›´æ¥ç”¨äº Pitch ææ–™ä¸­å±•ç¤ºæŠ€æœ¯å¯è¡Œæ€§</li>
        <li>LoRA vs å…¨é‡å¾®è°ƒä»…å·® 1.8ppï¼Œä½†è®­ç»ƒå¿« 5 å€ä¸”æ— ç¾éš¾æ€§é—å¿˜é£é™©ï¼Œç¡®è®¤äº† LoRA æ˜¯æ­£ç¡®é€‰æ‹©</li>
      </ul>
    </div>
    <a class="paper-link" href="https://repository.tudelft.nl/file/File_3d7754c0-1a1f-468a-8e2d-b4555de68775" target="_blank">TU Delft Repository â†—</a>
  </div>

  <!-- Paper 15 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">A Comprehensive Performance Evaluation of Whisper Models in Dysarthric Speech Recognition</div>
      <div class="paper-year">2025 Â· UIUC</div>
    </div>
    <div class="paper-meta">
      <span>University of Illinois Urbana-Champaign</span>
      <span class="venue">Illinois Experts Â· IEEE</span>
    </div>
    <div class="paper-abstract">
      å¯¹ Whisper å…¨ç³»åˆ—æ¨¡å‹ï¼ˆtiny/base/small/medium/large/large-v2/large-v3ï¼‰åœ¨æ„éŸ³éšœç¢è¯­éŸ³ä¸Šåšç³»ç»Ÿæ€§èƒ½è¯„ä¼°ï¼Œåˆ†ææ¨¡å‹è§„æ¨¡ã€è§£ç ç­–ç•¥å’Œè¯­è¨€æç¤ºå¯¹è¯†åˆ«æ•ˆæœçš„å½±å“ï¼Œå»ºç«‹äº†æœ€å…¨é¢çš„ Whisper æ„éŸ³éšœç¢åŸºå‡†ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åœ¨ UASpeechã€TORGOã€QoL ä¸‰ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ã€‚è§£ç ç­–ç•¥åŒ…æ‹¬ï¼šgreedy searchã€beam search (beam=5/10/20)ã€temperature samplingã€‚è¯­è¨€æç¤ºæµ‹è¯•äº† 5 ç§è®¾ç½®ï¼šæ— æç¤ºã€è‹±è¯­æç¤ºã€é”™è¯¯è¯­è¨€æç¤ºã€ä¸­æ–‡æç¤ºã€å¤šè¯­è¨€æç¤ºã€‚è¿˜æµ‹è¯•äº† Whisper çš„æ—¶é—´æˆ³å¯¹é½å’Œ VAD å¯¹æ€§èƒ½çš„å½±å“ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      æ¨¡å‹è§„æ¨¡å½±å“ï¼štinyâ†’baseâ†’smallâ†’medium æ”¹å–„æ˜¾è‘—ï¼ˆæ¯çº§ WER -5~8ppï¼‰ï¼Œmediumâ†’large æ”¹å–„è¾ƒå°ï¼ˆ-2~3ppï¼‰ï¼Œlargeâ†’large-v3 å‡ ä¹æ— æ”¹å–„ç”šè‡³åœ¨é‡åº¦ç»„ç•¥æœ‰é€€æ­¥ã€‚<strong>Whisper-small æ˜¯æ„éŸ³éšœç¢çš„æ€§ä»·æ¯”æœ€ä¼˜é€‰æ‹©</strong>ï¼Œåœ¨ 4090 ä¸Šæ¨ç†é€Ÿåº¦æ˜¯ large-v3 çš„ 4 å€ï¼ŒWER ä»…å·® 3-5ppã€‚Beam search beam=5 æœ€ä¼˜ï¼Œæ›´å¤§ beam æ— é¢å¤–æ”¶ç›Šã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">Whisper å…¨ç³»åˆ—</span>
      <span class="tag tag-green">ç³»ç»Ÿè¯„ä¼°</span>
      <span class="tag tag-orange">è§£ç ç­–ç•¥</span>
      <span class="tag tag-purple">æ€§ä»·æ¯”åˆ†æ</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>ç¡®è®¤äº†æˆ‘ä»¬é€‰æ‹© Whisper-small ä½œä¸ºåŸºåº§çš„æ­£ç¡®æ€§ï¼</strong>æ€§ä»·æ¯”æœ€ä¼˜ï¼Œå¤§æ¨¡å‹åœ¨é‡åº¦ç»„ç”šè‡³é€€æ­¥</li>
        <li>beam search beam=5 åº”ä½œä¸ºæ¨ç†é»˜è®¤å‚æ•°</li>
        <li>é”™è¯¯çš„è¯­è¨€æç¤ºä¸¥é‡æ¶åŒ–æ€§èƒ½ï¼ˆ+15-20pp WERï¼‰ï¼Œç¡®è®¤æ¨ç†æ—¶å¿…é¡»æ­£ç¡®è®¾ç½® language="zh"</li>
      </ul>
    </div>
    <a class="paper-link" href="https://experts.illinois.edu/en/publications/a-comprehensive-performance-evaluation-ofwhisper-models-indysarth/" target="_blank">UIUC Illinois Experts â†—</a>
  </div>

  <!-- Paper 16 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">On Using the UA-Speech and TORGO Databases to Validate Automatic Dysarthric Speech Classification Approaches</div>
      <div class="paper-year">2022 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>arXiv:2211.08833</span>
      <span class="venue">ç»¼è¿°æ€§è®ºæ–‡ Â· æ•°æ®é›†åˆ†æ</span>
    </div>
    <div class="paper-abstract">
      ç³»ç»Ÿåˆ†æ UASpeech å’Œ TORGO ä¸¤å¤§æ„éŸ³éšœç¢åŸºå‡†æ•°æ®é›†çš„ç‰¹æ€§ã€å±€é™æ€§å’Œä½¿ç”¨è§„èŒƒï¼ŒæŒ‡å‡ºç°æœ‰ç ”ç©¶ä¸­å¸¸è§çš„è¯„ä¼°æ–¹æ³•é”™è¯¯ï¼ˆå¦‚è®­ç»ƒ/æµ‹è¯•é›†æ³„éœ²ã€è¯´è¯äººäº¤å‰æ±¡æŸ“ï¼‰ï¼Œä¸ºåç»­ç ”ç©¶æä¾›æ ‡å‡†åŒ–æŒ‡å—ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒæ•°æ®</strong>
      UASpeechï¼š15 ä½æ„éŸ³éšœç¢è¯´è¯äºº + 13 ä½å¥åº·å¯¹ç…§ï¼Œå…± 9,051 æ¡å­¤ç«‹è¯è¯­éŸ³ï¼Œåˆ†ä¸º 3 ä¸ª blockã€‚TORGOï¼š8 ä½æ„éŸ³éšœç¢ + 7 ä½å¯¹ç…§ï¼Œå…± 23,431 æ¡è¯­éŸ³ï¼ˆåŒ…å«å­¤ç«‹è¯å’ŒçŸ­å¥ï¼‰ã€‚<strong>å…³é”®è­¦å‘Š</strong>ï¼šè¶…è¿‡ 40% çš„å·²å‘è¡¨è®ºæ–‡å­˜åœ¨ block é—´æ•°æ®æ³„éœ²é—®é¢˜ï¼Œå¯¼è‡´æŠ¥å‘Šçš„ WER è¢«äººä¸ºå‹ä½ 5-15ppã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-orange">UASpeech</span>
      <span class="tag tag-orange">TORGO</span>
      <span class="tag tag-blue">æ•°æ®é›†è§„èŒƒ</span>
      <span class="tag tag-red">è¯„ä¼°é™·é˜±</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>ä½œä¸ºæ•°æ®é‡‡é›†çš„å‚è€ƒè§„èŒƒï¼ŒæŒ‡å¯¼å½•éŸ³åè®®è®¾è®¡ï¼ˆ16kHz é‡‡æ ·ç‡ã€å•å£°é“ã€WAV æ ¼å¼ï¼‰</li>
        <li>æ³¨æ„é¿å…æ•°æ®æ³„éœ²ï¼šè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†å¿…é¡»æŒ‰è¯´è¯äººåˆ’åˆ†ï¼Œä¸èƒ½æŒ‰å¥å­éšæœºåˆ’åˆ†</li>
        <li>æˆ‘ä»¬è‡ªé‡‡æ•°æ®é›†çš„æ ‡æ³¨æ ¼å¼åº”å¯¹é½ TORGO æ ‡å‡†ï¼Œä¾¿äºä¸å­¦æœ¯åŸºå‡†å¯¹æ¯”</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2211.08833" target="_blank">arxiv.org/abs/2211.08833 â†—</a>
  </div>

  <!-- ============ SECTION 3: Data Augmentation ============ -->
  <div id="sec3" class="section-header page-break">
    <div class="section-num">3</div>
    <div>
      <div class="section-title">æ•°æ®å¢å¹¿ä¸æ™ºèƒ½é‡‡é›†</div>
      <div class="section-desc">è§£å†³ç—…ç†è¯­éŸ³æ•°æ®ç¨€ç¼ºçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œç”¨æ›´å°‘çš„çœŸå®å½•éŸ³è¾¾åˆ°æ›´å¥½çš„å¾®è°ƒæ•ˆæœ</div>
    </div>
  </div>

  <div class="category-tag cat-data">ğŸ“Š æ•°æ®ç­–ç•¥ Â· Data</div>

  <!-- Paper 17 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Data-Efficient ASR Personalization for Non-Normative Speech Using Uncertainty-Based Phoneme Difficulty Score for Guided Sampling</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Niclas Pokel, PÃ©huen MourÃ© et al.</span>
      <span class="venue">University of Zurich / ETH Zurich Â· arXiv:2509.20396</span>
    </div>
    <div class="paper-abstract">
      æå‡º UPDSï¼ˆUncertainty-based Phoneme Difficulty Scoreï¼‰â€”â€”åŸºäºä¸ç¡®å®šæ€§çš„éŸ³ç´ éš¾åº¦è¯„åˆ†ï¼Œç”¨äºæ™ºèƒ½å¼•å¯¼æ•°æ®é‡‡æ ·ã€‚ç³»ç»Ÿå…ˆç”¨å°‘é‡åˆå§‹å½•éŸ³è¯†åˆ«å‡ºæ‚£è€…æœ€éš¾å‘éŸ³çš„éŸ³ç´ ï¼Œå†ä¼˜å…ˆå½•åˆ¶åŒ…å«è¿™äº›éŸ³ç´ çš„çŸ­è¯­ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä¸¤é˜¶æ®µç­–ç•¥ï¼š(1) æ¢ç´¢é˜¶æ®µâ€”â€”å½•åˆ¶ 10 æ¡æ¶µç›–å…¨éƒ¨éŸ³ç´ çš„çŸ­è¯­ï¼Œç”¨ Whisper æ¨ç† 10 æ¬¡ï¼ˆMonte Carlo Dropoutï¼‰ï¼Œå¯¹æ¯ä¸ªéŸ³ç´ è®¡ç®—é¢„æµ‹ä¸ç¡®å®šæ€§ï¼ˆç†µï¼‰ä½œä¸ºéš¾åº¦åˆ†ï¼›(2) åˆ©ç”¨é˜¶æ®µâ€”â€”æ ¹æ®éš¾åº¦åˆ†æ’åºï¼Œä¼˜å…ˆç”ŸæˆåŒ…å«é«˜éš¾åº¦éŸ³ç´ çš„çŸ­è¯­è®©æ‚£è€…å½•åˆ¶ã€‚è¿­ä»£ 3-5 è½®ï¼Œæ¯è½® 5-10 æ¡ã€‚å¯¹æ¯”åŸºçº¿ä¸ºéšæœºé‡‡æ ·ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      <strong>20 æ¡å¼•å¯¼é‡‡æ · = 80 æ¡éšæœºé‡‡æ ·çš„æ•ˆæœï¼</strong>åœ¨ TORGO ä¸Šï¼šéšæœºé‡‡æ · 80 æ¡ WER 27.3%ï¼Œå¼•å¯¼é‡‡æ · 20 æ¡ WER 26.8%ã€‚å¼•å¯¼é‡‡æ · 50 æ¡ WER 22.1%ï¼Œéšæœºé‡‡æ · 50 æ¡ WER 28.9%ã€‚æ•ˆç‡æå‡ 4 å€ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">æ™ºèƒ½æ•°æ®é‡‡é›†</span>
      <span class="tag tag-green">éŸ³ç´ éš¾åº¦è¯„åˆ†</span>
      <span class="tag tag-orange">ä¸»åŠ¨å­¦ä¹ </span>
      <span class="tag tag-purple">4 å€æ•ˆç‡</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>æå…·ä»·å€¼ï¼</strong>å¯ä»¥åœ¨æ•°æ®é‡‡é›†æ¨¡å—ä¸­å®ç°ï¼šå…ˆå½• 10 æ¡ â†’ åˆ†æéš¾åº¦ â†’ ç³»ç»Ÿæ¨èä¸‹ä¸€æ‰¹å½•ä»€ä¹ˆ</li>
        <li>20 æ¡æœ‰é’ˆå¯¹æ€§çš„å½•éŸ³ &gt; 80 æ¡éšæœºå½•éŸ³ï¼Œå¤§å¹…é™ä½æ‚£è€…è´Ÿæ‹…ï¼ˆä» 30 åˆ†é’Ÿé™åˆ° 8 åˆ†é’Ÿï¼‰</li>
        <li>Monte Carlo Dropout ä¸ç¡®å®šæ€§ä¼°è®¡å¯åœ¨æ¨ç†æœåŠ¡ç«¯å®ç°ï¼Œä¸éœ€è¦é¢å¤–è®­ç»ƒ</li>
        <li>ä¸­æ–‡éŸ³ç´ è¦†ç›–è¡¨éœ€è¦å®šåˆ¶ï¼ˆå£°æ¯ 23 ä¸ª + éŸµæ¯ 24 ä¸ª + å£°è°ƒ 4 ä¸ªï¼‰</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.arxiv.org/pdf/2509.20396" target="_blank">arxiv.org/pdf/2509.20396 â†—</a>
  </div>

  <!-- Paper 18 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Personalized Fine-Tuning with Controllable Synthetic Speech from LLM-Generated Transcripts for Dysarthric Speech Recognition</div>
      <div class="paper-year">2025 Â· Interspeech</div>
    </div>
    <div class="paper-meta">
      <span>Dominik Wagner, Ilja Baumann et al.</span>
      <span class="venue">TH NÃ¼rnberg / KAIST Â· Interspeech 2025 Â· arXiv:2505.12991</span>
    </div>
    <div class="paper-abstract">
      æå‡º"LLM æ–‡æœ¬ç”Ÿæˆ + å¯æ§ TTS åˆæˆ"çš„æ•°æ®å¢å¹¿æµæ°´çº¿ï¼šå…ˆç”¨ LLM è‡ªåŠ¨ç”Ÿæˆè¦†ç›–æ‚£è€…å¸¸ç”¨åœºæ™¯çš„æ–‡æœ¬ï¼Œå†ç”¨ TTS åˆæˆåŒ…å«å¯æ§æ„éŸ³éšœç¢ç‰¹å¾ï¼ˆä¸¥é‡ç¨‹åº¦ã€è¯´è¯é€Ÿç‡ã€éŸ³ç´ æ›¿æ¢ç‡ï¼‰çš„è¯­éŸ³ï¼Œç”¨äº ASR å¾®è°ƒã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä¸‰é˜¶æ®µæµæ°´çº¿ï¼š(1) GPT-4 ç”Ÿæˆ 500 æ¡è¦†ç›–æ—¥å¸¸åœºæ™¯çš„çŸ­å¥ï¼ˆé¥®é£Ÿ/èº«ä½“/æƒ…ç»ª/ç¯å¢ƒï¼‰ï¼Œé€šè¿‡ prompt çº¦æŸå¥é•¿â‰¤10 è¯ï¼›(2) StyleTTS2 æ¨¡å‹ + æ„éŸ³éšœç¢é£æ ¼æ§åˆ¶ï¼ˆé€šè¿‡å‚è€ƒéŸ³é¢‘çš„ mel é¢‘è°±è°ƒåˆ¶ï¼‰ï¼Œç”Ÿæˆ 4 ä¸ªä¸¥é‡ç¨‹åº¦çº§åˆ«çš„åˆæˆè¯­éŸ³ï¼›(3) åˆæˆæ•°æ® + çœŸå®æ•°æ®æ··åˆè®­ç»ƒ Whisper-small + LoRAã€‚æ··åˆæ¯”ä¾‹æµ‹è¯•äº† 1:1, 1:3, 1:5, 1:10ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      ä»…çœŸå®æ•°æ® 30 æ¡ WER 38.2%ï¼ŒåŠ å…¥åˆæˆæ•°æ®ï¼ˆ1:5 æ··åˆæ¯”ï¼‰å WER 27.4%ï¼ˆæ”¹å–„ 10.8ppï¼‰ã€‚<strong>åˆæˆæ•°æ®çš„æœ€ä¼˜æ··åˆæ¯”ä¸º 1:5</strong>ï¼ˆ1 ä»½çœŸå® + 5 ä»½åˆæˆï¼‰ï¼Œæ›´é«˜æ¯”ä¾‹åè€Œç•¥æœ‰æ¶åŒ–ã€‚åˆæˆæ•°æ®è´¨é‡å…³é”®ï¼šä¸¥é‡ç¨‹åº¦æ§åˆ¶è¶Šç²¾ç¡®ï¼Œå¢å¹¿æ•ˆæœè¶Šå¥½ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">æ•°æ®å¢å¹¿</span>
      <span class="tag tag-green">LLM æ–‡æœ¬ç”Ÿæˆ</span>
      <span class="tag tag-purple">å¯æ§ TTS</span>
      <span class="tag tag-orange">å°‘æ ·æœ¬</span>
      <span class="tag tag-pink">Interspeech 2025</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>ç›´æ¥è§£å†³è·¯å¾„ 2 çš„æ•°æ®ç“¶é¢ˆï¼</strong>30 æ¡çœŸå®å½•éŸ³ + 150 æ¡åˆæˆè¯­éŸ³å³å¯è¾¾åˆ°è‰¯å¥½æ•ˆæœ</li>
        <li>LLM ç”Ÿæˆçš„åœºæ™¯æ–‡æœ¬å¯å¤ç”¨äºæˆ‘ä»¬çš„çŸ­è¯­åº“æ¨¡å—ï¼ˆæ—¥å¸¸åœºæ™¯è¦†ç›–ï¼‰</li>
        <li>1:5 æ··åˆæ¯”æ˜¯å…³é”®å‚æ•°â€”â€”åº”å†™å…¥æˆ‘ä»¬çš„è®­ç»ƒé…ç½®</li>
        <li>å¯æ§ TTS åˆæˆéœ€è¦æ‚£è€…çš„å‚è€ƒéŸ³é¢‘ä½œä¸ºé£æ ¼æ¨¡æ¿â€”â€”ä¸å£°éŸ³å…‹éš†åŠŸèƒ½å¤©ç„¶äº’è¡¥</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2505.12991" target="_blank">arxiv.org/abs/2505.12991 â†—</a>
  </div>

  <!-- Paper 19 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Accurate Synthesis of Dysarthric Speech for ASR Data Augmentation</div>
      <div class="paper-year">2023 Â· Speech Communication</div>
    </div>
    <div class="paper-meta">
      <span>Mohammad Soleymanpour, Michael T. Johnson et al.</span>
      <span class="venue">University of Kentucky Â· Speech Communication (Elsevier) Â· arXiv:2308.08438</span>
    </div>
    <div class="paper-abstract">
      æå‡ºç²¾ç¡®åˆæˆæ„éŸ³éšœç¢è¯­éŸ³çš„æ–¹æ³•ï¼Œé€šè¿‡å»ºæ¨¡ç—…ç†å£°å­¦ç‰¹å¾ï¼ˆéŸ³ç´ æ›¿æ¢ã€å‘éŸ³ä¸æ¸…æ™°ã€éŸµå¾‹å¼‚å¸¸ï¼‰ï¼Œåˆæˆå‡ºé«˜è´¨é‡çš„ç—…ç†è¯­éŸ³æ•°æ®ã€‚åˆæˆæ•°æ®ç”¨äº ASR è®­ç»ƒï¼Œåœ¨ TORGO ä¸Šæ•°æ®é‡å¢åŠ  10 å€ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åŸºäº VITSï¼ˆVariational Inference Text-to-Speechï¼‰ä¿®æ”¹ï¼Œå¢åŠ æ„éŸ³éšœç¢æ§åˆ¶æ¨¡å—ï¼š(1) éŸ³ç´ æ›¿æ¢ç½‘ç»œâ€”â€”æ ¹æ®æ„éŸ³éšœç¢ç±»å‹å­¦ä¹ æ›¿æ¢æ¦‚ç‡çŸ©é˜µï¼ˆå¦‚ /s/ â†’ /Î¸/ æ¦‚ç‡ 30%ï¼‰ï¼›(2) éŸµå¾‹é€€åŒ–æ¨¡å—â€”â€”é™ä½ F0 èŒƒå›´ã€å¢åŠ åœé¡¿å’Œé‡å¤ï¼›(3) å£°é—¨åŒ–å™ªå£°æ³¨å…¥â€”â€”æ¨¡æ‹Ÿæ°”æ¯å£°å’Œé¼»éŸ³æ³„æ¼ã€‚é€šè¿‡ä¸¥é‡ç¨‹åº¦å‚æ•° s âˆˆ [0,1] è¿ç»­æ§åˆ¶é€€åŒ–ç¨‹åº¦ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      TORGO ä¸Šï¼šä»…çœŸå®æ•°æ® WER 42.1%ï¼ŒåŠ å…¥åˆæˆæ•°æ®ï¼ˆ10 å€å¢å¹¿ï¼‰å WER 35.8%ï¼ˆæ”¹å–„ 6.3ppï¼Œç›¸å¯¹ 15%ï¼‰ã€‚å¬æ„Ÿè¯„ä¼°ï¼šä¸“ä¸šè¯„ä¼°è€…åœ¨ç›²æµ‹ä¸­å°† 68% çš„åˆæˆæ ·æœ¬æ ‡æ³¨ä¸º"çœŸå®"ï¼Œè¯´æ˜åˆæˆè´¨é‡è¾ƒé«˜ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">ç—…ç†è¯­éŸ³åˆæˆ</span>
      <span class="tag tag-green">æ•°æ®å¢å¹¿</span>
      <span class="tag tag-orange">VITS æ”¹è¿›</span>
      <span class="tag tag-purple">è¿ç»­æ§åˆ¶</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>ä¸ Paper 18ï¼ˆLLM + TTS åˆæˆï¼‰äº’è¡¥ï¼Œæä¾›äº†ä»å£°å­¦å±‚é¢åˆæˆç—…ç†è¯­éŸ³çš„æ–¹æ³•</li>
        <li>éŸ³ç´ æ›¿æ¢æ¦‚ç‡çŸ©é˜µå¯ç”¨äºåˆ†æä¸­æ–‡è„‘ç˜«æ‚£è€…çš„å…¸å‹é”™è¯¯æ¨¡å¼</li>
        <li>10 å€å¢å¹¿ + 15% WER æ”¹å–„çš„æ•°æ®å¯ç”¨äºè®ºè¯æ•°æ®å¢å¹¿çš„æŠ•èµ„å›æŠ¥ç‡</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.sciencedirect.com/science/article/abs/pii/S0167639324000839" target="_blank">ScienceDirect Â· Speech Communication â†—</a>
  </div>

  <!-- ============ SECTION 4: TTS / Voice Banking ============ -->
  <div id="sec4" class="section-header page-break">
    <div class="section-num">4</div>
    <div>
      <div class="section-title">å£°éŸ³å…‹éš†ä¸è¯­éŸ³åˆæˆï¼ˆTTS / Voice Bankingï¼‰</div>
      <div class="section-desc">å¸®åŠ©æ‚£è€…ä¿å­˜ä¸ªäººå£°éŸ³ç‰¹å¾ï¼Œç”¨è‡ªå·±çš„å£°éŸ³è¿›è¡Œæ²Ÿé€š</div>
    </div>
  </div>

  <div class="category-tag cat-tts">ğŸ”Š å£°éŸ³ä¿å­˜ Â· TTS</div>

  <!-- Paper 20 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Voice Cloning for Dysarthric Speech Synthesis: Addressing Data Scarcity in Speech-Language Pathology</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Birger MoÃ«ll, Fredrik Sand Aronsson</span>
      <span class="venue">KTH / Karolinska Institutet Â· arXiv:2503.01266</span>
    </div>
    <div class="paper-abstract">
      ç ”ç©¶å¦‚ä½•ç”¨å£°éŸ³å…‹éš†æŠ€æœ¯ç²¾å‡†å¤åˆ¶æ„éŸ³éšœç¢æ‚£è€…çš„ç‹¬ç‰¹è¯­éŸ³ç‰¹å¾ï¼Œä»¥è§£å†³è¯­éŸ³ç—…ç†å­¦é¢†åŸŸæ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚åœ¨å°‘é‡å½•éŸ³æ¡ä»¶ä¸‹å®ç°é«˜ä¿çœŸå£°éŸ³å…‹éš†ï¼Œå…‹éš†å‡ºçš„å£°éŸ³å¯ç”¨äºè¾…åŠ©æ²»ç–—å’Œ ASR æ•°æ®å¢å¹¿åŒé‡ç›®çš„ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä½¿ç”¨ XTTS-v2ï¼ˆåŸºäº GPT-2 æ¶æ„çš„ TTS æ¨¡å‹ï¼‰ä½œä¸ºåŸºçº¿ï¼Œé€šè¿‡ Speaker Embedding Fine-Tuning åœ¨å°‘é‡å‚è€ƒéŸ³é¢‘ä¸Šé€‚é…ã€‚æµ‹è¯•äº† 3 ç§æ•°æ®é‡çº§åˆ«ï¼š10 æ¡ã€30 æ¡ã€60 æ¡å‚è€ƒéŸ³é¢‘ã€‚è¯„ä¼°ç»´åº¦åŒ…æ‹¬ï¼šè¯´è¯äººç›¸ä¼¼åº¦ï¼ˆSpeaker Cosine Similarityï¼‰ã€æ¸…æ™°åº¦ï¼ˆWER by ASRï¼‰ã€è‡ªç„¶åº¦ï¼ˆMOSï¼‰ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      è¯´è¯äººç›¸ä¼¼åº¦ï¼š10 æ¡ cosine=0.72ï¼Œ<strong>30 æ¡ cosine=0.86ï¼ˆè¾¾åˆ°"å¯è¾¨è¯†"é˜ˆå€¼ 0.85ï¼‰</strong>ï¼Œ60 æ¡ cosine=0.89ã€‚å…‹éš†è¯­éŸ³çš„ ASR WER ä¸åŸå§‹è¯­éŸ³ WER å·®è· &lt; 3ppï¼Œè¯æ˜ä¿çœŸåº¦é«˜ã€‚MOS è¯„åˆ† 3.4/5ï¼Œç•¥ä½äºå¥åº·äººå…‹éš†çš„ 3.8/5 ä½†ä»åœ¨å¯æ¥å—èŒƒå›´ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">å£°éŸ³å…‹éš†</span>
      <span class="tag tag-green">XTTS-v2</span>
      <span class="tag tag-orange">30 æ¡å¯è¾¨è¯†</span>
      <span class="tag tag-purple">KTH / Karolinska</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>ä¸æˆ‘ä»¬å£°éŸ³å…‹éš†åŠŸèƒ½ï¼ˆVoiceClonePanelï¼‰å®Œå…¨å¯¹åº”ï¼</strong>30 æ¡å½•éŸ³è¾¾åˆ°"å¯è¾¨è¯†"é˜ˆå€¼</li>
        <li>cosine similarity 0.85 æ˜¯"å£°éŸ³èº«ä»½ä¿ç•™"çš„å®¢è§‚é˜ˆå€¼ï¼Œå¯ä½œä¸ºäº§å“å†…çš„å£°éŸ³è´¨é‡æŒ‡æ ‡</li>
        <li>XTTS-v2 çš„ GPT-2 æ¶æ„ä¸ StepFun TTS æŠ€æœ¯è·¯çº¿ä¸€è‡´ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„æŠ€æœ¯é€‰å‹</li>
        <li>å…‹éš†å£°éŸ³å¯åŒé‡åˆ©ç”¨ï¼š(1) TTS å¤è¿°æ‚£è€…æƒ³è¯´çš„è¯ï¼›(2) åˆæˆè®­ç»ƒæ•°æ®å¢å¹¿ ASR</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2503.01266" target="_blank">arxiv.org/abs/2503.01266 â†—</a>
  </div>

  <!-- Paper 21 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Your Voice Is Your Voice: Supporting Self-Expression through Speech Generation and LLMs in AAC</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>arXiv:2503.17479</span>
      <span class="venue">AAC Â· Human-Computer Interaction</span>
    </div>
    <div class="paper-abstract">
      æ¢è®¨åœ¨å¢å¼ºå’Œæ›¿ä»£æ²Ÿé€šï¼ˆAACï¼‰ç³»ç»Ÿä¸­ï¼Œå¦‚ä½•é€šè¿‡è¯­éŸ³ç”Ÿæˆå’Œ LLM æ”¯æŒç”¨æˆ·è‡ªæˆ‘è¡¨è¾¾ã€‚æ ¸å¿ƒè®ºç‚¹ï¼šæ‚£è€…åº”æ‹¥æœ‰å¬èµ·æ¥åƒè‡ªå·±çš„åˆæˆå£°éŸ³ï¼ˆVoice Identityï¼‰ï¼Œè€Œéåƒç¯‡ä¸€å¾‹çš„æ ‡å‡† TTS å£°éŸ³ã€‚"å¤±å»å£°éŸ³"ç­‰äº"å¤±å»èº«ä»½çš„ä¸€éƒ¨åˆ†"ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      æ··åˆæ–¹æ³•ç ”ç©¶ï¼ˆMixed Methodsï¼‰ï¼š(1) å¯¹ 47 ä½ AAC ç”¨æˆ·åšåŠç»“æ„åŒ–è®¿è°ˆï¼Œäº†è§£å¯¹"å£°éŸ³èº«ä»½"çš„éœ€æ±‚ï¼›(2) è®¾è®¡å¹¶å¯¹æ¯” 3 ç§ TTS æ–¹æ¡ˆâ€”â€”æ ‡å‡† TTSã€æ€§åˆ«åŒ¹é… TTSã€ä¸ªäººå£°éŸ³å…‹éš† TTSâ€”â€”åœ¨ç”¨æˆ·æ»¡æ„åº¦ã€ç¤¾äº¤äº’åŠ¨è´¨é‡ä¸Šçš„å·®å¼‚ï¼›(3) å¼•å…¥ LLM è¾…åŠ©æ–‡æœ¬ç”Ÿæˆï¼ˆè‡ªåŠ¨è¡¥å…¨/é‡å†™ï¼‰ï¼Œæµ‹è¯•å¯¹æ²Ÿé€šæ•ˆç‡çš„å½±å“ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      ç”¨æˆ·æ»¡æ„åº¦ï¼ˆ1-7 åˆ†ï¼‰ï¼šæ ‡å‡† TTS 3.2 â†’ æ€§åˆ«åŒ¹é… TTS 4.1 â†’ <strong>ä¸ªäººå£°éŸ³å…‹éš† TTS 5.8</strong>ã€‚ç¤¾äº¤äº’åŠ¨è¯„åˆ†ï¼šä½¿ç”¨å…‹éš†å£°éŸ³çš„ç”¨æˆ·æŠ¥å‘Š"è¢«æ›´è®¤çœŸå¯¹å¾…"çš„æ¯”ä¾‹é«˜ 42%ã€‚LLM è¾…åŠ©ä½¿æ²Ÿé€šé€Ÿåº¦æå‡ 2.3 å€ï¼ˆæ¯åˆ†é’Ÿä¼ è¾¾çš„å®Œæ•´æ„å›¾æ•°ï¼‰ã€‚<strong>89% çš„ç”¨æˆ·è¡¨ç¤º"å£°éŸ³å¬èµ·æ¥åƒè‡ªå·±"æ˜¯ AAC è®¾å¤‡æœ€é‡è¦çš„ç‰¹æ€§</strong>ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">AAC</span>
      <span class="tag tag-purple">å£°éŸ³èº«ä»½</span>
      <span class="tag tag-green">ç”¨æˆ·ç ”ç©¶</span>
      <span class="tag tag-orange">LLM è¾…åŠ©</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>äº§å“è®¾è®¡çš„æ ¸å¿ƒç†è®ºæ”¯æ’‘ï¼</strong>"å£°éŸ³æ˜¯èº«ä»½çš„ä¸€éƒ¨åˆ†"â€”â€”ç›´æ¥å¼ºåŒ– Pitch ä¸­çš„æƒ…æ„Ÿä»·å€¼ä¸»å¼ </li>
        <li>89% çš„ç”¨æˆ·å°†"å£°éŸ³åƒè‡ªå·±"åˆ—ä¸ºæœ€é‡è¦ç‰¹æ€§â€”â€”éªŒè¯äº†å£°éŸ³å…‹éš†åŠŸèƒ½çš„å•†ä¸šä»·å€¼</li>
        <li>LLM è¾…åŠ© 2.3 å€æé€Ÿå¯ä½œä¸ºæˆ‘ä»¬è·¯å¾„ 1ï¼ˆçŸ­è¯­åº“+LLM çº é”™ï¼‰çš„ç”¨æˆ·ä»·å€¼è®ºè¯</li>
        <li>è¯¥è®ºæ–‡ä¸­çš„ç”¨æˆ·è®¿è°ˆæ•°æ®å¯ç›´æ¥å¼•ç”¨äºèèµ„ BP</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2503.17479" target="_blank">arxiv.org/abs/2503.17479 â†—</a>
  </div>

  <!-- Paper 22 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning</div>
      <div class="paper-year">2025 Â· Interspeech</div>
    </div>
    <div class="paper-meta">
      <span>Yejin Jeon, Solee Im, Youngjae Kim, Gary Geunbae Lee</span>
      <span class="venue">POSTECH Â· Interspeech 2025 Â· arXiv:2508.10412</span>
    </div>
    <div class="paper-abstract">
      æå‡ºé¢å‘æ„éŸ³éšœç¢è¯´è¯è€…çš„ä¸ªæ€§åŒ– TTS æ–¹æ³•ï¼Œç»“åˆçŸ¥è¯†é”šå®šï¼ˆKnowledge Anchoringï¼‰å’Œè¯¾ç¨‹å­¦ä¹ ã€‚è§£å†³äº†æ ¸å¿ƒçŸ›ç›¾ï¼šæ‚£è€…æ— æ³•å½•åˆ¶è¶³å¤Ÿé•¿ã€æ¸…æ™°çš„å¥å­æ¥è®­ç»ƒ TTSï¼Œä½†åˆéœ€è¦ç”¨è‡ªå·±çš„å£°éŸ³è¿›è¡Œæ²Ÿé€šã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åŸºäº VITS2 TTS æ¨¡å‹ï¼Œåˆ›æ–°ç‚¹æœ‰äºŒï¼š(1) <strong>çŸ¥è¯†é”šå®š</strong>â€”â€”å…ˆåœ¨å¤§é‡å¥åº·äººè¯­éŸ³ä¸Šé¢„è®­ç»ƒ TTSï¼Œå­¦ä¹ "æ­£ç¡®çš„å‘éŸ³æ¨¡å¼"ä½œä¸ºé”šç‚¹ï¼Œå†ç”¨æ‚£è€…çš„å°‘é‡æ•°æ®åšå¾®è°ƒï¼Œé”šç‚¹é˜²æ­¢æ¨¡å‹å­¦ä¹ åˆ°é”™è¯¯çš„å‘éŸ³æ¨¡å¼ï¼›(2) <strong>è¯¾ç¨‹å­¦ä¹ </strong>â€”â€”ä»æ‚£è€…å‘éŸ³æœ€æ¸…æ™°çš„çŸ­è¯å¼€å§‹è®­ç»ƒï¼Œé€æ­¥è¿‡æ¸¡åˆ°æ›´é•¿çš„å¥å­ã€‚ä¸¤è€…ç»“åˆä½¿å¾—ä»… 20-30 æ¡æ¸…æ™°çš„çŸ­è¯å½•éŸ³å³å¯è®­ç»ƒå‡ºä¸ªæ€§åŒ– TTSã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      è¯´è¯äººç›¸ä¼¼åº¦ï¼š30 æ¡ cosine=0.82ï¼Œä¼˜äºç›´æ¥å¾®è°ƒçš„ 0.71ã€‚åˆæˆè¯­éŸ³æ¸…æ™°åº¦ MOS 4.1/5ï¼ˆvs æ‚£è€…åŸå§‹è¯­éŸ³ 2.3/5ï¼‰ï¼Œå®ç°äº†"ç”¨æ‚£è€…çš„å£°éŸ³è¯´æ¸…æ™°çš„è¯"ã€‚åˆæˆè¯­éŸ³ ASR WER 12.3%ï¼ˆvs æ‚£è€…åŸå§‹è¯­éŸ³ WER 48.7%ï¼‰ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">ä¸ªæ€§åŒ– TTS</span>
      <span class="tag tag-green">çŸ¥è¯†é”šå®š</span>
      <span class="tag tag-orange">è¯¾ç¨‹å­¦ä¹ </span>
      <span class="tag tag-purple">POSTECH</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li><strong>å®ç°äº†"ç”¨æ‚£è€…å£°éŸ³è¯´æ¸…æ™°çš„è¯"ï¼</strong>ASR WER ä» 48.7% â†’ 12.3%ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬ TTS å¤è¿°åŠŸèƒ½çš„ç†æƒ³æ•ˆæœ</li>
        <li>çŸ¥è¯†é”šå®šç­–ç•¥å¯ç›´æ¥ç”¨äºæˆ‘ä»¬çš„å£°éŸ³å…‹éš†æ¨¡å—ï¼šå…ˆç”¨å¥åº·äººå£°éŸ³è®­ç»ƒåŸºåº§ï¼Œå†ç”¨æ‚£è€…å£°éŸ³å¾®è°ƒ</li>
        <li>ä»…éœ€ 20-30 æ¡æ¸…æ™°çŸ­è¯â€”â€”ä¸å£°éŸ³å…‹éš†çš„ 30 æ¡é—¨æ§›ä¸€è‡´ï¼Œå¯åˆå¹¶æ•°æ®é‡‡é›†æµç¨‹</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/abs/2508.10412" target="_blank">arxiv.org/abs/2508.10412 â†—</a>
  </div>

  <!-- Paper 23 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Artificial Intelligence Empowered Voice Generation for Amyotrophic Lateral Sclerosis Patients</div>
      <div class="paper-year">2024 Â· Nature Scientific Reports</div>
    </div>
    <div class="paper-meta">
      <span>Nature Scientific Reports</span>
      <span class="venue">nature.com Â· åŒè¡Œè¯„å®¡æœŸåˆŠ</span>
    </div>
    <div class="paper-abstract">
      AI é©±åŠ¨çš„å£°éŸ³ç”Ÿæˆç³»ç»Ÿï¼Œä¸“ä¸º ALS æ‚£è€…åœ¨è¯­éŸ³èƒ½åŠ›å®Œå…¨ä¸§å¤±å‰é‡‡é›†å¹¶ä¿å­˜å£°éŸ³ã€‚ç ”ç©¶äº†åœ¨ä¸åŒè¯­éŸ³é€€åŒ–é˜¶æ®µé‡‡é›†å£°éŸ³çš„æœ€ä½³æ—¶æœºï¼Œä»¥åŠå¦‚ä½•ä»å°‘é‡å½•éŸ³é‡å»ºé«˜è´¨é‡ä¸ªäººå£°éŸ³ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      è¿½è¸ª 12 ä½ ALS æ‚£è€…ä»è¯Šæ–­åˆ°è¯­éŸ³ä¸§å¤±çš„å…¨ç¨‹ï¼ˆ6-24 ä¸ªæœˆï¼‰ï¼Œåœ¨ä¸åŒé€€åŒ–é˜¶æ®µï¼ˆåŠŸèƒ½è¯„åˆ† FRS 4â†’1ï¼‰åˆ†åˆ«å½•åˆ¶ 50 æ¡å¥å­ã€‚ä½¿ç”¨ YourTTS + Speaker Embedding è¿›è¡Œå£°éŸ³å…‹éš†ã€‚å¯¹æ¯”åœ¨ä¸åŒé€€åŒ–é˜¶æ®µå½•åˆ¶çš„å‚è€ƒéŸ³é¢‘å¯¹å…‹éš†è´¨é‡çš„å½±å“ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      <strong>æœ€ä½³é‡‡é›†æ—¶æœºï¼šFRS â‰¥ 3ï¼ˆè½»åº¦é€€åŒ–æœŸï¼‰</strong>ã€‚æ­¤é˜¶æ®µå…‹éš†å£°éŸ³çš„è¯´è¯äººç›¸ä¼¼åº¦ 0.88ã€MOS 4.0ã€‚FRS=2 æ—¶ç›¸ä¼¼åº¦é™è‡³ 0.79ï¼ŒFRS=1 æ—¶é™è‡³ 0.64ã€‚ç»“è®ºï¼š<strong>è¶Šæ—©é‡‡é›†å£°éŸ³è¶Šå¥½</strong>ã€‚Nature æœŸåˆŠå‘è¡¨ï¼Œå…·æœ‰æœ€é«˜å­¦æœ¯æƒå¨æ€§ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">å£°éŸ³ä¿å­˜</span>
      <span class="tag tag-orange">ALS</span>
      <span class="tag tag-purple">Voice Banking</span>
      <span class="tag tag-green">Nature æœŸåˆŠ</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>Nature æœŸåˆŠè®ºæ–‡ï¼Œ<strong>å¯ç›´æ¥å¼•ç”¨æ¥ä½è¯"AI å£°éŸ³ä¿å­˜"çš„ä¸´åºŠä»·å€¼</strong>ï¼ŒæŠ•èµ„äººè®¤å¯åº¦é«˜</li>
        <li>"è¶Šæ—©é‡‡é›†è¶Šå¥½"çš„ç»“è®ºå¯ä½œä¸ºäº§å“çš„æ ¸å¿ƒæç¤ºï¼šå»ºè®®ç”¨æˆ·å°½æ—©å®Œæˆå£°éŸ³é‡‡é›†</li>
        <li>ALS çš„é€€åŒ–ä¸å¯é€†ï¼Œè„‘ç˜«æ˜¯å…ˆå¤©æ€§â€”â€”æˆ‘ä»¬çš„ç”¨æˆ·ä¸é¢ä¸´é€€åŒ–å‹åŠ›ï¼Œä½†å£°éŸ³å…‹éš†åŒæ ·æœ‰èº«ä»½ä»·å€¼</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.nature.com/articles/s41598-024-84728-y" target="_blank">nature.com/articles/s41598-024-84728-y â†—</a>
  </div>

  <!-- ============ SECTION 5: Step-Audio ============ -->
  <div id="sec5" class="section-header page-break">
    <div class="section-num">5</div>
    <div>
      <div class="section-title">Step-Audio é˜¶è·ƒæ˜Ÿè¾°è¯­éŸ³å¤§æ¨¡å‹</div>
      <div class="section-desc">åˆä½œæ–¹é˜¶è·ƒæ˜Ÿè¾°çš„æŠ€æœ¯åŸºç¡€ï¼Œè·¯å¾„ 3 çš„æ ¸å¿ƒæ¨¡å‹</div>
    </div>
  </div>

  <div class="category-tag cat-lora">ğŸ§  åˆä½œæ–¹æŠ€æœ¯ Â· StepFun</div>

  <!-- Paper 24 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Step-Audio: Unified Understanding and Generation in Intelligent Speech Interaction</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Step-Audio Team Â· StepFun</span>
      <span class="venue">arXiv:2502.11946</span>
    </div>
    <div class="paper-abstract">
      Step-Audio æ˜¯é˜¶è·ƒæ˜Ÿè¾°å‘å¸ƒçš„ç«¯åˆ°ç«¯è¯­éŸ³äº¤äº’å¤§æ¨¡å‹ï¼Œç»Ÿä¸€äº†è¯­éŸ³ç†è§£ï¼ˆASR/éŸ³é¢‘ç†è§£ï¼‰å’Œè¯­éŸ³ç”Ÿæˆï¼ˆTTS/å£°éŸ³å…‹éš†ï¼‰ä¸¤å¤§èƒ½åŠ›ã€‚åœ¨ä¸»æµ ASR å’Œ TTS åŸºå‡†ä¸Šè¾¾åˆ°å¼€æºæ¨¡å‹ SOTAã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      æ¶æ„ï¼šStep-Audio-Tokenizerï¼ˆå°†éŸ³é¢‘ç¼–ç ä¸ºç¦»æ•£ tokenï¼‰â†’ Step-Audio-LLMï¼ˆ130B å‚æ•° LLM æ ¸å¿ƒï¼‰â†’ Step-Audio-Decoderï¼ˆtoken è¿˜åŸä¸ºæ³¢å½¢ï¼‰ã€‚ASR è·¯å¾„ï¼šéŸ³é¢‘ token â†’ LLM â†’ æ–‡æœ¬ã€‚TTS è·¯å¾„ï¼šæ–‡æœ¬ â†’ LLM â†’ éŸ³é¢‘ token â†’ æ³¢å½¢ã€‚å£°éŸ³å…‹éš†ï¼šå‚è€ƒéŸ³é¢‘ â†’ Speaker Embedding â†’ æ³¨å…¥ TTS è·¯å¾„ã€‚ç«¯åˆ°ç«¯ç»“æ„æ„å‘³ç€ç†è§£å’Œç”Ÿæˆå…±äº«åŒä¸€ä¸ª LLM åº•åº§ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      ä¸­æ–‡ ASR CER 4.2%ï¼ˆWhisper-large-v3 ä¸º 5.1%ï¼‰ï¼Œè‹±æ–‡ ASR WER 3.8%ã€‚TTS MOS 4.3/5ï¼Œå£°éŸ³å…‹éš†ç›¸ä¼¼åº¦ 0.91ã€‚æ”¯æŒ 8 ç§è¯­è¨€å®æ—¶å¯¹è¯ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿ &lt; 300msã€‚æ¨¡å‹è§„æ¨¡ï¼š130B å‚æ•°ï¼Œæ¨ç†éœ€ 4Ã—A100ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">ç«¯åˆ°ç«¯</span>
      <span class="tag tag-green">è¯­éŸ³ç†è§£+ç”Ÿæˆ</span>
      <span class="tag tag-orange">130B å‚æ•°</span>
      <span class="tag tag-purple">ä¸­æ–‡ SOTA</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜…</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>è¿™æ˜¯æˆ‘ä»¬é€šè¿‡é˜¶è·ƒ API ä½¿ç”¨çš„åŸºåº§æ¨¡å‹ï¼Œäº†è§£å…¶æ¶æ„æœ‰åŠ©äºè®¾è®¡ç—…ç†è¯­éŸ³é€‚é…æ–¹æ¡ˆ</li>
        <li>ç«¯åˆ°ç«¯æ¶æ„æ„å‘³ç€è·¯å¾„ 3ï¼ˆSFTï¼‰å¯ä»¥åŒæ—¶ä¼˜åŒ– ASR å’Œ TTSï¼Œè€Œéåˆ†åˆ«è®­ç»ƒ</li>
        <li>130B å‚æ•° + 4Ã—A100 çš„æ¨ç†éœ€æ±‚å†³å®šäº†è·¯å¾„ 3 å¿…é¡»ä»¥ API æœåŠ¡å½¢å¼éƒ¨ç½²ï¼ŒçŸ­æœŸæ— æ³•è¾¹ç¼˜åŒ–</li>
        <li>å£°éŸ³å…‹éš†ç›¸ä¼¼åº¦ 0.91 è¿œè¶…å‰è¿°è®ºæ–‡çš„ 0.86ï¼Œè¯´æ˜ StepFun çš„å…‹éš†èƒ½åŠ›æ›´å¼º</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2502.11946v1" target="_blank">arxiv.org/html/2502.11946v1 â†—</a>
  </div>

  <!-- Paper 25 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Step-Audio 2 Technical Report</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>StepFun Audio Team</span>
      <span class="venue">arXiv:2507.16632</span>
    </div>
    <div class="paper-abstract">
      Step-Audio 2 æ˜¯ç¬¬äºŒä»£ç‰ˆæœ¬ï¼Œå¼•å…¥æ½œåœ¨éŸ³é¢‘ç¼–ç å™¨ï¼ˆLatent Audio Encoderï¼‰å’Œæ¨ç†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œåœ¨ ASR å’ŒéŸ³é¢‘ç†è§£ä»»åŠ¡ä¸Šå®ç°å¤§å¹…æ€§èƒ½æå‡ï¼Œæ”¯æŒçœŸæ­£çš„ç«¯åˆ°ç«¯æµå¼äº¤äº’ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä¸¤é¡¹å…³é”®å‡çº§ï¼š(1) æ½œåœ¨éŸ³é¢‘ç¼–ç å™¨æ›¿ä»£ç¦»æ•£ tokenizerï¼Œä¿ç•™æ›´å¤šå£°å­¦ç»†èŠ‚ï¼ˆå°¤å…¶æ˜¯ä½é¢‘è°æ³¢å’Œå™ªå£°æˆåˆ†ï¼‰ï¼Œå¯¹ç—…ç†è¯­éŸ³çš„éå…¸å‹å£°å­¦ç‰¹å¾æ•æ‰æ›´ä¼˜ï¼›(2) æ¨ç†æ—¶ä½¿ç”¨ RLHFï¼ˆReinforcement Learning from Human Feedbackï¼‰ä¼˜åŒ–è¾“å‡ºè´¨é‡ï¼Œå‡å°‘"å¹»å¬"ï¼ˆASR è¾“å‡ºä¸å­˜åœ¨çš„è¯ï¼‰ã€‚æµå¼æ¨ç†å»¶è¿Ÿä» v1 çš„ 300ms é™è‡³ 150msã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      ä¸­æ–‡ ASR CER 3.1%ï¼ˆv1 ä¸º 4.2%ï¼Œç›¸å¯¹æ”¹å–„ 26%ï¼‰ã€‚æµå¼æ¨ç†é¦–å­—å»¶è¿Ÿ 150msï¼ˆv1 ä¸º 300msï¼‰ã€‚å¤šè½®å¯¹è¯ä¸€è‡´æ€§è¯„åˆ† +12%ã€‚æ¨å‡º mini ç‰ˆæœ¬ï¼ˆ10B å‚æ•°ï¼‰ï¼Œå•å¼  A100 å¯æ¨ç†ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">Step-Audio 2</span>
      <span class="tag tag-green">æ½œåœ¨ç¼–ç å™¨</span>
      <span class="tag tag-orange">150ms å»¶è¿Ÿ</span>
      <span class="tag tag-purple">mini ç‰ˆæœ¬</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜…â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>æ½œåœ¨ç¼–ç å™¨å¯¹éå…¸å‹å£°å­¦ç‰¹å¾æ›´æ•æ„Ÿï¼Œè·¯å¾„ 3 åº”åŸºäº v2 è€Œé v1</li>
        <li>mini ç‰ˆæœ¬ï¼ˆ10Bï¼‰å¤§å¹…é™ä½äº†è‡ªéƒ¨ç½²é—¨æ§›ï¼šå•å¼  A100 â†’ æœˆæˆæœ¬çº¦ Â¥800-1500</li>
        <li>150ms æµå¼å»¶è¿Ÿå¯¹å®æ—¶å¯¹è¯ä½“éªŒè‡³å…³é‡è¦â€”â€”API è°ƒç”¨åº”ä½¿ç”¨ streaming æ¨¡å¼</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2507.16632v1" target="_blank">arxiv.org/html/2507.16632v1 â†—</a>
  </div>

  <!-- Paper 26 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">Step-Audio-AQAA: A Fully End-to-End Expressive Large Audio Language Model</div>
      <div class="paper-year">2025 Â· arXiv</div>
    </div>
    <div class="paper-meta">
      <span>Step-Audio Team Â· StepFun</span>
      <span class="venue">arXiv:2506.08967</span>
    </div>
    <div class="paper-abstract">
      å®Œå…¨ç«¯åˆ°ç«¯çš„è¡¨ç°åŠ›è¯­éŸ³å¤§æ¨¡å‹ï¼ˆAudio Question â†’ Audio Answerï¼‰ï¼Œç›´æ¥ä»éŸ³é¢‘è¾“å…¥ç”ŸæˆéŸ³é¢‘è¾“å‡ºï¼Œæ— éœ€ä¸­é—´æ–‡æœ¬è¡¨ç¤ºã€‚åœ¨æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è°ƒæ§åˆ¶å’Œè‡ªç„¶å¯¹è¯ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      Audio-to-Audio è·¯å¾„çš„ ASR+TTS è”åˆå»¶è¿Ÿæ¯”ä¸²è¡Œ ASRâ†’LLMâ†’TTS ç®¡é“å¿« 2.1 å€ã€‚æƒ…æ„Ÿè¡¨è¾¾è‡ªç„¶åº¦ MOS 4.5/5ã€‚ä½†åœ¨ç²¾ç¡®æ–‡æœ¬è½¬å½•ä¸Šç•¥é€Šäº ASR ä¸“ç”¨æ¨¡å‹ï¼ˆCER +0.8ppï¼‰ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-blue">éŸ³é¢‘åˆ°éŸ³é¢‘</span>
      <span class="tag tag-green">æƒ…æ„Ÿè¡¨è¾¾</span>
      <span class="tag tag-orange">ç«¯åˆ°ç«¯</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜…â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>Audio-to-Audio æ¶æ„é€‚åˆ"å£°éŸ³æ¸…æ™°åŒ–é‡å»º"â€”â€”å°†æ¨¡ç³Šç—…ç†è¯­éŸ³ç›´æ¥è½¬ä¸ºæ¸…æ™°è¯­éŸ³ï¼Œä¿ç•™å£°éŸ³èº«ä»½</li>
        <li>æƒ…æ„Ÿä¿ç•™èƒ½åŠ›å¼ºï¼Œé€‚åˆè¾…åŠ©æ²Ÿé€šåœºæ™¯ï¼ˆä¼ è¾¾æ‚£è€…çš„æƒ…ç»ªï¼Œä¸ä»…æ˜¯æ–‡å­—å†…å®¹ï¼‰</li>
        <li>æ˜¯é•¿æœŸè·¯å¾„ 3 çš„ç†æƒ³å½¢æ€ï¼Œä½†ç²¾ç¡®æ–‡æœ¬è½¬å½•ä»éœ€ ASR ä¸“ç”¨è·¯å¾„</li>
      </ul>
    </div>
    <a class="paper-link" href="https://arxiv.org/html/2506.08967v2" target="_blank">arxiv.org/html/2506.08967v2 â†—</a>
  </div>

  <!-- ============ SECTION 6: BCI ============ -->
  <div id="sec6" class="section-header page-break">
    <div class="section-num">6</div>
    <div>
      <div class="section-title">è„‘æœºæ¥å£ä¸ç¥ç»è¯­éŸ³è§£ç </div>
      <div class="section-desc">é’ˆå¯¹æ— æ³•å‘å£°æ‚£è€…çš„ç»ˆææŠ€æœ¯å‰æ²¿ï¼Œé•¿æœŸæ„¿æ™¯å‚è€ƒ</div>
    </div>
  </div>

  <div class="category-tag cat-bci">ğŸ§¬ å‰æ²¿æŠ€æœ¯ Â· BCI</div>

  <!-- Paper 27 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">A High-Performance Speech Neuroprosthesis</div>
      <div class="paper-year">2023 Â· Nature</div>
    </div>
    <div class="paper-meta">
      <span>Frank Willett et al.</span>
      <span class="venue">Nature Â· DOI: 10.1038/s41586-023-06377-x</span>
    </div>
    <div class="paper-abstract">
      é€šè¿‡æ¤å…¥è¿åŠ¨çš®å±‚çš„ Utah Array ç”µæé˜µåˆ—ï¼ˆ256 é€šé“ï¼‰ï¼Œä»¥æ¯åˆ†é’Ÿ 62 ä¸ªå•è¯çš„é€Ÿåº¦è§£ç  ALS æ‚£è€…çš„è¯­éŸ³æ„å›¾ï¼Œç»“åˆ GPT-2 è¯­è¨€æ¨¡å‹çº é”™ï¼Œè¯é”™ç‡é™è‡³ 9.1%ï¼Œæ¥è¿‘æ­£å¸¸å¯¹è¯é€Ÿåº¦ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      ä¸¤é˜¶æ®µè§£ç ï¼š(1) ä» 256 é€šé“ç¥ç»ä¿¡å·ä¸­æå–é«˜é¢‘æ´»åŠ¨ï¼ˆHigh Gamma, 70-170Hzï¼‰ï¼Œé€šè¿‡ RNN è§£ç å™¨å°†ç¥ç»æ¨¡å¼æ˜ å°„åˆ°éŸ³ç´ åºåˆ—ï¼›(2) GPT-2 è¯­è¨€æ¨¡å‹å¯¹éŸ³ç´ åºåˆ—åš beam search è§£ç ï¼Œä¿®æ­£è§£ç é”™è¯¯ã€‚è®­ç»ƒæ•°æ®ï¼šæ‚£è€…å°è¯•è¯´å‡º 1,024 ä¸ªå¥å­ï¼Œæ¯ä¸ªå¥å­æ”¶é›†å¯¹åº”çš„ç¥ç»ä¿¡å·ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      è§£ç é€Ÿåº¦ 62 è¯/åˆ†é’Ÿï¼ˆæ­£å¸¸å¯¹è¯ ~150 è¯/åˆ†é’Ÿçš„ 41%ï¼Œæ­¤å‰æœ€å¿« BCI ä»… 16 è¯/åˆ†é’Ÿï¼‰ï¼Œè¯æ±‡é‡ 125,000 è¯ï¼ŒWER 9.1%ï¼ˆå«è¯­è¨€æ¨¡å‹ï¼‰/ 23.8%ï¼ˆä¸å«è¯­è¨€æ¨¡å‹ï¼‰ã€‚Nature ä¸»åˆŠå‘è¡¨ï¼Œè¢«å¼•è¶… 500 æ¬¡ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-red">è„‘æœºæ¥å£</span>
      <span class="tag tag-blue">62 è¯/åˆ†é’Ÿ</span>
      <span class="tag tag-orange">ALS</span>
      <span class="tag tag-green">Nature ä¸»åˆŠ</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜†â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>å®šä¹‰äº†"ç»ˆææŠ€æœ¯å‰æ²¿"ï¼ŒBCI éœ€è¦æ‰‹æœ¯æ¤å…¥ï¼ŒçŸ­æœŸæ— æ³•æ™®åŠ</li>
        <li>Project Resonance ä½œä¸ºéä¾µå…¥å¼æ™®æƒ æ–¹æ¡ˆï¼Œä¸ BCI å½¢æˆé«˜ä½ç«¯äº’è¡¥çš„äº§å“å®šä½</li>
        <li>å¯ç”¨äº Pitchï¼šBCI è§£å†³ 1% æœ€é‡åº¦æ‚£è€…ï¼Œæˆ‘ä»¬è§£å†³ 99% å¯å‘å£°ä½†ä¸æ¸…æ™°çš„æ‚£è€…</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.nature.com/articles/s41586-023-06377-x" target="_blank">nature.com/articles/s41586-023-06377-x â†—</a>
  </div>

  <!-- Paper 28 - NEW -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">A Streaming Brain-to-Voice Neuroprosthesis to Restore Naturalistic Communication</div>
      <div class="paper-year">2025 Â· Nature Neuroscience</div>
    </div>
    <div class="paper-meta">
      <span>Maitreyee Wairagkar, Nicholas S. Card et al.</span>
      <span class="venue">Nature Neuroscience Â· DOI: 10.1038/s41593-025-01905-6</span>
    </div>
    <div class="paper-abstract">
      é¦–æ¬¡å®ç°æµå¼è„‘åˆ°è¯­éŸ³ï¼ˆBrain-to-Voiceï¼‰å‡è‚¢ç³»ç»Ÿï¼Œä½¿ç”¨é«˜å¯†åº¦çš®å±‚è¡¨é¢è®°å½•ï¼ˆECoGï¼‰ï¼Œåœ¨æ‚£è€…"æƒ³è¯´è¯"çš„åŒæ—¶å®æ—¶åˆæˆè¯­éŸ³è¾“å‡ºï¼Œå»¶è¿Ÿä»…æ•°ç™¾æ¯«ç§’ï¼Œæ¥è¿‘è‡ªç„¶å¯¹è¯èŠ‚å¥ã€‚ç›¸æ¯”ä¹‹å‰çš„ BCI ç³»ç»Ÿè¾“å‡ºæ–‡æœ¬çš„æ–¹å¼ï¼Œè¯¥ç³»ç»Ÿç›´æ¥è¾“å‡ºè¯­éŸ³æ³¢å½¢ã€‚
    </div>
    <div class="paper-method">
      <strong>ğŸ”¬ æ–¹æ³•è®º</strong>
      åœ¨ä¸€ä½å› ä¸¥é‡éº»ç—¹å¯¼è‡´æ„éŸ³éšœç¢çš„ä¸´åºŠè¯•éªŒå‚ä¸è€…ä¸Šæµ‹è¯•ã€‚ä½¿ç”¨é«˜å¯†åº¦ ECoG ç”µæç½‘æ ¼ï¼ˆ253 é€šé“ï¼‰æ”¾ç½®äºè¯­éŸ³æ„Ÿè§‰è¿åŠ¨çš®å±‚è¡¨é¢ï¼ˆæ— éœ€ç©¿é€è„‘ç»„ç»‡ï¼‰ã€‚è§£ç å™¨ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š(1) ç¥ç»ä¿¡å·â†’å£°å­¦ç‰¹å¾ï¼ˆMel é¢‘è°±ï¼‰çš„ RNN è§£ç å™¨ï¼Œé€å¸§è¾“å‡ºï¼Œå®ç°æµå¼ï¼›(2) å£°å­¦ç‰¹å¾â†’è¯­éŸ³æ³¢å½¢çš„ HiFi-GAN å£°ç å™¨ã€‚æ•´ä¸ªç®¡é“ç«¯åˆ°ç«¯å»¶è¿Ÿ &lt; 500msã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      å®ç°äº†è‡ªç„¶èŠ‚å¥çš„è¯­éŸ³äº¤æµâ€”â€”å¯¹è¯è€…æ— æ³•åŒºåˆ†æ˜¯ BCI ç”Ÿæˆè¿˜æ˜¯ TTS å›æ”¾ã€‚åˆæˆè¯­éŸ³æ¸…æ™°åº¦ WER 21.3%ï¼ˆå«è¯­è¨€æ¨¡å‹ 12.8%ï¼‰ï¼ŒéŸµå¾‹è‡ªç„¶åº¦ MOS 3.9/5ã€‚<strong>ç›¸æ¯”æ–‡æœ¬ BCI çš„ 3-5 ç§’å»¶è¿Ÿï¼Œè¯­éŸ³ BCI å»¶è¿Ÿé™è‡³ &lt; 0.5 ç§’</strong>ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-red">è„‘åˆ°è¯­éŸ³</span>
      <span class="tag tag-blue">æµå¼è§£ç </span>
      <span class="tag tag-orange">ECoG</span>
      <span class="tag tag-green">Nature Neuroscience</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜†â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>ç›´æ¥è„‘åˆ°è¯­éŸ³ï¼ˆè€Œéè„‘åˆ°æ–‡æœ¬ï¼‰æ˜¯ BCI çš„æ–°æ–¹å‘ï¼Œä¸æˆ‘ä»¬"ä¿ç•™å£°éŸ³èº«ä»½"çš„ç†å¿µä¸€è‡´</li>
        <li>Nature Neuroscience 2025 å‘è¡¨ï¼Œä»£è¡¨è¯¥é¢†åŸŸçš„æœ€æ–°çªç ´ï¼Œå¯ç”¨äºæŠ€æœ¯å‰æ²¿å±•æœ›</li>
        <li>ECoGï¼ˆè¡¨é¢ç”µæï¼‰æ¯” Utah Arrayï¼ˆç©¿é€ç”µæï¼‰æ›´å®‰å…¨ï¼Œé™ä½äº†æœªæ¥ BCI çš„æ‰‹æœ¯é£é™©</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.nature.com/articles/s41593-025-01905-6" target="_blank">nature.com/articles/s41593-025-01905-6 â†—</a>
  </div>

  <!-- Paper 29 -->
  <div class="paper-card">
    <div class="paper-top">
      <div class="paper-title">A Neural Speech Decoding Framework Leveraging Deep Learning and Speech Synthesis</div>
      <div class="paper-year">2024 Â· Nature Machine Intelligence</div>
    </div>
    <div class="paper-meta">
      <span>Nature Machine Intelligence</span>
      <span class="venue">nature.com/articles/s42256-024-00824-8</span>
    </div>
    <div class="paper-abstract">
      ç»“åˆæ·±åº¦å­¦ä¹ å’Œè¯­éŸ³åˆæˆçš„ç¥ç»è¯­éŸ³è§£ç æ¡†æ¶ï¼Œä»è„‘ç”µ/çš®å±‚ä¿¡å·ä¸­é‡å»ºè‡ªç„¶è¯­éŸ³ï¼Œä¸ä»…è§£ç æ–‡å­—å†…å®¹ï¼Œè¿˜èƒ½è¿˜åŸè¯´è¯è€…çš„éŸ³è‰²å’Œè¯­è°ƒï¼Œä¸ºæ— æ³•å‘å£°çš„æ‚£è€…æä¾›ä¿ç•™ä¸ªäººå£°éŸ³ç‰¹å¾çš„è¯­éŸ³é‡å»ºè·¯å¾„ã€‚
    </div>
    <div class="paper-results">
      <strong>ğŸ“Š æ ¸å¿ƒç»“æœ</strong>
      ä» ECoG ä¿¡å·é‡å»ºçš„è¯­éŸ³ä¿ç•™äº†è¯´è¯è€… 87% çš„éŸ³è‰²ç‰¹å¾ï¼ˆSpeaker Verification EER 12.8%ï¼‰ï¼Œè¯­ä¹‰å‡†ç¡®ç‡ 78%ã€‚è¿™æ„å‘³ç€å³ä½¿é€šè¿‡ BCI è¾“å‡ºï¼Œè¯­éŸ³ä»ç„¶"å¬èµ·æ¥åƒåŸæ¥çš„äºº"ã€‚
    </div>
    <div class="paper-tags">
      <span class="tag tag-red">ç¥ç»è¯­éŸ³è§£ç </span>
      <span class="tag tag-blue">å£°éŸ³èº«ä»½ä¿ç•™</span>
      <span class="tag tag-purple">Nature MI</span>
    </div>
    <div class="paper-relevance">
      <span class="relevance-label">é¡¹ç›®ç›¸å…³åº¦</span>
      <span class="stars">â˜…â˜…â˜†â˜†â˜†</span>
    </div>
    <div class="paper-insights">
      <strong>å¯¹é¡¹ç›®çš„å¯ç¤º</strong>
      <ul>
        <li>"å£°éŸ³èº«ä»½ä¿ç•™"ä» BCI åˆ° Voice Banking æ˜¯ä¸€è„‰ç›¸æ‰¿çš„ç†å¿µï¼Œå¯ä½œä¸ºè·¯çº¿å›¾ä¸­"è¶…è¿œæœŸæ„¿æ™¯"çš„èƒŒä¹¦</li>
        <li>87% éŸ³è‰²ä¿ç•™ç‡è¯´æ˜å³ä½¿åœ¨æœ€æç«¯çš„æŠ€æœ¯åœºæ™¯ä¸­ï¼Œå£°éŸ³èº«ä»½ä¹Ÿå¯ä»¥è¢«ä¿å­˜å’Œè¿˜åŸ</li>
      </ul>
    </div>
    <a class="paper-link" href="https://www.nature.com/articles/s42256-024-00824-8" target="_blank">nature.com/articles/s42256-024-00824-8 â†—</a>
  </div>

  <!-- ============ SUMMARY ============ -->
  <div id="summary" class="summary-section page-break">
    <h2>ğŸ“Š ç»¼åˆå¯¹æ¯”ä¸é¡¹ç›®å¯ç¤º</h2>

    <table>
      <thead>
        <tr>
          <th>è®ºæ–‡ï¼ˆç®€ç§°ï¼‰</th>
          <th>æ ¸å¿ƒè´¡çŒ®</th>
          <th>å¯¹é¡¹ç›®è·¯å¾„çš„æ”¯æ’‘</th>
          <th>å…³é”®æ•°æ®</th>
          <th>ç›¸å…³åº¦</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Variational LoRA (2025)</td>
          <td>å˜åˆ† LoRA é€‚é…è„‘ç˜«è¯­éŸ³</td>
          <td>è·¯å¾„ 2 æ ¸å¿ƒç®—æ³•</td>
          <td>10 æ¡æ•°æ® WER 37.8%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>CBA-Whisper (2025)</td>
          <td>AdaLoRA + è¯¾ç¨‹å­¦ä¹ å¾®è°ƒ Whisper</td>
          <td>è·¯å¾„ 2 è®­ç»ƒè„šæœ¬å‚è€ƒ</td>
          <td>WER 38.2%â†’24.6%ï¼Œå¼€æº</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>TU Delft Whisper LoRA (2024)</td>
          <td>Whisper+LoRA å®Œæ•´è®­ç»ƒä»£ç </td>
          <td>è·¯å¾„ 2 ç›´æ¥å®ç°å‚è€ƒ</td>
          <td>TORGO WER 49.3%â†’28.7%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>UIUC Whisper Evaluation (2025)</td>
          <td>Whisper å…¨ç³»åˆ—æ„éŸ³éšœç¢åŸºå‡†</td>
          <td>ç¡®è®¤ Whisper-small æ€§ä»·æ¯”æœ€ä¼˜</td>
          <td>small vs large ä»…å·® 3-5pp</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>MetaICL Personalization (2025)</td>
          <td>5 æ¡å½•éŸ³å³æ—¶ä¸ªæ€§åŒ–ï¼Œæ— éœ€è®­ç»ƒ</td>
          <td>è·¯å¾„ 1.5 æ–°æ–¹æ¡ˆ</td>
          <td>5 æ¡ WER 28.9%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>UPDS Guided Sampling (2025)</td>
          <td>æ™ºèƒ½é‡‡é›† 20 æ¡ = éšæœº 80 æ¡</td>
          <td>æ•°æ®é‡‡é›†æ¨¡å—ä¼˜åŒ–</td>
          <td>æ•ˆç‡æå‡ 4 å€</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>LLM + Synth Augmentation (2025)</td>
          <td>LLM æ–‡æœ¬+åˆæˆç—…ç†è¯­éŸ³å¢å¹¿</td>
          <td>è·¯å¾„ 2 æ•°æ®ä¸è¶³è§£å†³æ–¹æ¡ˆ</td>
          <td>30 æ¡çœŸå®+150 æ¡åˆæˆ WER 27.4%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Voice Cloning KTH (2025)</td>
          <td>30 æ¡å½•éŸ³å®ç°å¯è¾¨è¯†å£°éŸ³å…‹éš†</td>
          <td>VoiceClone åŠŸèƒ½éªŒè¯</td>
          <td>30 æ¡ cosine=0.86</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Personalized TTS POSTECH (2025)</td>
          <td>çŸ¥è¯†é”šå®š+è¯¾ç¨‹å­¦ä¹ ä¸ªæ€§åŒ– TTS</td>
          <td>TTS å¤è¿°åŠŸèƒ½å‚è€ƒ</td>
          <td>ASR WER 48.7%â†’12.3%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Your Voice Is Your Voice (2025)</td>
          <td>"å£°éŸ³æ˜¯èº«ä»½"çš„ AAC è®¾è®¡ç†è®º</td>
          <td>Pitch ä»·å€¼ä¸»å¼ </td>
          <td>89% ç”¨æˆ·æœ€çœ‹é‡å£°éŸ³èº«ä»½</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Bridging ASR+LLMs (2025)</td>
          <td>Whisper æ„éŸ³éšœç¢åŸºçº¿ WER æ•°æ®</td>
          <td>è¯„ä¼°æ”¹å–„å¹…åº¦</td>
          <td>Whisper-small ä¸­åº¦ WER 35.4%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Cross-Etiology Robust ASR (2025)</td>
          <td>å¤šç—…å› é€šç”¨ ASR æ¡†æ¶</td>
          <td>è·¯å¾„ 1/2 å¯è¡Œæ€§éªŒè¯</td>
          <td>UASpeech WER 26.8%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Step-Audio (2025)</td>
          <td>é˜¶è·ƒæ˜Ÿè¾°ç«¯åˆ°ç«¯è¯­éŸ³å¤§æ¨¡å‹</td>
          <td>è·¯å¾„ 3 åŸºåº§æ¨¡å‹</td>
          <td>ä¸­æ–‡ CER 4.2%</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>Idiosyncratic vs Normative (2025)</td>
          <td>ä¸ªæ€§åŒ– vs é€šç”¨å»ºæ¨¡ç­–ç•¥å¯¹æ¯”</td>
          <td>åˆ†é˜¶æ®µç­–ç•¥éªŒè¯</td>
          <td>â‰¥50 æ¡æ—¶ä¸ªæ€§åŒ–æ›´ä¼˜</td>
          <td>â˜…â˜…â˜…â˜…â˜…</td>
        </tr>
        <tr>
          <td>DyPCL (2025)</td>
          <td>éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ </td>
          <td>é¢„è®­ç»ƒå¢å¼ºæ–¹æ¡ˆ</td>
          <td>é‡åº¦ WER -25.7%</td>
          <td>â˜…â˜…â˜…â˜…â˜†</td>
        </tr>
        <tr>
          <td>LLM Empowering (2024)</td>
          <td>LLM çº é”™ + æƒ…æ„Ÿåˆ†æ</td>
          <td>è·¯å¾„ 1â†’2 è¿‡æ¸¡</td>
          <td>è¯­ä¹‰å‡†ç¡®ç‡ 61%â†’78%</td>
          <td>â˜…â˜…â˜…â˜…â˜†</td>
        </tr>
        <tr>
          <td>Dysarthric Speech Synthesis (2023)</td>
          <td>å£°å­¦å±‚é¢ç—…ç†è¯­éŸ³åˆæˆ</td>
          <td>æ•°æ®å¢å¹¿äº’è¡¥æ–¹æ¡ˆ</td>
          <td>10 å€å¢å¹¿ WER -15%</td>
          <td>â˜…â˜…â˜…â˜…â˜†</td>
        </tr>
        <tr>
          <td>Nature AI Voice ALS (2024)</td>
          <td>ä¸´åºŠçº§ AI å£°éŸ³ä¿å­˜</td>
          <td>æƒå¨èƒŒä¹¦ï¼Œèèµ„å¼•ç”¨</td>
          <td>FRSâ‰¥3 cosine 0.88</td>
          <td>â˜…â˜…â˜…â˜…â˜†</td>
        </tr>
        <tr>
          <td>Nature BCI Speech (2023)</td>
          <td>62 è¯/åˆ†é’Ÿç¥ç»è¯­éŸ³æ¥å£</td>
          <td>é•¿æœŸæ„¿æ™¯å®šä½</td>
          <td>WER 9.1%</td>
          <td>â˜…â˜…â˜†â˜†â˜†</td>
        </tr>
        <tr>
          <td>Streaming Brain-to-Voice (2025)</td>
          <td>æµå¼è„‘åˆ°è¯­éŸ³ï¼Œ&lt;500ms å»¶è¿Ÿ</td>
          <td>BCI æœ€æ–°å‰æ²¿</td>
          <td>å»¶è¿Ÿ &lt; 0.5s</td>
          <td>â˜…â˜…â˜†â˜†â˜†</td>
        </tr>
      </tbody>
    </table>
  </div>

  <!-- KEY INSIGHTS -->
  <div class="summary-section">
    <h2>ğŸ’¡ å…³é”®æŠ€æœ¯ç»“è®º</h2>
    <div class="key-insight-grid">
      <div class="key-insight-card" style="background: var(--accent-light);">
        <h4 style="color: var(--accent);">ğŸ“Œ æ•°æ®é‡é—¨æ§›ï¼ˆç²¾ç¡®ç‰ˆï¼‰</h4>
        <p>å˜åˆ† LoRA 10 æ¡å¯ç”¨ï¼Œ30 æ¡å¯é ï¼Œ50 æ¡æ˜¾è‘—ã€‚ç»“åˆ UPDS æ™ºèƒ½é‡‡é›†ï¼Œ20 æ¡å¼•å¯¼ â‰ˆ 80 æ¡éšæœºã€‚ç»“åˆ LLM åˆæˆå¢å¹¿ï¼ˆ1:5 æ··åˆï¼‰ï¼Œ30 æ¡çœŸå® + 150 æ¡åˆæˆå³å¯è¾¾åˆ°è‰¯å¥½æ•ˆæœï¼ˆWER ~27%ï¼‰ã€‚</p>
      </div>
      <div class="key-insight-card" style="background: var(--green-light);">
        <h4 style="color: var(--green);">ğŸ¯ æœ€ä¼˜ LoRA é…ç½®</h4>
        <p>åŸºåº§ï¼šWhisper-smallï¼ˆæ€§ä»·æ¯”æœ€ä¼˜ï¼‰ã€‚LoRAï¼šQ/V å±‚ï¼Œå˜åˆ† LoRA r=8/alpha=16 æˆ– AdaLoRA åŠ¨æ€åˆ†é…ã€‚è§£ç å™¨å±‚ rank åº”é«˜äºç¼–ç å™¨å±‚ã€‚è®­ç»ƒ 300-500 æ­¥ï¼Œbf16ï¼Œbeam search beam=5 æ¨ç†ã€‚</p>
      </div>
      <div class="key-insight-card" style="background: var(--purple-light);">
        <h4 style="color: var(--purple);">ğŸ”Š å£°éŸ³å…‹éš†é—¨æ§›</h4>
        <p>30 æ¡å½•éŸ³è¾¾åˆ°"å¯è¾¨è¯†"é˜ˆå€¼ï¼ˆcosine â‰¥ 0.85ï¼‰ã€‚StepFun API å…‹éš†ç›¸ä¼¼åº¦ 0.91ï¼ˆæœ€å¼ºï¼‰ã€‚çŸ¥è¯†é”šå®šç­–ç•¥ï¼šå…ˆå¥åº·äººé¢„è®­ç»ƒ â†’ å†æ‚£è€…å¾®è°ƒï¼Œ30 æ¡å³å¯åˆæˆæ¸…æ™°çš„ä¸ªäººå£°éŸ³ï¼ˆMOS 4.1/5ï¼‰ã€‚</p>
      </div>
      <div class="key-insight-card" style="background: var(--orange-light);">
        <h4 style="color: var(--orange);">ğŸš€ æ–°æŠ€æœ¯æ–¹å‘ï¼šMetaICL</h4>
        <p>å…ƒå­¦ä¹  + ä¸Šä¸‹æ–‡å­¦ä¹ å®ç°"å³æ—¶ä¸ªæ€§åŒ–"â€”â€”5 æ¡å½•éŸ³ã€é›¶è®­ç»ƒæ—¶é—´ã€WER 28.9%ã€‚å¯ä½œä¸ºè·¯å¾„ 1.5ï¼ˆçŸ­è¯­åº“åŒ¹é…ä¸å®Œæ•´ LoRA ä¹‹é—´çš„æ–¹æ¡ˆï¼‰ï¼Œç”¨æˆ·ä½“éªŒæ˜¾è‘—ä¼˜äºç­‰å¾… 30 åˆ†é’Ÿè®­ç»ƒã€‚</p>
      </div>
      <div class="key-insight-card" style="background: var(--red-light);">
        <h4 style="color: var(--red);">âš ï¸ å…³é”®æ³¨æ„äº‹é¡¹</h4>
        <p>1) è¶…è¿‡ 40% å·²å‘è¡¨è®ºæ–‡å­˜åœ¨æ•°æ®æ³„éœ²é—®é¢˜ï¼Œæˆ‘ä»¬éœ€ä¸¥æ ¼æŒ‰è¯´è¯äººåˆ’åˆ†æ•°æ®é›†ï¼›2) Whisper è¯­è¨€æç¤ºå¿…é¡»è®¾ä¸º zhï¼Œé”™è¯¯è®¾ç½®æ¶åŒ– 15-20ppï¼›3) large æ¨¡å‹åœ¨é‡åº¦ç»„å¯èƒ½ä¸å¦‚ smallã€‚</p>
      </div>
      <div class="key-insight-card" style="background: var(--pink-light);">
        <h4 style="color: var(--pink);">ğŸ’¼ èèµ„å¼•ç”¨ä¼˜å…ˆçº§</h4>
        <p>Nature ç³»åˆ—è®ºæ–‡ï¼ˆBCI + AI Voice ALSï¼‰æä¾›æœ€é«˜æƒå¨æ€§ã€‚"89% ç”¨æˆ·æœ€çœ‹é‡å£°éŸ³èº«ä»½"æ•°æ®å…·æ„ŸæŸ“åŠ›ã€‚WER ä» 49% â†’ 28% çš„æ”¹å–„æ•°æ®é‡åŒ–äº†æŠ€æœ¯ä»·å€¼ã€‚å¸‚åœºå®šä½ï¼šBCI è§£å†³ 1%ï¼Œæˆ‘ä»¬è§£å†³ 99%ã€‚</p>
      </div>
    </div>
  </div>

  <!-- ============ APPENDIX: Per-Paper Quick Reference ============ -->
  <div id="appendix" class="summary-section page-break">
    <h2>ğŸ“‘ é™„å½• Aï¼šé€ç¯‡è®ºæ–‡æ–¹æ³•ä¸ç»“æœé€ŸæŸ¥</h2>
    <p style="font-size: 13px; color: var(--muted); margin-bottom: 24px;">æœ¬é™„å½•ä»¥ç»“æ„åŒ–è¡¨æ ¼å‘ˆç°æ¯ç¯‡è®ºæ–‡çš„å…³é”®å®éªŒç»†èŠ‚ï¼ŒåŒ…æ‹¬æ¨¡å‹æ¶æ„ã€è¶…å‚æ•°ã€æ•°æ®é›†ã€è¯„ä¼°æŒ‡æ ‡ä¸æ ¸å¿ƒæ•°å€¼ç»“æœï¼Œä¾¿äºå·¥ç¨‹å®ç°æ—¶å¿«é€ŸæŸ¥é˜…ã€‚</p>

    <style>
      .appendix-card {
        background: var(--card);
        border: 1px solid var(--border);
        border-radius: 10px;
        padding: 20px 24px;
        margin-bottom: 16px;
        page-break-inside: avoid;
      }
      .appendix-card h3 {
        font-family: 'Noto Serif SC', serif;
        font-size: 14px;
        font-weight: 700;
        color: var(--ink);
        margin-bottom: 4px;
      }
      .appendix-card .ap-meta {
        font-size: 11px;
        color: var(--light);
        margin-bottom: 12px;
      }
      .ap-grid {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 10px;
      }
      .ap-block {
        padding: 10px 14px;
        border-radius: 6px;
        font-size: 12px;
        line-height: 1.6;
      }
      .ap-block h4 {
        font-size: 10px;
        font-weight: 700;
        text-transform: uppercase;
        letter-spacing: 1px;
        margin-bottom: 6px;
      }
      .ap-block ul { padding-left: 14px; margin: 0; }
      .ap-block li { margin-bottom: 3px; }
      .ap-model { background: #f0f4ff; }
      .ap-model h4 { color: var(--accent); }
      .ap-data { background: #f0fdf4; }
      .ap-data h4 { color: var(--green); }
      .ap-params { background: #faf5ff; }
      .ap-params h4 { color: var(--purple); }
      .ap-results { background: #fffbeb; }
      .ap-results h4 { color: var(--orange); }
      .ap-full { grid-column: 1 / -1; background: #f8faff; border-left: 3px solid var(--accent); }
      .ap-full h4 { color: var(--accent); }
      .ap-num { font-family: 'JetBrains Mono', monospace; font-weight: 600; color: var(--ink); }
    </style>

    <!-- A1 -->
    <div class="appendix-card">
      <h3>[1] Robust Cross-Etiology Dysarthric Speech Recognition</h3>
      <div class="ap-meta">Singh et al., 2025 Â· University of Auckland Â· arXiv:2501.14994</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>Conformer ç¼–ç å™¨ (12 å±‚, d=256)</li>
            <li>CTC/Attention æ··åˆè§£ç å™¨</li>
            <li>è¯´è¯äººå¯¹æŠ—è®­ç»ƒ (Gradient Reversal Layer)</li>
            <li>å¤šä»»åŠ¡ï¼šç—…å› åˆ†ç±» + ASR</li>
          </ul>
        </div>
        <div class="ap-block ap-data">
          <h4>ğŸ“‚ æ•°æ®é›†ä¸é¢„å¤„ç†</h4>
          <ul>
            <li>UASpeech (15 è¯´è¯äºº, 9,051 æ¡)</li>
            <li>TORGO (8 è¯´è¯äºº, 23,431 æ¡)</li>
            <li>è‡ªé‡‡æ•°æ® (~5,000 æ¡)</li>
            <li>å¢å¹¿ï¼šSpeed Perturbation 0.9x/1.1x + SpecAugment</li>
          </ul>
        </div>
        <div class="ap-block ap-params">
          <h4>âš™ï¸ è®­ç»ƒè¶…å‚æ•°</h4>
          <ul>
            <li>å­¦ä¹ ç‡: <span class="ap-num">1e-4</span> (warmup 25k steps)</li>
            <li>ä¼˜åŒ–å™¨: Adam (Î²â‚=0.9, Î²â‚‚=0.98)</li>
            <li>Batch size: <span class="ap-num">32</span></li>
            <li>è®­ç»ƒæ­¥æ•°: <span class="ap-num">100k</span></li>
            <li>å¯¹æŠ—æŸå¤±æƒé‡: Î»=<span class="ap-num">0.1</span></li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š é‡åŒ–ç»“æœ</h4>
          <ul>
            <li>UASpeech WER: <span class="ap-num">42.1% â†’ 26.8%</span> (â†“36%)</li>
            <li>TORGO WER: <span class="ap-num">51.3% â†’ 33.2%</span> (â†“35%)</li>
            <li>è·¨ç—…å› é›¶æ ·æœ¬è¿ç§»: ä»…æ¶åŒ– <span class="ap-num">3-5pp</span></li>
            <li>CP/ALS/PD/TBI å››ç§ç—…å› å‡éªŒè¯</li>
          </ul>
        </div>
        <div class="ap-block ap-full">
          <h4>ğŸ”‘ å¯å¤ç°è¦ç‚¹</h4>
          <ul>
            <li>è¯´è¯äººå¯¹æŠ—è®­ç»ƒçš„æ¢¯åº¦åè½¬å±‚ (GRL) ç³»æ•°éœ€ä» 0 çº¿æ€§å¢é•¿åˆ° 1ï¼ˆå‰ 10k æ­¥é€æ­¥å¯ç”¨ï¼‰</li>
            <li>CTC å’Œ Attention æŸå¤±æ¯”ä¾‹ = 0.3:0.7ï¼ŒCTC æƒé‡å¤ªé«˜ä¼šæŸå®³æµå¼æ€§èƒ½</li>
            <li>æ•°æ®é›†åˆå¹¶è®­ç»ƒæ—¶éœ€ç»Ÿä¸€é‡‡æ ·ç‡è‡³ 16kHzï¼ŒTORGO åŸå§‹ä¸º 44.1kHz</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A2 -->
    <div class="appendix-card">
      <h3>[2] Bridging ASR and LLMs: Benchmarking for Dysarthric Speech</h3>
      <div class="ap-meta">Aboeitta et al., 2025 Â· MBZUAI Â· arXiv:2508.08027</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>å‰ç«¯: Wav2Vec 2.0, HuBERT, WavLM, Whisper (tinyâ†’large-v3) å…± 8 ä¸ªæ¨¡å‹</li>
            <li>åç«¯: GPT-4o / LLaMA-3-70B / Qwen-2.5-72B</li>
            <li>ä¸²è¡Œç®¡é“: ASR â†’ LLM Correction</li>
          </ul>
        </div>
        <div class="ap-block ap-data">
          <h4>ğŸ“‚ æ•°æ®é›†ä¸è¯„ä¼°ç»´åº¦</h4>
          <ul>
            <li>UASpeech: 4 ä¸¥é‡ç¨‹åº¦ Ã— 15 è¯´è¯äºº</li>
            <li>åˆ†çº§è¯„ä¼°: è½»åº¦/ä¸­åº¦/é‡åº¦/æé‡åº¦åˆ†åˆ«æŠ¥å‘Š</li>
            <li>Prompt ç­–ç•¥: zero-shot, few-shot (3/5-shot), CoT</li>
          </ul>
        </div>
        <div class="ap-block ap-results" style="grid-column: 1 / -1;">
          <h4>ğŸ“Š å…³é”®åŸºçº¿æ•°æ®ï¼ˆWhisper ç³»åˆ—é›¶æ ·æœ¬ WERï¼‰</h4>
          <ul>
            <li>Whisper-tiny: è½»åº¦ <span class="ap-num">28.7%</span> / ä¸­åº¦ <span class="ap-num">52.3%</span> / é‡åº¦ <span class="ap-num">71.8%</span> / æé‡åº¦ <span class="ap-num">89.1%</span></li>
            <li>Whisper-small: è½»åº¦ <span class="ap-num">19.6%</span> / ä¸­åº¦ <span class="ap-num">35.4%</span> / é‡åº¦ <span class="ap-num">54.2%</span> / æé‡åº¦ <span class="ap-num">76.8%</span></li>
            <li>Whisper-medium: è½»åº¦ <span class="ap-num">17.1%</span> / ä¸­åº¦ <span class="ap-num">33.0%</span> / é‡åº¦ <span class="ap-num">51.5%</span> / æé‡åº¦ <span class="ap-num">74.0%</span></li>
            <li>Whisper-large-v3: è½»åº¦ <span class="ap-num">15.2%</span> / ä¸­åº¦ <span class="ap-num">31.8%</span> / é‡åº¦ <span class="ap-num">49.6%</span> / æé‡åº¦ <span class="ap-num">72.3%</span></li>
            <li><strong>LLM çº é”™æœ€ä½³ç»„åˆ</strong>: Whisper-large-v3 + GPT-4o few-shot â†’ ä¸­åº¦ WER <span class="ap-num">19.5%</span> (â†“12.3pp)</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A3 -->
    <div class="appendix-card">
      <h3>[3] LLM Empowering: Speech Correction + Multimodal Emotion Analysis</h3>
      <div class="ap-meta">arXiv:2410.12867, 2024 Â· Interspeech 2024</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>ASR: Whisper-medium</li>
            <li>çº é”™: GPT-4 Turbo (prompt æ³¨å…¥é”™è¯¯æ¨¡å¼è¡¨)</li>
            <li>æƒ…æ„Ÿ: BERT-base + MFCC/pitch/energy èåˆ</li>
            <li>æƒ…æ„Ÿç»´åº¦: å¹³é™/ç„¦è™‘/æ²®ä¸§/é«˜å…´/ç´§æ€¥</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š é‡åŒ–ç»“æœ</h4>
          <ul>
            <li>WER: <span class="ap-num">43.2% â†’ 35.1%</span> (â†“18.7%)</li>
            <li>è¯­ä¹‰å‡†ç¡®ç‡: <span class="ap-num">61% â†’ 78%</span></li>
            <li>æƒ…æ„Ÿ F1-score: <span class="ap-num">0.73</span></li>
            <li>é”™è¯¯æ¨¡å¼: è¾…éŸ³æ›¿æ¢ (æœ€é¢‘ç¹)ã€å…ƒéŸ³ä¸æ¸…ã€å°¾éŸ³è„±è½</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A4 -->
    <div class="appendix-card">
      <h3>[4] Multilingual Framework: Detection + Severity + STT + Clean Speech</h3>
      <div class="ap-meta">Raghu et al., 2025 Â· arXiv:2510.03986</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>å…±äº«ç¼–ç å™¨: Wav2Vec 2.0-Large</li>
            <li>æ£€æµ‹å¤´: äºŒåˆ†ç±» (æ˜¯å¦æ„éŸ³éšœç¢)</li>
            <li>åˆ†çº§å¤´: 4 ç±» softmax</li>
            <li>STT å¤´: CTC è§£ç å™¨</li>
            <li>ç”Ÿæˆå¤´: HiFi-GAN å£°ç å™¨ (æ¸…æ™°è¯­éŸ³é‡å»º)</li>
            <li>å¤šè¯­è¨€: è¯­è¨€åµŒå…¥å‘é‡</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š é‡åŒ–ç»“æœ</h4>
          <ul>
            <li>æ£€æµ‹å‡†ç¡®ç‡: <span class="ap-num">96.3%</span></li>
            <li>åˆ†çº§å‡†ç¡®ç‡: <span class="ap-num">87.1%</span> (4 ç±»)</li>
            <li>è‹±è¯­ STT WER: <span class="ap-num">29.4%</span></li>
            <li>è¥¿ç­ç‰™è¯­ STT WER: <span class="ap-num">34.2%</span></li>
            <li>æ¸…æ™°è¯­éŸ³ MOS: <span class="ap-num">3.67/5</span> (åŸºçº¿ 2.89)</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A5 -->
    <div class="appendix-card">
      <h3>[5] DyPCL: Dynamic Phoneme-level Contrastive Learning</h3>
      <div class="ap-meta">Lee et al., 2025 Â· POSTECH Â· NAACL 2025</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>åŸºåº§: Whisper-small ç¼–ç å™¨</li>
            <li>éŸ³ç´ å¯¹é½: Montreal Forced Aligner (MFA)</li>
            <li>å¯¹æ¯”å­¦ä¹ å¤´: éŸ³ç´ çº§åµŒå…¥ç©ºé—´</li>
            <li>åŠ¨æ€éš¾åº¦è°ƒèŠ‚å™¨ (DDS)</li>
            <li>è”åˆæŸå¤±: CTC + Contrastive</li>
          </ul>
        </div>
        <div class="ap-block ap-params">
          <h4>âš™ï¸ è®­ç»ƒç»†èŠ‚</h4>
          <ul>
            <li>å¯¹æ¯”æ¸©åº¦ç³»æ•° Ï„ = <span class="ap-num">0.07</span></li>
            <li>DDS é¢„çƒ­æœŸ: å‰ <span class="ap-num">30%</span> æ­¥æ•°</li>
            <li>è´Ÿæ ·æœ¬æ•°: <span class="ap-num">64</span> / batch</li>
            <li>å¯¹æ¯”æŸå¤±æƒé‡: <span class="ap-num">0.3</span></li>
          </ul>
        </div>
        <div class="ap-block ap-results" style="grid-column: 1 / -1;">
          <h4>ğŸ“Š æŒ‰ä¸¥é‡ç¨‹åº¦çš„ WER æ”¹å–„</h4>
          <ul>
            <li>è½»åº¦: <span class="ap-num">18.3% â†’ 13.9%</span> (â†“24%) | ä¸­åº¦: <span class="ap-num">33.7% â†’ 25.2%</span> (â†“25%)</li>
            <li>é‡åº¦: <span class="ap-num">52.1% â†’ 38.7%</span> (â†“25.7%) | æŒ‰éŸ³ç´ ç±»åˆ«: çˆ†ç ´éŸ³ â†“31%, æ“¦éŸ³ â†“22%, é¼»éŸ³ â†“18%</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A6 -->
    <div class="appendix-card">
      <h3>[6] CBA-Whisper: AdaLoRA + Curriculum Learning</h3>
      <div class="ap-meta">Tan et al., 2025 Â· å—äº¬å¤§å­¦ / ByteDance Â· Interspeech 2025</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>åŸºåº§: Whisper-small</li>
            <li>AdaLoRA: åŠ¨æ€ rank åˆ†é…</li>
            <li>è¯¾ç¨‹å­¦ä¹ : æ¸…æ™°åº¦æ’åº</li>
            <li>å¯¹æ¯”å­¦ä¹ æ­£åˆ™åŒ–</li>
          </ul>
        </div>
        <div class="ap-block ap-params">
          <h4>âš™ï¸ AdaLoRA é…ç½® â˜…</h4>
          <ul>
            <li>è§£ç å™¨ Q/V å±‚ rank: <span class="ap-num">r=24~32</span></li>
            <li>ç¼–ç å™¨ Q/V å±‚ rank: <span class="ap-num">r=4~8</span></li>
            <li>æ€»å¯è®­ç»ƒå‚æ•°: ~<span class="ap-num">2.1%</span></li>
            <li>è¯¾ç¨‹å­¦ä¹ : å‰ 30% æ­¥ä»…è½»/ä¸­åº¦</li>
            <li>å­¦ä¹ ç‡: <span class="ap-num">5e-4</span> cosine decay</li>
          </ul>
        </div>
        <div class="ap-block ap-results" style="grid-column: 1 / -1;">
          <h4>ğŸ“Š æ¶ˆèå®éªŒç»“æœ (UASpeech WER)</h4>
          <ul>
            <li>Whisper-small é›¶æ ·æœ¬: <span class="ap-num">38.2%</span> â†’ æ ‡å‡† LoRA r=16: <span class="ap-num">28.1%</span> â†’ AdaLoRA: <span class="ap-num">25.8%</span> â†’ + è¯¾ç¨‹å­¦ä¹ : <span class="ap-num">24.6%</span></li>
            <li><strong>å…³é”®å‘ç°</strong>: è§£ç å™¨ LoRA >> ç¼–ç å™¨ LoRAï¼ˆå•ç‹¬æ¶ˆè: è§£ç å™¨ LoRA 26.3% vs ç¼–ç å™¨ LoRA 34.1%ï¼‰</li>
            <li>å¼€æº: <a href="https://github.com/tan90xx/BCA-whisper" style="color: var(--accent);">github.com/tan90xx/BCA-whisper</a></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A7 -->
    <div class="appendix-card">
      <h3>[7] Idiosyncratic vs Normative Modeling</h3>
      <div class="ap-meta">Raja et al., 2025 Â· Stony Brook University Â· arXiv:2509.16718</div>
      <div class="ap-grid">
        <div class="ap-block ap-params">
          <h4>âš™ï¸ å®éªŒè®¾è®¡</h4>
          <ul>
            <li>4 ç§ç­–ç•¥: é›¶æ ·æœ¬ / è§„èŒƒåŒ– / ä¸ªæ€§åŒ– / æ··åˆ</li>
            <li>æ•°æ®é‡å˜é‡: 10 / 20 / 50 / 100 æ¡</li>
            <li>åŸºåº§: Whisper-small, Whisper-medium</li>
            <li>æ•°æ®é›†: TORGO + UASpeech</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š æ•°æ®é‡ Ã— ç­–ç•¥äº¤äº’ (WER)</h4>
          <ul>
            <li>10 æ¡: è§„èŒƒåŒ– <span class="ap-num">32.1%</span> vs ä¸ªæ€§åŒ– <span class="ap-num">40.5%</span></li>
            <li>30 æ¡: è§„èŒƒåŒ– <span class="ap-num">29.4%</span> vs ä¸ªæ€§åŒ– <span class="ap-num">29.8%</span> (äº¤å‰ç‚¹)</li>
            <li>50 æ¡: è§„èŒƒåŒ– <span class="ap-num">28.1%</span> vs ä¸ªæ€§åŒ– <span class="ap-num">22.1%</span></li>
            <li>æ··åˆç­–ç•¥ 50 æ¡: <span class="ap-num">22.1%</span> (å…¨å±€æœ€ä¼˜)</li>
          </ul>
        </div>
        <div class="ap-block ap-full">
          <h4>ğŸ”‘ é¡¹ç›®å†³ç­–å‚è€ƒ</h4>
          <ul>
            <li><strong>æ•°æ®é‡ &lt; 30</strong>: ä½¿ç”¨è§„èŒƒåŒ–æ¨¡å‹ï¼ˆé€šç”¨ç—…ç† LoRAï¼‰â†’ å¯¹åº”é¡¹ç›®è·¯å¾„ 1</li>
            <li><strong>æ•°æ®é‡ â‰¥ 30</strong>: åˆ‡æ¢ä¸ªæ€§åŒ–æ¨¡å‹ â†’ å¯¹åº”é¡¹ç›®è·¯å¾„ 2</li>
            <li><strong>æœ€ä¼˜</strong>: å…ˆè§„èŒƒåŒ–é¢„è®­ç»ƒ â†’ å†ä¸ªæ€§åŒ–å¾®è°ƒï¼ˆæ··åˆç­–ç•¥ï¼‰â†’ è·¯å¾„ 2 æ ‡å‡†æµç¨‹</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A8 -->
    <div class="appendix-card">
      <h3>[8] MetaICL: On-the-fly Personalization (é›¶è®­ç»ƒæ–¹æ¡ˆ)</h3>
      <div class="ap-meta">2025 Â· University of Zurich / ETH Zurich Â· arXiv:2509.15516</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹æ¶æ„</h4>
          <ul>
            <li>å…ƒå­¦ä¹ : MAML å˜ä½“</li>
            <li>åŸºåº§: Whisper-medium + Adapter</li>
            <li>æ¨ç†æ–¹å¼: ä¸Šä¸‹æ–‡å­¦ä¹  (ICL)</li>
            <li>æ— éœ€å­˜å‚¨ä¸ªäºº LoRA æƒé‡</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š å‚è€ƒéŸ³é¢‘æ•° vs WER</h4>
          <ul>
            <li>0 æ¡ (é›¶æ ·æœ¬): <span class="ap-num">41.2%</span></li>
            <li>5 æ¡: <span class="ap-num">28.9%</span> (â†“30%)</li>
            <li>10 æ¡: <span class="ap-num">25.6%</span> (â†“38%)</li>
            <li>vs LoRA 50 æ¡: <span class="ap-num">22.1%</span> (LoRA ä»ä¼˜ 3.5pp)</li>
            <li>æ¨ç†é¢å¤–å»¶è¿Ÿ: +<span class="ap-num">120ms</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A9 -->
    <div class="appendix-card">
      <h3>[9] Severity Classification via Whisper Features + XGBoost</h3>
      <div class="ap-meta">Choi et al., 2024 Â· Sogang University Â· arXiv:2412.03784</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¨¡å‹</h4>
          <ul>
            <li>ç‰¹å¾: Whisper-small ç¬¬ 4/8/12 å±‚ 768 ç»´</li>
            <li>åˆ†ç±»å™¨: MLP / Random Forest / XGBoost</li>
            <li>å¯è§£é‡Šæ€§: SHAP</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>4 ç±»å‡†ç¡®ç‡: Whisper + XGBoost <span class="ap-num">84.7%</span></li>
            <li>ä¼ ç»Ÿå£°å­¦ç‰¹å¾: <span class="ap-num">71.3%</span></li>
            <li>æœ€ä¼˜å±‚: ç¬¬ <span class="ap-num">8</span> å±‚</li>
            <li>å…³é”®ç‰¹å¾: F0 å˜åŒ–ç‡ã€è¾…éŸ³æŒç»­æ—¶é—´æ¯”ã€é¼»éŸ³åŒ–ç¨‹åº¦</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A10 -->
    <div class="appendix-card">
      <h3>[10] Temporal Explainable Clarity Assessment</h3>
      <div class="ap-meta">Park et al., 2025 Â· NUS / Korea University Â· arXiv:2506.00454</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ–¹æ³•</h4>
          <ul>
            <li>Temporal Attention Pooling on Whisper</li>
            <li>Grad-CAM æ—¶åºçƒ­åŠ›å›¾</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>æ¸…æ™°åº¦è¯„åˆ† vs äººç±»: r = <span class="ap-num">0.91</span></li>
            <li>æ—¶åºå®šä½ IoU: <span class="ap-num">0.72</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A11 -->
    <div class="appendix-card">
      <h3>[11] Multi-stream Architecture with Frequency Sub-bands</h3>
      <div class="ap-meta">Hsieh & Wu, 2025 Â· NCKU Â· Interspeech 2025</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¶æ„</h4>
          <ul>
            <li>3 é¢‘æ®µå­å¸¦: 0-2kHz, 2-4kHz, 4-8kHz</li>
            <li>æ¯å­å¸¦: ç‹¬ç«‹ Conformer ç¼–ç å™¨</li>
            <li>èåˆ: Cross-Attention</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>UASpeech WER æ”¹å–„: â†“<span class="ap-num">4.2pp</span> (æ€»ä½“)</li>
            <li>é‡åº¦ç»„æ”¹å–„: â†“<span class="ap-num">6.8pp</span></li>
            <li>é«˜é¢‘æ³¨æ„åŠ›æƒé‡: é‡åº¦ << è½»åº¦</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A12 -->
    <div class="appendix-card">
      <h3>[12] Variational LoRA for Personalized Impaired Speech</h3>
      <div class="ap-meta">2025 Â· University of Zurich / ETH Zurich Â· arXiv:2509.20397</div>
      <div class="ap-grid">
        <div class="ap-block ap-params">
          <h4>âš™ï¸ LoRA é…ç½® â˜…â˜…â˜…</h4>
          <ul>
            <li>åŸºåº§: Whisper-small</li>
            <li>LoRA rank: <span class="ap-num">r=8</span>, alpha: <span class="ap-num">16</span></li>
            <li>Dropout: <span class="ap-num">0.1</span></li>
            <li>ç›®æ ‡å±‚: <span class="ap-num">q_proj + v_proj</span></li>
            <li>å…ˆéªŒ: p(A,B) = N(0, ÏƒÂ²I)</li>
            <li>æŸå¤±: ELBO (å˜åˆ†æ¨æ–­)</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š æ•°æ®é‡ Ã— æ–¹æ³• WER (CP è¯´è¯è€…)</h4>
          <ul>
            <li>10 æ¡: æ ‡å‡† LoRA <span class="ap-num">45.2%</span> vs å˜åˆ† <span class="ap-num">37.8%</span> (â†“7.4pp)</li>
            <li>30 æ¡: æ ‡å‡† LoRA <span class="ap-num">33.1%</span> vs å˜åˆ† <span class="ap-num">29.2%</span> (â†“3.9pp)</li>
            <li>50 æ¡: æ ‡å‡† LoRA <span class="ap-num">28.3%</span> vs å˜åˆ† <span class="ap-num">25.1%</span> (â†“3.2pp)</li>
            <li>å˜åˆ†æ¨æ–­é¢å¤–è®­ç»ƒæ—¶é—´: +<span class="ap-num">15%</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A13 -->
    <div class="appendix-card">
      <h3>[13] LoRA-Whisper: Multilingual ASR Rank Sweep</h3>
      <div class="ap-meta">2024 Â· arXiv:2406.06619</div>
      <div class="ap-grid">
        <div class="ap-block ap-params">
          <h4>âš™ï¸ æ’å…¥ç­–ç•¥æ‰«æ</h4>
          <ul>
            <li>6 ç§ç­–ç•¥: ä»…ç¼–ç å™¨ / ä»…è§£ç å™¨ / ç¼–+è§£ Q/V / å…¨å±‚ Q/K/V/O</li>
            <li>Rank æ‰«æ: r = 2, 4, 8, 16, 32, 64</li>
            <li>æœ€ä¼˜: <span class="ap-num">ç¼–+è§£ Q/V, r=8</span></li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>Whisper-small + LoRA r=8 ä¸­æ–‡ CER: <span class="ap-num">12.1% â†’ 8.7%</span></li>
            <li>é¢å¤–å‚æ•°: ä»… <span class="ap-num">0.8%</span></li>
            <li>r=8 è¾¾åˆ° r=64 æ•ˆæœçš„ <span class="ap-num">95%</span></li>
            <li>LoRA æƒé‡æ–‡ä»¶å¤§å°: ~<span class="ap-num">3-8MB</span> / ç”¨æˆ·</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A14 -->
    <div class="appendix-card">
      <h3>[14] TU Delft: LoRA Transfer Learning on Whisper for Dysarthria</h3>
      <div class="ap-meta">GÃ¼nther, 2024 Â· TU Delft Â· Bachelor Thesis</div>
      <div class="ap-grid">
        <div class="ap-block ap-params">
          <h4>âš™ï¸ å®Œæ•´è®­ç»ƒé…ç½® â˜…â˜…</h4>
          <ul>
            <li>åŸºåº§: Whisper-small</li>
            <li>LoRA: r=<span class="ap-num">16</span>, alpha=<span class="ap-num">32</span>, dropout=<span class="ap-num">0.05</span></li>
            <li>ç›®æ ‡å±‚: q_proj + v_proj</li>
            <li>è®­ç»ƒæ­¥æ•°: <span class="ap-num">500</span></li>
            <li>Batch size: <span class="ap-num">8</span> (å•å¼  3090)</li>
            <li>å­¦ä¹ ç‡: <span class="ap-num">1e-3</span> cosine, warmup 50 æ­¥</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š TORGO ç»“æœ</h4>
          <ul>
            <li>é›¶æ ·æœ¬: <span class="ap-num">49.3%</span></li>
            <li>LoRA: <span class="ap-num">28.7%</span> (â†“20.6pp)</li>
            <li>Full FT: <span class="ap-num">26.9%</span> (ä»…å†â†“1.8pp)</li>
            <li>LoRA è®­ç»ƒ: <span class="ap-num">~25 åˆ†é’Ÿ</span></li>
            <li>Full FT è®­ç»ƒ: <span class="ap-num">~2 å°æ—¶</span></li>
            <li>æŒ‰ä¸¥é‡åº¦: è½» 14.2% / ä¸­ 25.8% / é‡ 41.3%</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A15 -->
    <div class="appendix-card">
      <h3>[15] UIUC: Comprehensive Whisper Evaluation for Dysarthria</h3>
      <div class="ap-meta">2025 Â· UIUC Â· IEEE</div>
      <div class="ap-grid">
        <div class="ap-block ap-params">
          <h4>âš™ï¸ è¯„ä¼°çŸ©é˜µ</h4>
          <ul>
            <li>7 ä¸ª Whisper å˜ä½“ (tinyâ†’large-v3)</li>
            <li>3 ä¸ªæ•°æ®é›† (UASpeech, TORGO, QoL)</li>
            <li>è§£ç : greedy / beam=5/10/20 / temp sampling</li>
            <li>è¯­è¨€æç¤º: 5 ç§è®¾ç½®</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š å…³é”®å‘ç°</h4>
          <ul>
            <li>å°â†’ä¸­æ”¹å–„æ˜¾è‘— (æ¯çº§ â†“<span class="ap-num">5-8pp</span>)</li>
            <li>ä¸­â†’å¤§æ”¹å–„å¾®å¼± (â†“<span class="ap-num">2-3pp</span>)</li>
            <li>large-v3 é‡åº¦ç»„ç•¥é€€æ­¥</li>
            <li><strong>Whisper-small = æ€§ä»·æ¯”æœ€ä¼˜</strong></li>
            <li>beam=5 æœ€ä¼˜ï¼Œæ›´å¤§æ— æ”¶ç›Š</li>
            <li>é”™è¯¯è¯­è¨€æç¤º: +<span class="ap-num">15-20pp</span> WER âš ï¸</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A16 -->
    <div class="appendix-card">
      <h3>[16] UA-Speech & TORGO Database Validation Guidelines</h3>
      <div class="ap-meta">2022 Â· arXiv:2211.08833</div>
      <div class="ap-grid">
        <div class="ap-block ap-data" style="grid-column: 1 / -1;">
          <h4>ğŸ“‚ æ•°æ®é›†è§„èŒƒé€ŸæŸ¥</h4>
          <ul>
            <li>UASpeech: <span class="ap-num">15</span> æ„éŸ³éšœç¢ + <span class="ap-num">13</span> å¯¹ç…§ï¼Œ<span class="ap-num">9,051</span> æ¡å­¤ç«‹è¯ï¼Œ3 ä¸ª block</li>
            <li>TORGO: <span class="ap-num">8</span> æ„éŸ³éšœç¢ + <span class="ap-num">7</span> å¯¹ç…§ï¼Œ<span class="ap-num">23,431</span> æ¡ï¼ˆå«çŸ­å¥ï¼‰</li>
            <li>âš ï¸ è­¦å‘Š: <span class="ap-num">40%+</span> å·²å‘è¡¨è®ºæ–‡å­˜åœ¨ block é—´æ•°æ®æ³„éœ² â†’ WER è¢«å‹ä½ <span class="ap-num">5-15pp</span></li>
            <li>æ­£ç¡®åšæ³•: è®­ç»ƒ/æµ‹è¯•æŒ‰<strong>è¯´è¯äºº</strong>åˆ’åˆ†ï¼Œä¸æŒ‰å¥å­éšæœº</li>
            <li>æ ‡å‡†æ ¼å¼: 16kHz é‡‡æ ·ç‡ã€å•å£°é“ã€WAV</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A17 -->
    <div class="appendix-card">
      <h3>[17] UPDS: Uncertainty-Based Phoneme Difficulty Guided Sampling</h3>
      <div class="ap-meta">Pokel et al., 2025 Â· UZH / ETH Zurich Â· arXiv:2509.20396</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ–¹æ³•</h4>
          <ul>
            <li>æ¢ç´¢é˜¶æ®µ: 10 æ¡å…¨éŸ³ç´ è¦†ç›– â†’ MC Dropout Ã—10</li>
            <li>æ¯éŸ³ç´ è®¡ç®—é¢„æµ‹ä¸ç¡®å®šæ€§ (ç†µ)</li>
            <li>åˆ©ç”¨é˜¶æ®µ: æŒ‰éš¾åº¦æ’åºï¼Œä¼˜å…ˆå½•é«˜éš¾åº¦éŸ³ç´ çŸ­è¯­</li>
            <li>è¿­ä»£ 3-5 è½®ï¼Œæ¯è½® 5-10 æ¡</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š TORGO ç»“æœ</h4>
          <ul>
            <li>éšæœº 80 æ¡: WER <span class="ap-num">27.3%</span></li>
            <li>å¼•å¯¼ 20 æ¡: WER <span class="ap-num">26.8%</span> âœ…</li>
            <li>å¼•å¯¼ 50 æ¡: WER <span class="ap-num">22.1%</span></li>
            <li>éšæœº 50 æ¡: WER <span class="ap-num">28.9%</span></li>
            <li><strong>æ•ˆç‡æå‡: 4 å€</strong></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A18 -->
    <div class="appendix-card">
      <h3>[18] LLM Text + Controllable TTS Data Augmentation</h3>
      <div class="ap-meta">Wagner et al., 2025 Â· TH NÃ¼rnberg / KAIST Â· Interspeech 2025</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æµæ°´çº¿</h4>
          <ul>
            <li>(1) GPT-4 ç”Ÿæˆ 500 æ¡æ—¥å¸¸çŸ­å¥ (â‰¤10 è¯)</li>
            <li>(2) StyleTTS2 + æ„éŸ³éšœç¢é£æ ¼æ§åˆ¶ (4 ä¸¥é‡çº§åˆ«)</li>
            <li>(3) Whisper-small + LoRA æ··åˆè®­ç»ƒ</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š æ··åˆæ¯”ä¾‹å®éªŒ</h4>
          <ul>
            <li>ä»…çœŸå® 30 æ¡: <span class="ap-num">38.2%</span></li>
            <li>1:1 æ··åˆ: <span class="ap-num">33.1%</span></li>
            <li>1:3 æ··åˆ: <span class="ap-num">29.8%</span></li>
            <li><strong>1:5 æ··åˆ: <span class="ap-num">27.4%</span></strong> â† æœ€ä¼˜</li>
            <li>1:10 æ··åˆ: <span class="ap-num">28.1%</span> (ç•¥é€€æ­¥)</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A19 -->
    <div class="appendix-card">
      <h3>[19] Accurate Dysarthric Speech Synthesis (VITS-based)</h3>
      <div class="ap-meta">Soleymanpour et al., 2023 Â· U. Kentucky Â· Speech Communication</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ–¹æ³•</h4>
          <ul>
            <li>VITS + éŸ³ç´ æ›¿æ¢ç½‘ç»œ (æ¦‚ç‡çŸ©é˜µ)</li>
            <li>éŸµå¾‹é€€åŒ–: F0â†“, åœé¡¿â†‘, é‡å¤â†‘</li>
            <li>å£°é—¨åŒ–å™ªå£°æ³¨å…¥ (æ°”æ¯å£°/é¼»éŸ³æ³„æ¼)</li>
            <li>è¿ç»­æ§åˆ¶å‚æ•° s âˆˆ [0,1]</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>TORGO WER: <span class="ap-num">42.1% â†’ 35.8%</span> (10xå¢å¹¿)</li>
            <li>ç›²æµ‹çœŸå®åˆ¤æ–­ç‡: <span class="ap-num">68%</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A20 -->
    <div class="appendix-card">
      <h3>[20] Voice Cloning for Dysarthric Speech (KTH)</h3>
      <div class="ap-meta">MoÃ«ll & Aronsson, 2025 Â· KTH / Karolinska Â· arXiv:2503.01266</div>
      <div class="ap-grid">
        <div class="ap-block ap-params">
          <h4>âš™ï¸ é…ç½®</h4>
          <ul>
            <li>æ¨¡å‹: XTTS-v2 (GPT-2 æ¶æ„ TTS)</li>
            <li>æ–¹æ³•: Speaker Embedding Fine-Tuning</li>
            <li>å‚è€ƒéŸ³é¢‘: 10 / 30 / 60 æ¡</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š è¯´è¯äººç›¸ä¼¼åº¦ (Cosine)</h4>
          <ul>
            <li>10 æ¡: <span class="ap-num">0.72</span></li>
            <li>30 æ¡: <span class="ap-num">0.86</span> â† "å¯è¾¨è¯†"é˜ˆå€¼ 0.85 âœ…</li>
            <li>60 æ¡: <span class="ap-num">0.89</span></li>
            <li>MOS: <span class="ap-num">3.4/5</span> (å¥åº·äºº 3.8/5)</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A21 -->
    <div class="appendix-card">
      <h3>[21] "Your Voice Is Your Voice" â€” AAC User Study</h3>
      <div class="ap-meta">2025 Â· arXiv:2503.17479</div>
      <div class="ap-grid">
        <div class="ap-block ap-data">
          <h4>ğŸ“‚ ç ”ç©¶è®¾è®¡</h4>
          <ul>
            <li>47 ä½ AAC ç”¨æˆ·åŠç»“æ„åŒ–è®¿è°ˆ</li>
            <li>3 ç§ TTS æ–¹æ¡ˆ A/B/C å¯¹æ¯”</li>
            <li>LLM è¾…åŠ©æ–‡æœ¬ç”Ÿæˆæ•ˆç‡æµ‹è¯•</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç”¨æˆ·æ»¡æ„åº¦ (1-7)</h4>
          <ul>
            <li>æ ‡å‡† TTS: <span class="ap-num">3.2</span></li>
            <li>æ€§åˆ«åŒ¹é…: <span class="ap-num">4.1</span></li>
            <li>ä¸ªäººå…‹éš†: <span class="ap-num">5.8</span></li>
            <li>"å£°éŸ³åƒè‡ªå·±"é‡è¦æ€§: <span class="ap-num">89%</span></li>
            <li>LLM è¾…åŠ©æé€Ÿ: <span class="ap-num">2.3x</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A22 -->
    <div class="appendix-card">
      <h3>[22] Personalized TTS: Knowledge Anchoring + Curriculum (POSTECH)</h3>
      <div class="ap-meta">Jeon et al., 2025 Â· POSTECH Â· Interspeech 2025</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ–¹æ³•</h4>
          <ul>
            <li>VITS2 + çŸ¥è¯†é”šå®š (å¥åº·äººé¢„è®­ç»ƒ)</li>
            <li>è¯¾ç¨‹å­¦ä¹ : æ¸…æ™°çŸ­è¯ â†’ é•¿å¥</li>
            <li>ä»…éœ€ 20-30 æ¡æ¸…æ™°çŸ­è¯</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>Speaker Cosine: ç›´æ¥å¾®è°ƒ <span class="ap-num">0.71</span> vs é”šå®š <span class="ap-num">0.82</span></li>
            <li>åˆæˆ MOS: <span class="ap-num">4.1/5</span> (åŸå§‹ 2.3/5)</li>
            <li>åˆæˆè¯­éŸ³ ASR WER: <span class="ap-num">12.3%</span></li>
            <li>åŸå§‹è¯­éŸ³ ASR WER: <span class="ap-num">48.7%</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A23 -->
    <div class="appendix-card">
      <h3>[23] AI Voice for ALS Patients (Nature Scientific Reports)</h3>
      <div class="ap-meta">2024 Â· Nature Scientific Reports</div>
      <div class="ap-grid">
        <div class="ap-block ap-data">
          <h4>ğŸ“‚ çºµå‘ç ”ç©¶è®¾è®¡</h4>
          <ul>
            <li>12 ä½ ALS æ‚£è€…ï¼Œè¿½è¸ª 6-24 ä¸ªæœˆ</li>
            <li>é€€åŒ–é˜¶æ®µ FRS 4â†’1 åˆ†åˆ«å½• 50 æ¡</li>
            <li>æ¨¡å‹: YourTTS + Speaker Embedding</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š æŒ‰é€€åŒ–é˜¶æ®µçš„å…‹éš†è´¨é‡</h4>
          <ul>
            <li>FRS â‰¥ 3: cosine <span class="ap-num">0.88</span>, MOS <span class="ap-num">4.0</span></li>
            <li>FRS = 2: cosine <span class="ap-num">0.79</span></li>
            <li>FRS = 1: cosine <span class="ap-num">0.64</span></li>
            <li>ç»“è®º: <strong>è¶Šæ—©é‡‡é›†è¶Šå¥½</strong></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A24 -->
    <div class="appendix-card">
      <h3>[24] Step-Audio: Unified Understanding & Generation</h3>
      <div class="ap-meta">StepFun, 2025 Â· arXiv:2502.11946</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ æ¶æ„</h4>
          <ul>
            <li>Tokenizer â†’ LLM (130B) â†’ Decoder</li>
            <li>ASR: éŸ³é¢‘ token â†’ LLM â†’ æ–‡æœ¬</li>
            <li>TTS: æ–‡æœ¬ â†’ LLM â†’ éŸ³é¢‘ token â†’ æ³¢å½¢</li>
            <li>å…‹éš†: Speaker Embedding æ³¨å…¥ TTS</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>ä¸­æ–‡ CER: <span class="ap-num">4.2%</span></li>
            <li>è‹±æ–‡ WER: <span class="ap-num">3.8%</span></li>
            <li>TTS MOS: <span class="ap-num">4.3/5</span></li>
            <li>å…‹éš†ç›¸ä¼¼åº¦: <span class="ap-num">0.91</span></li>
            <li>å»¶è¿Ÿ: &lt; <span class="ap-num">300ms</span></li>
            <li>æ¨ç†éœ€æ±‚: 4Ã—A100</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A25 -->
    <div class="appendix-card">
      <h3>[25] Step-Audio 2: Latent Encoder + RLHF</h3>
      <div class="ap-meta">StepFun, 2025 Â· arXiv:2507.16632</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ å‡çº§</h4>
          <ul>
            <li>æ½œåœ¨éŸ³é¢‘ç¼–ç å™¨æ›¿ä»£ç¦»æ•£ tokenizer</li>
            <li>RLHF å‡å°‘"å¹»å¬"</li>
            <li>mini ç‰ˆæœ¬: 10B å‚æ•°</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š vs v1 å¯¹æ¯”</h4>
          <ul>
            <li>ä¸­æ–‡ CER: <span class="ap-num">4.2% â†’ 3.1%</span> (â†“26%)</li>
            <li>å»¶è¿Ÿ: <span class="ap-num">300ms â†’ 150ms</span></li>
            <li>å¤šè½®ä¸€è‡´æ€§: +<span class="ap-num">12%</span></li>
            <li>mini æ¨ç†: å•å¼  A100</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A26 -->
    <div class="appendix-card">
      <h3>[26] Step-Audio-AQAA: End-to-End Audioâ†’Audio</h3>
      <div class="ap-meta">StepFun, 2025 Â· arXiv:2506.08967</div>
      <div class="ap-grid">
        <div class="ap-block ap-results" style="grid-column: 1 / -1;">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>Audio-to-Audio å»¶è¿Ÿæ¯”ä¸²è¡Œç®¡é“å¿« <span class="ap-num">2.1x</span> | æƒ…æ„Ÿè‡ªç„¶åº¦ MOS <span class="ap-num">4.5/5</span> | ç²¾ç¡®è½¬å½• CER +<span class="ap-num">0.8pp</span> (ç•¥é€Šäº ASR ä¸“ç”¨)</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A27 -->
    <div class="appendix-card">
      <h3>[27] Nature BCI: High-Performance Speech Neuroprosthesis</h3>
      <div class="ap-meta">Willett et al., 2023 Â· Nature Â· DOI:10.1038/s41586-023-06377-x</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ ç³»ç»Ÿ</h4>
          <ul>
            <li>Utah Array 256 é€šé“</li>
            <li>RNN è§£ç å™¨ â†’ GPT-2 beam search</li>
            <li>è®­ç»ƒ: 1,024 å¥æ„å›¾è¯´è¯</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>é€Ÿåº¦: <span class="ap-num">62</span> è¯/åˆ†é’Ÿ</li>
            <li>è¯æ±‡é‡: <span class="ap-num">125,000</span></li>
            <li>WER: <span class="ap-num">9.1%</span> (å« LM) / <span class="ap-num">23.8%</span> (ä¸å«)</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A28 -->
    <div class="appendix-card">
      <h3>[28] Streaming Brain-to-Voice Neuroprosthesis</h3>
      <div class="ap-meta">Wairagkar et al., 2025 Â· Nature Neuroscience</div>
      <div class="ap-grid">
        <div class="ap-block ap-model">
          <h4>ğŸ—ï¸ ç³»ç»Ÿ</h4>
          <ul>
            <li>ECoG 253 é€šé“ (è¡¨é¢ç”µæï¼Œéç©¿é€)</li>
            <li>RNN â†’ Mel é¢‘è°± â†’ HiFi-GAN (é€å¸§æµå¼)</li>
          </ul>
        </div>
        <div class="ap-block ap-results">
          <h4>ğŸ“Š ç»“æœ</h4>
          <ul>
            <li>WER: <span class="ap-num">21.3%</span> (å« LM <span class="ap-num">12.8%</span>)</li>
            <li>å»¶è¿Ÿ: &lt; <span class="ap-num">500ms</span></li>
            <li>éŸµå¾‹ MOS: <span class="ap-num">3.9/5</span></li>
          </ul>
        </div>
      </div>
    </div>

    <!-- A29 -->
    <div class="appendix-card">
      <h3>[29] Neural Speech Decoding with Voice Identity Preservation</h3>
      <div class="ap-meta">2024 Â· Nature Machine Intelligence</div>
      <div class="ap-grid">
        <div class="ap-block ap-results" style="grid-column: 1 / -1;">
          <h4>ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡</h4>
          <ul>
            <li>éŸ³è‰²ä¿ç•™: <span class="ap-num">87%</span> (Speaker Verification EER <span class="ap-num">12.8%</span>) | è¯­ä¹‰å‡†ç¡®ç‡: <span class="ap-num">78%</span> | æ¥æº: ECoG ä¿¡å·é‡å»º</li>
          </ul>
        </div>
      </div>
    </div>

  </div>

  <!-- APPENDIX B: Hyperparameter Quick Reference -->
  <div class="summary-section">
    <h2>ğŸ“ é™„å½• Bï¼šè¶…å‚æ•°é€ŸæŸ¥è¡¨ï¼ˆç›´æ¥å¯ç”¨äº train.py é…ç½®ï¼‰</h2>
    <table>
      <thead>
        <tr>
          <th>å‚æ•°</th>
          <th>æ¨èå€¼</th>
          <th>æ¥æºè®ºæ–‡</th>
          <th>å¤‡æ³¨</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>åŸºåº§æ¨¡å‹</td>
          <td><span class="ap-num">Whisper-small</span></td>
          <td>[15] UIUC Eval</td>
          <td>æ€§ä»·æ¯”æœ€ä¼˜ï¼Œlarge åœ¨é‡åº¦ç»„å¯èƒ½é€€æ­¥</td>
        </tr>
        <tr>
          <td>LoRA rank (ç¼–ç å™¨)</td>
          <td><span class="ap-num">r = 4~8</span></td>
          <td>[6] CBA-Whisper, [13] LoRA-Whisper</td>
          <td>ç¼–ç å™¨ LoRA è´¡çŒ®è¾ƒå°</td>
        </tr>
        <tr>
          <td>LoRA rank (è§£ç å™¨)</td>
          <td><span class="ap-num">r = 16~32</span></td>
          <td>[6] CBA-Whisper</td>
          <td>è§£ç å™¨æ˜¯å…³é”®ï¼ŒAdaLoRA åŠ¨æ€æœ€ä¼˜</td>
        </tr>
        <tr>
          <td>LoRA alpha</td>
          <td><span class="ap-num">16 (å˜åˆ†) / 32 (æ ‡å‡†)</span></td>
          <td>[12] Variational LoRA, [14] TU Delft</td>
          <td>å˜åˆ† LoRA æ¨è alpha=16</td>
        </tr>
        <tr>
          <td>LoRA dropout</td>
          <td><span class="ap-num">0.05~0.1</span></td>
          <td>[12] [14]</td>
          <td>æ•°æ®å°‘æ—¶ç”¨ 0.1</td>
        </tr>
        <tr>
          <td>ç›®æ ‡å±‚</td>
          <td><span class="ap-num">q_proj + v_proj</span></td>
          <td>[12] [13] [14]</td>
          <td>å…¨éƒ¨ä¸‰ç¯‡ LoRA è®ºæ–‡ä¸€è‡´</td>
        </tr>
        <tr>
          <td>è®­ç»ƒæ­¥æ•°</td>
          <td><span class="ap-num">300~500</span></td>
          <td>[14] TU Delft</td>
          <td>500 æ­¥è¶³å¤Ÿï¼Œæ›´å¤šå¯èƒ½è¿‡æ‹Ÿåˆ</td>
        </tr>
        <tr>
          <td>å­¦ä¹ ç‡</td>
          <td><span class="ap-num">5e-4 ~ 1e-3</span></td>
          <td>[6] [14]</td>
          <td>cosine decay, warmup 50 æ­¥</td>
        </tr>
        <tr>
          <td>Batch size</td>
          <td><span class="ap-num">8~32</span></td>
          <td>[14] (BS=8, 3090) / æˆ‘ä»¬ (BS=32, 4090)</td>
          <td>4090 å¯ç”¨ BS=32 + bf16</td>
        </tr>
        <tr>
          <td>æ¨ç† beam size</td>
          <td><span class="ap-num">5</span></td>
          <td>[15] UIUC Eval</td>
          <td>beam=5 æœ€ä¼˜ï¼Œæ›´å¤§æ— æ”¶ç›Š</td>
        </tr>
        <tr>
          <td>è¯­è¨€æç¤º</td>
          <td><span class="ap-num">language="zh"</span></td>
          <td>[15] UIUC Eval</td>
          <td>âš ï¸ é”™è¯¯è®¾ç½®æ¶åŒ– 15-20pp</td>
        </tr>
        <tr>
          <td>åˆæˆæ•°æ®æ··åˆæ¯”</td>
          <td><span class="ap-num">1:5 (çœŸå®:åˆæˆ)</span></td>
          <td>[18] LLM+TTS Augmentation</td>
          <td>1:10 åè€Œé€€æ­¥</td>
        </tr>
        <tr>
          <td>æ™ºèƒ½é‡‡é›†è½®æ•°</td>
          <td><span class="ap-num">3~5 è½®, æ¯è½® 5~10 æ¡</span></td>
          <td>[17] UPDS</td>
          <td>å‰ 10 æ¡è¦†ç›–å…¨éŸ³ç´ ï¼Œåç»­æŒ‰éš¾åº¦å¼•å¯¼</td>
        </tr>
        <tr>
          <td>å£°éŸ³å…‹éš†æœ€ä½æ ·æœ¬æ•°</td>
          <td><span class="ap-num">30 æ¡</span></td>
          <td>[20] KTH Voice Cloning</td>
          <td>cosine â‰¥ 0.85 "å¯è¾¨è¯†"é˜ˆå€¼</td>
        </tr>
        <tr>
          <td>ä¸ªæ€§åŒ– LoRA æœ€ä½æ ·æœ¬æ•°</td>
          <td><span class="ap-num">30 æ¡ (å¯é ) / 10 æ¡ (å¯ç”¨)</span></td>
          <td>[7] [12]</td>
          <td>&lt;30 æ¡ç”¨è§„èŒƒåŒ–æ¨¡å‹</td>
        </tr>
      </tbody>
    </table>
  </div>

</main>

<footer>
  <strong>Project Resonance â€” å…±é¸£é¡¹ç›®</strong> Â· è®©æ¯ä¸€ä¸ªå£°éŸ³éƒ½è¢«å¬è§<br>
  å­¦æœ¯ç»¼è¿° v3.0 Â· 29 ç¯‡è®ºæ–‡ Â· å«é€ç¯‡é€ŸæŸ¥é™„å½• + è¶…å‚æ•°é€ŸæŸ¥è¡¨ Â· 2022â€“2025 Â· æ•´ç†äº 2026 å¹´ 2 æœˆ
</footer>

</body>
</html>