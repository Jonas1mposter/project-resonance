阶段,任务,负责人,优先级,状态,预计耗时,开始日期,结束日期,依赖项,备注
环境准备,申请云GPU服务器（AutoDL/RunPod）,待定,P0,未开始,1天,,,,"推荐 A100/3090，CUDA 12.1"
环境准备,搭建Docker训练环境,待定,P0,未开始,0.5天,,,"申请云GPU服务器","Python 3.10 + PyTorch 2.1 + nvidia/cuda:12.1.1"
环境准备,安装训练依赖（transformers/peft/datasets）,待定,P0,未开始,0.5天,,,"搭建Docker训练环境","pip install transformers peft datasets soundfile librosa"
数据采集,确定目标短语列表（50-100条）,待定,P0,未开始,1天,,,,"从现有短语库中筛选高频短语"
数据采集,录制患者语音样本,待定,P0,未开始,3-5天,,,"确定目标短语列表","每条短语录2-3遍，WAV 16kHz 单声道"
数据采集,导出训练数据（音频+标注）,待定,P1,未开始,0.5天,,,"录制患者语音样本","使用App导出功能生成JSON manifest"
数据处理,音频格式统一（重采样/降噪）,待定,P1,未开始,1天,,,"导出训练数据","统一为16kHz单声道WAV"
数据处理,生成HuggingFace Dataset格式,待定,P1,未开始,0.5天,,,"音频格式统一","audio列+text列的Arrow格式"
数据处理,数据集划分（训练集/验证集）,待定,P1,未开始,0.5天,,,"生成HuggingFace Dataset格式","建议 80/20 划分"
模型训练,加载Whisper-small基座模型,待定,P0,未开始,0.5天,,,"数据集划分","openai/whisper-small，约244M参数"
模型训练,配置LoRA参数（r=16 alpha=32）,待定,P0,未开始,0.5天,,,"加载Whisper-small基座模型","target_modules: q_proj/v_proj"
模型训练,执行训练（~500 steps）,待定,P0,未开始,0.5-1天,,,"配置LoRA参数","单卡3090约30分钟，注意监控loss收敛"
模型训练,验证集评估（WER/CER）,待定,P1,未开始,0.5天,,,"执行训练","目标CER < 30%"
模型训练,导出LoRA权重文件,待定,P0,未开始,0.5天,,,"验证集评估","约8MB的adapter_model.safetensors"
模型部署,搭建FastAPI推理服务,待定,P1,未开始,1天,,,"导出LoRA权重文件","加载base+LoRA合并推理"
模型部署,编写健康检查和错误处理,待定,P2,未开始,0.5天,,,"搭建FastAPI推理服务",
模型部署,部署到GPU推理服务器,待定,P1,未开始,1天,,,"搭建FastAPI推理服务","RunPod Serverless 或 AutoDL"
模型部署,压测和性能优化,待定,P2,未开始,1天,,,"部署到GPU推理服务器","目标：单条推理 < 2秒"
前端集成,创建Edge Function代理,待定,P1,未开始,0.5天,,,"部署到GPU推理服务器","转发请求到自部署推理API"
前端集成,前端添加自定义ASR provider选项,待定,P1,未开始,1天,,,"创建Edge Function代理","settings中增加custom-lora选项"
前端集成,端到端测试,待定,P1,未开始,1天,,,"前端添加自定义ASR provider选项","录音→识别→TTS完整流程"
迭代优化,收集错误案例并补充训练数据,待定,P2,未开始,持续,,,"端到端测试","记录识别失败的case"
迭代优化,增量训练（追加数据重新LoRA）,待定,P2,未开始,持续,,,"收集错误案例","每积累20条新数据训练一轮"
迭代优化,多患者支持（每人独立LoRA权重）,待定,P2,未开始,2天,,,"增量训练","推理时按speaker_id加载对应权重"
