# 实验方法升级方案：从 v1.0 到 v2.0

**基于**：v1.0 批量评测结果（4,130 条）+ MDSC 论文（2406.10304）技术路径  
**日期**：2026-02-26

---

## 1. v1.0 实验结果分析

### 1.1 数据总览

| 维度 | 数值 |
|------|------|
| 总录音数 | 4,130 条 |
| 说话人数 | 12 位（6F + 6M） |
| 唤醒词类型 | ~20 种（小度小度、小爱同学、Hey Siri 等） |
| 指令类型 | ~100+ 种（空调控制、音量调节等） |

### 1.2 按说话人 CER 分布（从 CSV 估算）

| 说话人 | 估计样本数 | 主要表现 | 严重程度估计 |
|--------|-----------|---------|-------------|
| DF0001 | ~405 | 唤醒词 CER 约 30-50%，常见同音替换（小布→小步） | 中度 |
| DF0006 | ~404 | Hey Siri 全部 100% CER；中文唤醒词较好 | 中-重度 |
| DF0007 | ~405 | 待统计 | — |
| DF0009 | ~404 | 待统计 | — |
| DF0013 | ~405 | **极重度**：长句识别几乎完全失败，CER 常超 100% | 极重度 |
| DF0014 | ~405 | 待统计 | — |
| DM0002 | ~405 | 待统计 | — |
| DM0003 | ~781 | 混合表现：简单指令较好，复杂温控指令 CER 高 | 中-重度 |
| DM0008 | ~115 | 样本量最少 | — |
| DM0010 | ~405 | 待统计 | — |
| DM0017 | ~405 | 待统计 | — |
| DM0020 | ~405 | 简单指令表现良好，CER 0% 占比高 | 轻-中度 |

### 1.3 关键发现

#### 发现 1：严重程度分类不科学
v1.0 的「严重程度」列直接由单条 CER 阈值推算（0%=轻度, 25%=中度, ≥50%=重度），而非说话人级别的临床评估。  
**问题**：同一说话人（如 DF0001）在同一唤醒词上忽轻忽重，无法反映真实构音障碍等级。

#### 发现 2：CER 超过 100% 频繁出现
当参考文本很短（如 "E"、"T"、"低风"）而识别输出很长时，CER 超 100%。  
**问题**：CER 在短文本上不稳定，需引入**归一化 CER** 或**匹配率**指标。

#### 发现 3：中英混合唤醒词表现最差
"Hey Siri" 在几乎所有构音障碍说话人上 CER 接近 100%，因为 ASR 倾向将英文音素转写为中文字符。  
**问题**：需按语种分别评估，或将英文唤醒词排除出中文 ASR 评测。

#### 发现 4：长句指令 vs 短唤醒词差异显著
4 字唤醒词（"小度小度"）的 CER 波动远大于 10+ 字指令（"把空调温度调到二十五度"），因为长句有更多上下文约束帮助 ASR 纠错。  
**问题**：需按**文本长度分层**报告指标。

#### 发现 5：同一说话人不同短语的识别率差异巨大
如 DF0013 识别 "不感应"（3 字）CER=0%，但 "音量调大"（4 字）CER=100%。  
**问题**：识别难度与发音模式高度相关，需引入**音素级错误分析**。

---

## 2. v1.0 实验方法的缺陷

| # | 缺陷 | 影响 | 论文对标 |
|---|------|------|---------|
| 1 | 无说话人级别严重度标注 | 无法按严重度分层评测 | MDSC 论文 §3.1 使用 Frenchay 量表 + 主观可懂度评分 |
| 2 | CER 作为唯一指标 | 短文本 CER 不稳定；未区分插入/删除/替换 | 论文使用 FAR+FRR+Score 组合指标 |
| 3 | 无 Train/Test 划分 | 全量评测无法区分模型泛化能力 | 论文严格 Speaker-level 划分 |
| 4 | 无数据增强 | 小样本过拟合风险高 | 论文使用速度扰动+白噪声+频谱遮盖"三件套" |
| 5 | 单一 ASR 模型（step-asr） | 无法对比不同模型的适应能力 | 论文对比 SIC/SID/SDD 三阶段 |
| 6 | 无个性化注册语料 | 所有人共用通用模型 | 论文证明 3 分钟注册数据带来 74% 提升 |
| 7 | 无 OOV 拒识测试 | 不知道系统是否会误识别词表外语音 | test-data-standard §3.2 要求 15-20 条 OOV/人 |
| 8 | 严重度按单条 CER 赋值 | 掩盖了说话人真实障碍等级 | 论文使用双维度评估（主观+客观可懂度） |

---

## 3. v2.0 实验方法升级

### 3.1 评估指标体系升级

#### 3.1.1 核心指标（必须）

| 指标 | 定义 | 计算方式 | 目标值 |
|------|------|---------|--------|
| **CER** | 字符错误率 | `(S+D+I)/N × 100%` | 按严重度分层报告 |
| **nCER** | 归一化 CER（上限 100%） | `min(CER, 100%)` | 避免短文本膨胀 |
| **Top-1 Match** | 模糊匹配命中率 | ASR 输出与词表最近邻 = 正确短语 | ≥50% |
| **Top-3 Match** | 前 3 候选命中率 | 正确短语在 Top-3 内 | ≥75% |
| **WAcc** | 词级准确率 | `正确词数/总词数` | 补充 CER 的粒度不足 |

#### 3.1.2 拒识指标（必须）

| 指标 | 定义 | 目标值 |
|------|------|--------|
| **OOV Rejection Rate** | OOV 语料被正确拒绝的比例 | ≥80% |
| **False Acceptance Rate** | OOV 被误识别为词表内短语的比例 | ≤20% |
| **False Rejection Rate** | 词表内短语被错误拒绝的比例 | ≤15% |

#### 3.1.3 唤醒词检测指标（可选，对标 MDSC 论文）

| 指标 | 定义 | 目标值 |
|------|------|--------|
| **FAR** | 虚警率 = 误唤醒次数 / 非目标总数 | ≤5% |
| **FRR** | 漏检率 = 漏唤醒次数 / 目标总数 | ≤20% |
| **Score** | FAR + FRR 综合分 | ≤25% |

### 3.2 数据预处理升级

#### Step 1：说话人级别严重度标注

替换当前的「逐条 CER 推算」方法，采用 **双维度评估**（对标 MDSC 论文 §3.1）：

**客观可懂度**（自动计算）：
```
Speaker_CER = Σ(每条 CER × 字符数) / Σ(总字符数)   # 加权平均，消除短文本偏差
```

| Speaker_CER 区间 | 客观等级 |
|-----------------|---------|
| 0-20% | 轻度 (mild) |
| 20-50% | 中度 (moderate) |
| 50-80% | 重度 (severe) |
| >80% | 极重度 (profound) |

**主观可懂度**（人工评估，如条件允许）：
- 随机抽取每位说话人 20 条录音
- 5 位不熟悉该说话人的听者逐条转写
- 计算平均准确率作为主观可懂度分

#### Step 2：文本长度分层

将所有评测样本按参考文本长度分为 3 层：

| 层 | 字符数 | 代表类型 | 说明 |
|----|--------|---------|------|
| 短文本 | 1-4 字 | 唤醒词、短指令 | CER 波动大，需单独报告 |
| 中文本 | 5-8 字 | 普通指令 | 主力评测层 |
| 长文本 | 9+ 字 | 复杂温控指令 | ASR 上下文优势区 |

#### Step 3：语种分离

| 类别 | 处理方式 |
|------|---------|
| 纯中文 | 正常评测 |
| 中英混合（Hey Siri） | 单独报告，不纳入整体 CER 均值 |
| 纯英文 | 排除或使用英文 ASR 模型 |

### 3.3 训练方法升级（对标 MDSC 三阶段）

```
v1.0:  通用 ASR (step-asr) → 直接评测
                ↓
v2.0:  SIC 阶段 → SID 阶段 → SDD 阶段 → 分层评测
```

#### 阶段 1：SIC（Speaker-Independent Control）

| 项目 | 内容 |
|------|------|
| 训练数据 | 健康人语音（AISHELL-1 等公开数据集） |
| 基座模型 | Whisper-small |
| 目标 | 建立中文语音识别基线 |
| 产出 | SIC 基线模型 |

#### 阶段 2：SID（Speaker-Independent Dysarthria）

| 项目 | 内容 |
|------|------|
| 训练数据 | v1.0 全部 4,130 条构音障碍录音（需先标注） |
| 方法 | LoRA 微调 SIC 模型（r=16, α=32） |
| 数据增强 | 速度扰动 [0.9, 1.1] + 白噪声 SNR [-15,15]dB + 频谱遮盖 |
| 目标 | 学习构音障碍的通用发音模式 |
| 产出 | SID 通用障碍模型 |

#### 阶段 3：SDD（Speaker-Dependent Dysarthria）

| 项目 | 内容 |
|------|------|
| 训练数据 | 单个说话人的 **3 分钟注册语料**（~30 条录音） |
| 方法 | 在 SID 模型上继续 LoRA 微调（更小 lr） |
| 正负样本比 | **1:5**（目标短语 : 非目标短语） |
| 目标 | 适配个人发音特征 |
| 产出 | 每人一个 ~8MB LoRA 权重 |

### 3.4 数据集划分升级

```
v1.0:  全量数据 → 全量评测（无划分）
                ↓
v2.0:  按说话人内划分：
       ├── Train (70%) — 用于 SID/SDD 训练
       ├── Dev (10%)   — 用于调参（阈值、Top-K）
       └── Test (20%)  — 最终评测，严禁用于训练
       
       特殊处理：
       ├── 注册集 (3min/人) — 从 Train 中划出，用于 SDD
       └── OOV 集 (15-20 条/人) — 仅在 Test，用于拒识评估
```

### 3.5 评测报告格式升级

#### 总览表（按说话人）

| Speaker | 临床等级 | 客观 CER | nCER | Top-1 | Top-3 | OOV Rej. | 样本数 |
|---------|---------|---------|------|-------|-------|----------|--------|
| DF0001 | 中度 | xx% | xx% | xx% | xx% | xx% | 405 |
| DF0013 | 极重度 | xx% | xx% | xx% | xx% | xx% | 405 |
| ... | | | | | | | |

#### 分层表（按文本长度）

| 文本层 | 轻度 CER | 中度 CER | 重度 CER | 极重度 CER |
|--------|---------|---------|---------|-----------|
| 短(1-4) | xx% | xx% | xx% | xx% |
| 中(5-8) | xx% | xx% | xx% | xx% |
| 长(9+) | xx% | xx% | xx% | xx% |

#### 消融实验表（模型对比）

| 模型/阶段 | 整体 CER | 轻度 | 中度 | 重度 | 极重度 | Δ vs 基线 |
|-----------|---------|------|------|------|--------|-----------|
| step-asr（v1.0 基线） | xx% | xx% | xx% | xx% | xx% | — |
| Whisper-small（SIC） | xx% | xx% | xx% | xx% | xx% | — |
| + SID（通用障碍） | xx% | xx% | xx% | xx% | xx% | +xx% |
| + SDD（个性化） | xx% | xx% | xx% | xx% | xx% | +xx% |
| + 数据增强 | xx% | xx% | xx% | xx% | xx% | +xx% |

---

## 4. v2.0 实验执行计划

### Phase 1：数据清洗与标注（1 周）

```
1. 从 v1.0 CSV 中提取 speaker_id，计算每人加权平均 CER → 客观严重度
2. 按 §3.2 Step 2-3 分层，标注文本长度和语种
3. 人工标注 label（参考文本已有，只需验证）
4. 执行 Train/Dev/Test 划分（§3.4）
5. 为每位说话人划出 3 分钟注册集
```

### Phase 2：基线复现与对比（1 周）

```
1. 用 v1.0 的 step-asr 结果作为基线（已有）
2. 部署 Whisper-small → 同一测试集评测 → SIC 基线
3. 对比 step-asr vs Whisper-small 在各严重度上的表现
4. 生成 v2.0 格式的评测报告
```

### Phase 3：渐进式微调（2 周）

```
1. SID 训练：用全部说话人 Train 集 + 数据增强 → LoRA 微调 Whisper
2. SDD 训练：为 3-5 位重点说话人训练个性化 LoRA
3. 消融实验：每阶段独立评测，量化增益
4. 注册数据量实验：1min / 2min / 3min / 5min → 绘制可用性曲线
```

### Phase 4：评测与报告（3 天）

```
1. 在 Test 集上运行全部模型 → 生成各维度指标
2. OOV 拒识测试 → FAR/FRR/Score
3. 绘制：可用性曲线、严重度-性能关系图、音素错误热力图
4. 撰写实验报告，对标论文结果
```

---

## 5. v1.0 → v2.0 关键差异对照

| 维度 | v1.0 | v2.0 |
|------|------|------|
| **严重度定义** | 按单条 CER 自动分级 | 按说话人加权 CER + 临床量表 |
| **评测指标** | CER 单一指标 | CER + nCER + Top-1/3 + FAR/FRR + OOV Rej. |
| **数据划分** | 无划分 | Speaker-内 70/10/20 + 注册集 + OOV 集 |
| **模型** | step-asr 通用模型 | SIC → SID → SDD 三阶段渐进 |
| **数据增强** | 无 | 速度扰动 + 白噪声 + 频谱遮盖 |
| **个性化** | 无 | 3 分钟注册语料 → 个人 LoRA |
| **报告格式** | 一维表格 | 多维分层（说话人 × 严重度 × 文本长度 × 模型阶段） |
| **拒识能力** | 未测试 | OOV 集专项评测 |

---

## 6. 从 v1.0 数据中立即可做的事

以下分析**无需新模型训练**，直接基于 v1.0 CSV 即可完成：

### 6.1 计算说话人级加权 CER

```python
import pandas as pd

df = pd.read_csv('batch_evaluation_results.csv')
df['speaker'] = df['文件名'].str.extract(r'^([A-Z]+\d+)')

# 加权平均 CER（按字符数加权）
speaker_cer = df.groupby('speaker').apply(
    lambda g: (g['错误数'].sum() / g['总字符数'].sum()) * 100
).round(2)
print(speaker_cer.sort_values())
```

### 6.2 文本长度分层分析

```python
df['text_len'] = df['总字符数']
df['len_group'] = pd.cut(df['text_len'], bins=[0, 4, 8, 100], labels=['短(1-4)', '中(5-8)', '长(9+)'])

pivot = df.groupby(['speaker', 'len_group'])['CER(%)'].mean().unstack()
print(pivot.round(1))
```

### 6.3 音素错误模式分析

```python
# 找出最常见的替换模式
from collections import Counter

errors = []
for _, row in df[df['CER(%)'] > 0].iterrows():
    ref = row['参考文本']
    hyp = row['识别结果'].rstrip('。')
    if len(ref) == len(hyp):  # 仅分析等长替换
        for r, h in zip(ref, hyp):
            if r != h:
                errors.append(f'{r}→{h}')

print(Counter(errors).most_common(20))
```

---

## 附录 A：v1.0 数据中观察到的典型错误模式

| 错误类型 | 示例 | 频率 | 说明 |
|---------|------|------|------|
| 同音/近音替换 | 小度→小布, 小艺→小义 | 高频 | 声母/韵母偏移 |
| 完全幻觉 | "音量调大"→"一袋的辣" | 高频（重度） | ASR 对不清晰语音产生无关输出 |
| 标点插入 | "你好小布"→"你好，小布" | 中频 | 不影响语义，CER 虚高 |
| 数字格式差异 | "二十八"→"28" | 中频 | 阿拉伯数字 vs 中文数字，需统一 |
| 中英转写错误 | "Hey Siri"→"嘿昔日" | 高频 | 中文 ASR 不处理英文 |
| CER > 100% | "E"→"Eco模式关" | 低频但影响统计 | 参考文本极短时发生 |

### 建议的预处理清洗规则

```
1. 去除识别结果末尾标点（。，！？）再计算 CER
2. 统一数字格式：阿拉伯数字 → 中文数字（或反之）
3. CER 上限截断为 100%（使用 nCER）
4. 排除中英混合文本（Hey Siri 等）的整体统计
5. 忽略逗号、空格等标点差异
```

---

*Project Resonance — 共鸣项目 | 实验方法升级 v2.0*
