# 脑瘫患者定制化语音识别 —— 技术路径对比

## 路径 1：短语库模糊匹配（当前可做）

```
患者说话 → 通用 ASR (step-asr) → 模糊文本
                                      ↓
短语库 (100条) → 编辑距离/语义匹配 → Top-3 候选意图 → TTS 复述确认
```

| 维度 | 详情 |
|------|------|
| **原理** | ASR 输出的错误文本与短语库做字符串相似度匹配（Levenshtein 距离），找最接近的意图 |
| **难度** | 🟢 **低** — 纯前端逻辑，几十行代码 |
| **成本** | 💰 **零额外成本** — 用现有 ASR API，无需 GPU |
| **准确率** | ~40-60%（取决于 ASR 基础识别质量） |
| **个性化** | ❌ 不针对个人优化，所有用户共享同一模型 |
| **落地时间** | 1-2 小时 |

---

## 路径 2：Whisper + LoRA 微调（中期目标）

```
采集数据 (每人50-100条)
    ↓
标注 (音频↔文本对)
    ↓
Whisper-small 基座模型冻结
    ↓
LoRA 适配层训练 (~30分钟)
    ↓
患者专属 LoRA 权重 (~8MB)
    ↓
部署推理服务 (GPU 服务器)
    ↓
Edge Function 代理调用
```

| 维度 | 详情 |
|------|------|
| **原理** | 在 Whisper 模型的注意力层插入低秩矩阵（rank=8-16），只训练这部分参数来学习特定患者的发音模式 |
| **难度** | 🟡 **中** — 需要 Python 训练脚本 + GPU 环境 + 模型部署 |
| **训练成本** | 💰💰 单次训练 ~¥5-15（云 GPU 按需），每人一个模型 |
| **推理成本** | 💰💰 ~¥200-500/月（GPU 服务器 7×24 运行），或按需调用 |
| **准确率** | ~70-85%（50条数据即可显著提升） |
| **个性化** | ✅ 每人独立 LoRA 权重，真正的定制化 |
| **落地时间** | 2-4 周（含数据采集+训练+部署） |
| **技术栈** | Python, HuggingFace PEFT, PyTorch, RunPod/Modal/AutoDL |

### 关键步骤

```bash
1. pip install transformers peft datasets
2. 准备数据: [{audio: "patient_001.wav", text: "我想喝水"}, ...]
3. 加载 Whisper-small + LoRA config (r=16, alpha=32)
4. 训练 ~500 steps（约 30 分钟，单张 3090）
5. 导出 LoRA 权重 → 部署到 GPU 推理服务
6. Edge Function 代理转发请求
```

---

## 路径 3：Step-Audio 开源模型自部署 + SFT

```
大规模数据采集 (数百位患者)
    ↓
数据清洗标注
    ↓
Step-Audio 2 mini 开源基座
    ↓
全量 SFT 训练 (多张 A100)
    ↓
通用病理语音 ASR 模型
    ↓
自建推理集群
    ↓
API 服务
```

| 维度 | 详情 |
|------|------|
| **原理** | 用阶跃星辰开源的 Step-Audio 模型做全量/LoRA 微调，利用其端到端架构同时优化理解和生成 |
| **难度** | 🔴 **高** — 需要 ML 工程团队、大量标注数据、分布式训练经验 |
| **训练成本** | 💰💰💰 数千至数万元（多卡 A100，训练数天） |
| **推理成本** | 💰💰💰 ~¥2000+/月（模型更大，需更强 GPU） |
| **准确率** | ~85-95%（数据量足够时） |
| **个性化** | ✅✅ 可做通用病理语音模型 + 个人 LoRA 叠加 |
| **落地时间** | 3-6 个月 |
| **适用场景** | 商业化产品、医院级部署 |

---

## 总结建议

| 阶段 | 路径 | 适合场景 |
|------|------|----------|
| **黑客松（现在）** | 路径 1 模糊匹配 | Demo 演示，验证产品逻辑 |
| **赛后 1 个月** | 路径 2 Whisper+LoRA | 小规模试点，3-5 位真实用户 |
| **拿到融资后** | 路径 3 Step-Audio | 规模化部署，覆盖更多患者 |

---

## 关于 LoRA 微调

LoRA（**Low-Rank Adaptation**）是一种高效微调大模型的技术。核心思想：冻结原始模型参数，仅在注意力层插入小规模的低秩矩阵进行训练。

- **全量微调**：修改数十亿参数，需多张 A100，风险高（灾难性遗忘）
- **LoRA 微调**：仅修改 <1% 参数，单张消费级 GPU 即可，原模型能力完整保留

每位患者只需录制 **50-100 条短语**，即可训练出一个 ~8MB 的 LoRA 权重文件，叠加到基座模型上实现个性化识别。

---

*Project Resonance — 共鸣项目*
